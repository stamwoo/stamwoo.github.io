<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[老家的两棵树]]></title>
    <url>%2F2895591053%2F</url>
    <content type="text"><![CDATA[一棵是石榴树 另一棵还是石榴树 它们长大了,我也该长大了]]></content>
      <tags>
        <tag>Life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java_GC是如何做的(二)]]></title>
    <url>%2F4065948361%2F</url>
    <content type="text"><![CDATA[通过上文我们知道了Java GC的相关理论,那么在实际中,jvm是通过哪些垃圾收集器来完成GC的? Stop the World又是怎么一回事呢? 这是本文我们将解决的两个问题. 最新的垃圾回收器g1]]></content>
      <tags>
        <tag>jvm</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lost in Europe 8.尾声]]></title>
    <url>%2F1983337747%2F</url>
    <content type="text"><![CDATA[绿色的马褂木叶子 没想到这么快已经写到了这个系列的最后一篇,我深知自己文笔不好,叙述又简单直接,导致整个系列像是流水账一般,很多发生在这期间的趣事也都没能很好的记录下来. 不过不要紧,历久弥新,等记忆慢慢沉淀一段时间之后我会再将有趣的一件件小事更新进来. 回国的飞机还有一件幸运的事. 海航的飞机选位时一般都可以加钱选到比较好的位置,例如紧急出口旁边,这个位置空间很大,离洗手间也很近,并且有责任在发生紧急情况时协助机组.但如果没有人选的话,一般空姐会从乘客里选择一名幸运儿坐在那里.这一次,我就变成了那个幸运儿. 过去的已经过去,回来之后,让一切重新开始.]]></content>
      <tags>
        <tag>Life</tag>
        <tag>Lost in Europe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lost in Europe 7.Luzern]]></title>
    <url>%2F2290293698%2F</url>
    <content type="text"><![CDATA[Luzern是此行的最后一站,在卢塞恩其实没有很固定的景点需要去. 唯一一个比较出名的应该就是沉睡的狮子雕刻,像我这种对于西方历史只停留在初中历史的人其实也不太关心雕刻背后的事件影响之类的. 我所享受的更多是自然风光. 到达卢塞恩车站是在中午十二点,依然选择了离火车站不太远的一家酒店,因为还未到check in时间,寄存行李之后我便出门了.BTW,这里的酒店依旧像Interlaken一样,赠送了本地的公交日卡. 一路上,大多使用马蜂窝,穷游,小红书来查看本地有什么好吃的好玩的.综合比较下来,小红书的质量还是要稍高一些,信息更新也比较及时. 因此我便去了廊桥,不出意外的,卢塞恩有很多的国人,或许是因为钟表的原因让他们来到这里? 城市很小的原因,也确实没什么可去的. 接下来的行程就是卢塞恩游湖-穆塞格城墙(在城墙旁的草坪上还被我撸到了噬元兽!)-沉睡的狮子-Rolex店(当然只是看看) 游湖所乘坐的SAPHIR号 被我撸到的那只噬元兽,白色的脚真好看 沉睡的狮子,貌似是跟法国什么历史事件有关 其实说来去了很多地方,但因为城市的确很小,我又没有购物的需求,所以大概到下午四点我已经回到了酒店,毕竟第二天还要飞回国. 说到这家酒店,位置很棒,服务态度和早餐都是一流而且挺有性价比,唯一不好的地方是天台是个酒吧,当晚又是周六,然后就只能在趴体声中入眠,也算一个小小的缺点吧. 所享受的行程早餐]]></content>
      <tags>
        <tag>Life</tag>
        <tag>Lost in Europe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lost in Europe 6.Interlaken]]></title>
    <url>%2F3436201018%2F</url>
    <content type="text"><![CDATA[Interlaken是此行中最满意最开心的一个目的地. 景色棒,友善度高,费用合适. 不过我觉得Interlaken的中译名:”因特拉肯”,实在是不够好,完全不够美.让我起的话,可能叫湖间城(是湖间不是胡建hhh). 事实上,Interlaken确实位于两湖之间,有两座湖还有名叫少女峰的欧洲最高峰,讲真的,我特别羡慕生活的这里的人. 在我乘坐齿轮火车去少女峰的途中,看到很多很多当地人,不管男女老少,都带着自己的滑雪装备前往半山腰一个特别大的自然滑雪场滑雪.而我作为一个观光客,只能露出羡慕嫉妒恨的眼神. 到Interlaken的第一天住了一家名叫 Du Nord 的酒店,是此行住过最棒的酒店.酒店位置离Interlaken Ost车站步行8分钟,就在大草坪广场的旁边.而且早餐丰富,房间面积也很大,在前台还可以直接买去少女峰的火车票,当然也像其他酒店一样会送给你城市的公交天票,这样你就可以随便坐公交了. 从酒店可以直接看到雪山 来到Interlaken的80%的游客应该都是冲着少女峰去的,Top of Europe.少女峰的名字的由来其实是因为常年云雾环绕,就像一位带着面纱的害羞少女,所以得名少女峰.(好奇,西方人不都很开放的吗),少女峰作为整个欧洲都很出名的地方,经常举办各种活动,比如最长举办的就是滑雪,除此之外还有篮球名人赛,足球名人赛,邓紫棋还曾经在这里开过小型演唱会. 天气好的时候可以看到德国的黑森林 做小火车最棒的景色在与一路上两边的白雪或者瑞士那种类似天堂的安静平和的生活景象,一栋栋房子坐落在山谷间,远处就是白色山顶的山.我现在特别恨我文笔差,还是让图片来说话吧… 然后从少女峰下来,走在回酒店的路上,突然看到有人在玩滑翔伞,然后突然想起:我还没玩过什么刺激的呢这么多天. 于是一个小时之后,我背着伞,从一千米的高空看着lakes和Interlaken,耳边是呼呼的风,偶尔还有雨滴落在脸上.这种感觉美翻了. 就当我陶醉着呢,飞行教练问了我一句:Do u wanna something crazy?我当然说yeah,sure,come on.然后几个大角度的飞行动作下来.嗯,嘴巴里不停的叫着OMG,胃里也开始翻江倒海,脑袋里除了想吐还是想吐.最后当我降落在大草坪的时候,坐在广场旁的长椅上,满脑子就是我是谁,我在哪儿,我在干嘛. 离开Interlaken是在第二天的上午,坐着最出名的黄金列车,看着窗外的美景.只可惜天公不作美,天气有些阴沉.不过这必定不是我最后一次来Interlaken,等到下次,下下次,总会有好天气.]]></content>
      <tags>
        <tag>Life</tag>
        <tag>Lost in Europe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lost in Europe 5.Paris]]></title>
    <url>%2F736215289%2F</url>
    <content type="text"><![CDATA[因为之前回老家的缘故,巴黎篇一直没有写. 在没有写的这段时间里,巴黎又发生了很多”大事”: 周董和昆凌又去了巴黎 再次发生了暴乱 其实在老家期间又发生了很多事情,这里不再赘述. 回归正题: 今天刷煎蛋,看到巴黎赫然出现在世界生活成本前十的大城市里,不禁深以为然.因为在巴黎我住了这次流浪里最没有性价比的酒店. 酒店早餐,房间大小,硬件设施都十分愧对它的价格,唯二能称得上的就是服务&amp;位置. 巴黎虽然作为传统的旅游城市,但我对它的第一印象并不太好.从火车站出来,附近显得十分无序,没有给人一种井井有条的感觉. 特别是在巴黎你并不能像其他欧洲城市一张,挥手就能打车,大多数情况下你必须要到特定地点才能坐出租,否则就要通过电话预约. 之前,我看到有些宾馆提供叫车服务我还并不理解,现在终于明白了. 其次,巴黎的治安是要分区的,携程上便宜的酒店大多位于不安全的区,所以看到那些酒店经常会有几条差评.诸如,行李放房间被偷,晚上在酒店附近被抢这种. 所幸我住的地方位于第八区.治安还算可以,这也是我当时订酒店愿意付出高价的原因,毕竟出门在外,安全第一. 有埃菲尔怎么拍都好看. 在巴黎我呆了三天,行程比较常规. D1: 巴黎歌剧院 凯旋门 埃菲尔铁塔 塞纳河游船 D2: 卢浮宫 巴黎圣母院 在巴黎逛的时候,还遇到了一场小型示威活动.现场没看到火堆也没有人向防暴警察扔石头,当然我也不太想当个吃瓜群众,拍了段视频便离开了.我又想起我问出租车司机,巴黎安全吗?他跟我说,不要相信电视媒体的话,巴黎很安全,你看这路上,多么平和(calm).我信你个鬼,这几天我在国内看到又有商店被烧了. 蒙娜丽莎实在是太火爆了 据说是什么网红马卡龙,我也跟个风 我想说一句,卢浮宫实在太大了!真要认真逛的话恐怕三天三夜也逛不完,这也导致我第三天直接没办法安排任何行程,在酒店好好休息了一番.下午便启程前往Interlaken了.]]></content>
      <tags>
        <tag>Life</tag>
        <tag>Lost in Europe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lost in Europe 4.The Hague]]></title>
    <url>%2F531776623%2F</url>
    <content type="text"><![CDATA[离开了阿姆斯特丹,坐着火车来到了荷兰的另一个城市来到了海牙. 因为海牙国际法庭我知道了这里,而想来这里是因为一副画:戴珍珠耳环的少女. 这张画作为我的锁屏壁纸和电脑桌面陪伴了我很长的时间,经常我在发呆的时候就对着她的眼睛,想象着少女的心事.这幅画是那么美,让我感到平和感到安宁.作为工科生,并不知道如何鉴赏,如何考究画家的技艺.但是作为普通人即使不明白那些,也会有说不上的原因让你喜欢这幅画.是不是才是真的魅力?而看这幅画时,与在卢浮宫看蒙娜丽莎的微笑完全不同,蒙娜丽莎的微笑像深邃的大海,而这位少女像是小池塘. 在这次流浪中,海牙与因特拉肯可谓是我最喜欢的两个城市.甚至某种角度上,海牙更棒. 在这里,大部分道路上都没有红绿灯.但是十分有秩序.因为并不是特别火爆的旅游城市,也看不到很多游客与外地人. 整个城市给人的感觉就是安静,祥和.完全是人想象中的欧洲小城,城市里铺满石子的道路,18世纪就矗立着的建筑. 因为莫瑞泰斯博物馆周一下午才开门,我就在城里随便走走.却不小心进入了即将开始的一场小型午餐音乐会.这场小型音乐会的听众大都是白头发的当地人,有男也有女. 音乐会有三位艺术家表演,年龄最小的是一位2000年的男士.除了男士之外,另外还有两位女士,一位88年的女士负责主持与钢琴演奏,另一位99年的少女负责歌剧表演.关于这些信息我都由入场时发放的清单上得知,清单上有演出的曲目同时还有艺术家们的介绍,来让人们更熟悉这场音乐会.]]></content>
      <tags>
        <tag>Life</tag>
        <tag>Lost in Europe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lost in Europe 3.Amsterdam]]></title>
    <url>%2F2077908186%2F</url>
    <content type="text"><![CDATA[阿姆斯特丹中央车站离我订的酒店特别近,但我还是推着行李箱走了十多分钟.当晚住的酒店也是我至今为止住过最贵的酒店,但不是最棒的. 吃过了前台给的巧克力曲奇后,我就出门去了著名的红灯区.一个个穿着暴露服装的女郎呆在类似商店橱窗的小房间里,不断对着路人做出各种挑逗的姿势与眼神.有人敲开房门,她们便出来与之商量价格,而这种往往只是好奇,并不会真的进去.谁知道那些顾客与客人到底在想什么呢? 红灯区所在的那片区域十分繁华,处处都飘着大麻的气味.这种气味实在让我十分难受,于是在吃过了一碗日式拉面之后匆匆离开了这里. 在这里的两天基本都在下雨,并且风很大.好在我基本也都是室内活动.唯一比较烦的是,衣服一直是湿湿的,让我不太舒服. 接下来就是日常的博物馆之旅,和在柏林类似.这种历史悠久的西方城市总是有各种优秀的博物馆. 其中在阿姆斯特丹,我最想要去的就是梵高美术馆.馆里收藏了很多梵高的作品,比如向日葵,自画像等等. 因为这是一次流浪,流浪当然是没有计划的,所以我并没有提前在网上预订梵高美术馆的门票,这导致我到达美术馆门口,向工作人员询问后一度以为自己今天无法进去了. 转机发生在我去排队买旁边的荷兰国立博物馆门票的时候.我看着购票窗口上有写着:今日梵高美术馆门票已售尽.但当我直接向柜台人员买票时,他竟然直接给我了一张梵高美术馆的门票! 我简直高兴的蹦起来了! 然后这一天的行程就变成了上午参观荷兰国立博物馆,下午参观梵高美术馆,完美. 关于梵高,他真的是个天才,但是天才总是不被当下的人认同了.虽然是老生常谈的话题了,但是还是很悲哀.一个人因为超脱时代,而被时代挤压.就像布鲁诺. 在参观完国立博物馆之后,因为还有点时间.我便去了一家apple store,这对我来说是个顺便的行程. 因为这家apple store与王府井那家,或者与巴黎那家并没有特别让我印象深刻的地方,相似的巨大实木桌子,相似的透明阶梯通到二楼,相似的工作人员脸上的微笑. 想到苹果,就想到无印良品,想到特斯拉,想到宜家.]]></content>
      <tags>
        <tag>Life</tag>
        <tag>Lost in Europe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lost in Europe 2.Tromso]]></title>
    <url>%2F3538858214%2F</url>
    <content type="text"><![CDATA[去Tromso是唯一在欧洲坐飞机的行程,原因无他.中间隔着海,加上距离太远. Tromso虽然有机场,但一般都需在Oslo转机,我这次也是一样. 在飞机快要到达Oslo机场时,我往下看了一眼:一座小房子包裹在树林里,只有小路通向外面.有种与世隔绝的桃花源的感觉,住在这里的人们,肯定是和自己最爱的人生活在一起,才可以不怕孤独吧. 在Tromso是我第一次住Airbnb,房子还不错,屋子里巨大的落地窗正对着大海和山,景色很棒.设施也很齐全.但并不是那种和当地人生活在一起.而更像是中国农村小旅馆的感觉.唯一不方便的地方是地理位置,Tromso是一座小的岛屿,城市的旅游集散地和大多数酒店都集中在市中心,而我住的地方属于是居民区,离市中心走路需要25分钟.因为这里家家户户都有车的原因,公交设施并不十分发达,所以我大多数时候都是走路到市中心.也许有人说25分钟并不是很久.对,但是这里是岛屿,属于山丘地貌.这25分钟基本都是需要上上下下,特别耗费体力. 因为流浪并没有提前订极光团,等我当天晚上到了想在淘宝定却发现已经订不了了.于是我只能去当地的游客服务中心去订当天英语的大团. 然后当天白天的行程就是乘坐索道去一座满是雪的山坡从上往下俯视整个Tromso,景色特别好看.很多人还带了登山的用具,带着家人从这个山坡登向更高的山峰,而我作为一个懒散的流浪汉,只能在山坡上看了会景色就下来了. 之后白天的行程就是北极大教堂-Tromso图书馆.随后在市区吃了三文鱼就去极光团集合点了. 说到三文鱼我还不得不提一下物价,本身我以为这里的物价是跟Berlin差不多的.然而当我到了超市就被自己打脸了.一盒10个的鸡蛋要6欧,买了一袋鱼干200g 30欧.果然这种什么都不产的地方物价就很高.原本我以为挪威盛产三文鱼,那么三文鱼应该很便宜吧.但是在餐厅吃了一份简单的熟三文鱼和后来吃的生三文鱼,算下来都200+人民币.此处,心疼我的信用卡一秒钟. 追极光可以说是最让人振奋的时候了,我乘坐的大巴从Tromso出发,行驶了约两小时到达了极光营地,随行的向导一路上一直在告诉我们要有耐心.路上我还一直担心到底当晚能不能看到极光,事实证明我的担心是多余的.我去的那天虽然是满月,但是天气晴朗并且kp值到达了4.所以在营地等待了大约一个小时左右终于看到了如梦如幻的极光. 刚开始的时候,只是看到天空出现了一条很细微的绿色亮纹,但是它逐渐发生变化,颜色变得越来越深,范围也变得越来越大.慢慢的就像是一条绿色的彩带飘在空中,又像一条帷幕,不断在跳动.我也匆匆用手机拍了几张,但实在是没办法呈现出那种美. 看完极光,从市中心往回走的时候.居然就在自己住的airbnb门口再一次看到了极光!网上说除非运气特别好,能在市区看到极光真的很难.否则也不会有那么多极光团要开车几个小时去远郊追极光了.而且在门口看到的极光也特别清楚,也在舞动,当时我直接兴奋的喊了出来! 每次行程我都会抽出一天给自己放松下,不用赶什么景点,也没有目的地.在Tromso的最后一天也是这样,晃晃悠悠睡到了中午,看着景色走到了市区.吃过饭后就在市图书馆静静坐着,看着在图书馆里和我一样的年轻人在看着书或者用着电脑,除了安逸还是安逸.]]></content>
      <tags>
        <tag>Life</tag>
        <tag>Lost in Europe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lost in Europe 1.Berlin]]></title>
    <url>%2F2973382090%2F</url>
    <content type="text"><![CDATA[柏林是德国的首都,我从机场到酒店的路上跟出租车司机聊了一路.告诉他我来德国的目的和我的情况.想想那时的雄心壮志,现在忽然感觉有点傻. 刚开始我在酒店住了一周,我发现在这短短的几天里我并不喜欢这个城市.跟国内巨大的差异,让我一时很不适应.加上语言和生活习惯的问题,萌生了想要退却的想法,但是因为种种原因,仍旧照计划租了位于市中心的房子,继续了我的生活. 我租的房子在亚历山大广场附近,房间有很多窗户但是朝向不好,而且位于一层.在住在这里的时候,我曾经连续吃了三十天的汤面,也经历了很多工作或情感的问题.一度以为自己要抑郁了,每次有偏激的想法的时候,我都会出去走走. 亚历山大广场有一个教堂叫做圣母教堂,有一个电视塔.我拍过一张照片是电视塔顶和教堂顶的照片.离广场不远的地方是柏林著名的博物馆岛,柏林大教堂.对于我来说,因为对西方文化不了解并且不感兴趣并未给我留下很深的印象. 除了亚历山大广场附近以外,我还常去zoo附近.那里有一家名叫’樱’的中国餐馆,自助餐包括火锅,烤肉,寿司.女老板及帮工听口音都是南方人,火锅并不正宗,但却是我在柏林吃过的唯一一次火锅,当然也是最好吃的一次了. zoo的地铁站旁边有家名叫curry 36的小店,是卖香肠的.我在那里吃过好多次,特别喜欢那里的香肠,但是对于上面满满的酱料却总觉得重口味.回到国内想再吃就有点难了. 回到国内,很多事变得容易了,很多事变得难了,也有些事变得不可能了. 我总是想起坐100路公交,从亚历山大广场到zoo.路上会经过一片很大的公园. 记得在公园里,夕阳就洒在草坪上,有一个女人坐在长椅上,远远的背对着我,一只狗趴在那里,它的主人在旁边看着他.这是我记忆中关于柏林最美的场景. 从公园回去的路上经过了一座桥,就站在桥上看粉色的晚霞,特别美.]]></content>
      <tags>
        <tag>Life</tag>
        <tag>Lost in Europe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lost in Europe 0.序]]></title>
    <url>%2F2566597183%2F</url>
    <content type="text"><![CDATA[2019.3.12日,我坐在郑州的家中,回忆着过去几个月发生的种种. 一切就像是一场梦,而我告诉自己梦该醒了. 过去几个月走过的路比我此前二十多年走过的还要多,所经历事情的复杂程度也远远大于以前.如果说过去的我像是一列在轨道上高速行驶的火车,那这几个月之后我更希望我像一艘帆船.帆船在海上行驶大多是有固定的航线,不过偶尔也可以停在某个荒岛. 这是一系列自说自话的博客文章,写下来只是为了记录.文章中的图片是我使用iphone 8所拍,也有一些是同路人帮我拍的,谢谢他们. I’m alone,but I’m not lonely.]]></content>
      <tags>
        <tag>Life</tag>
        <tag>Lost in Europe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm调优总结]]></title>
    <url>%2F4127594812%2F</url>
    <content type="text"><![CDATA[大多数调优参数都是调整堆内存的大小,以及根据实际情况选择最合适的垃圾收集器. GC相关 通过NewRatio控制新生代老年代比例 通过MaxTenuringThreshold控制进入老年前生存次数等]]></content>
      <tags>
        <tag>jvm</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java_GC是如何做的]]></title>
    <url>%2F3421010594%2F</url>
    <content type="text"><![CDATA[在使用Java之前,我在大学使用过两年多的C++.刚接触Java时,肯定会下意识的与cpp去比较.譬如说:指针,单继承,值传递引用传递和垃圾回收. 众所周知,在写cpp时最重要的工作之一就是delete ptr,稍有不慎就会造成内存泄漏,出现大的问题.也正因为此,对java的GC机制感到十分神奇.Java是怎么做到垃圾回收的,它的垃圾回收机制是如何实现的,Java有了GC机制之后是否就不可能发生内存泄漏了呢? 在去回答这几个问题之前,我们先想一下以下三个问题: Java GC 一般说不依靠程序员手动调用,那它是什么时候发生的? 对于cpp来说,可以通过delete或free的方式释放指定区域内存,那Java GC怎么知道哪些内存是可以被释放掉的呢,换言之,Java GC是如何发现’垃圾’的? 在发现’垃圾’之后,Java GC又是通过哪些操作/算法去’清除’掉垃圾的呢? GC 发生时机程序调用System.gc时可以触发系统自身决定,一般无法精准预测那么问题就来了,系统是怎么决定的呢? 再说这个之前,你必须要清楚的知道Jvm的内存结构. 当代主流虚拟机(Hotspot VM)的垃圾回收都采用“分代回收”的算法.“分代回收”是基于这样一个事实：对象的生命周期不同,所以针对不同生命周期的对象可以采取不同的回收方式,以便提高回收效率. Hotspot VM将堆内存划分为不同的物理区,就是“分代”思想的体现.如图所示,JVM堆内存主要由新生代、老年代、永久代构成. 简单了解了jvm内存结构之后,继续说何时发生GC. 其实在主流jvm(HotSpot Vm)中,GC分为两种: Minor GC: 发生在新生代的垃圾收集动作,因为Java对象大多都具备朝生夕灭的特性,所以Minor GC非常频繁,一般回收速度也比较快. Full GC: 发生在老年代的GC,出现一次Full GC尝尝伴随至少一次Minor GC. 知道了Java GC 包含两种之后,我们再看下分别他们发生的时机: Minor GC: 当Eden区满了之后,触发MinorGC Full GC: 调用System.gc时,系统建议执行Full GC,但是不必然执行 老年代空间不足 持久代空间不足 通过Minor GC后进入老年代的平均大小大于老年代的可用内存 由Eden区、From Space区向To Space区复制时,对象大小大于To Space可用内存,则把该对象转存到老年代,且老年代的可用内存小于该对象大小 虽然Full GC发生的场景看着比Minor GC多不少,但实际它发生的频率是要大大少于Minor GC的.最重要的原因是:Java 里绝大多数对象都是’朝生夕死’,这导致老年代一般情况根本不会占多大空间.而一旦老年代或持久代空间占用过多,Full GC频繁,影响生产环境.那99%是程序有问题,需要通过排查gc日志去解决问题了 Java GC 是如何发现’垃圾’的呢?笼统的说,Java GC 通过GC Roots将无法搜索到的对象进行标记,经过一次标记后又经过可达性分析之后的对象就会被认为是’垃圾’. 可达性分析每次回收都需要经历两次标记过程: 第一次标记对象进行根搜索之后，如果发现没有与GC Roots 相连接的引用链，就会被第一次标记并进行筛选. 所谓筛选，就是检查此对象是否有必要执行finalize方法，如果对象定义了该方法并且没有执行过。那么该对象就会被放入到一个队列F-Queue，随后会有一个低优先级的线程去执行这个队列里面对象的finalize方法 第二次标记JVM 将对F-Queue队列里面的对象进行第二次标记。如果还是没有与GC Roots相连接,那么就要悲剧了. 如果对象不想被回收，那么就得在finalize方法里面拯救自己，否则，这些对象就真的会被回收. 下面有个小例子,说明了finalize是怎么拯救自己的.1234567891011121314151617181920212223242526272829303132333435363738394041public class GCRootsTest &#123; private static GCRootsTest obj; protected void finalize() throws Throwable &#123; super.finalize(); System.out.println("finalize方法被执行!"); obj = this; System.out.println("finalize "+ this); &#125; public static void main(String[] args) throws InterruptedException &#123; obj = new GCRootsTest(); System.out.println("main " + obj); obj = null; System.gc(); Thread.sleep(500); /** * 第一次调用时,通过finalize拯救了new出来的这个对象 */ if (null != obj) &#123; System.out.println("1-obj还存活着！"); &#125; else &#123; System.out.println("1-obj已经死了"); &#125; obj = null; System.gc(); Thread.sleep(500); /** * 第二次调用时,gc不再调用finalize.也就无法拯救自己 */ if (null != obj) &#123; System.out.println("2-obj还存活着！"); &#125; else &#123; System.out.println("2-obj已经死了"); &#125; &#125;&#125; 何为GC Roots上面的内容多次提到了GC Roots,然而并没有说明什么对象才会被Java JVM认定为GC Roots. 虚拟机栈中引用的对象：比如方法里面定义这种局部变量 User user= new User(); 方法区中静态属性引用的对象：比如 private static User user = new User(); 方法区中常量引用的对象：比如 private static final User user = new User(); 本地方法栈JNI(Native方法)中引用的对象 Java JVM通过哪些神奇操作清理掉’垃圾’的呢最初是通过三种算法来实现清理’垃圾’的操作,而在实际中又会更复杂些: 标记-清除 复制 标记-整理对于标记过程其实和上述的标记过程是一样的,通过GC Roots和两次标记来标记出需要被清理的垃圾.下面具体点介绍三种算法: 标记-清除(Mark-Sweep)算法 清除就只是释放掉被标记的对象占用的内存资源而已.可以看到,清除之后很容易产生内存碎片,导致无法为大对象分配空间,而很快触发下次GC 复制(Copying)算法为了解决Mark-Sweep算法的缺陷，Copying算法就被提了出来。它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用的内存空间一次清理掉，这样一来就不容易出现内存碎片的问题。具体过程如下图所示： 这种算法虽然实现简单，运行高效且不容易产生内存碎片，但是却对内存空间的使用做出了高昂的代价，因为能够使用的内存缩减到原来的一半。 很显然，Copying算法的效率跟存活对象的数目多少有很大的关系，如果存活对象很多，那么Copying算法的效率将会大大降低。 标记-整理(Mark-Compact)算法为了解决Copying算法的缺陷，充分利用内存空间，提出了Mark-Compact算法。该算法标记阶段和Mark-Sweep一样，但是在完成标记之后，它不是直接清理可回收对象，而是将存活对象都向一端移动，然后清理掉端边界以外的内存。具体过程如下图所示： 当然标记-整理算法也不是没有缺点.将村话对象移动是需要耗费系统资源的.如果存活的对象多的话,无疑是不能被接受的. Generational Collection(分代收集)算法分代收集算法是目前大部分JVM的垃圾收集器采用的算法。它的核心思想是根据对象存活的生命周期将内存划分为若干个不同的区域。一般情况下将堆区划分为新生代(Young Generation)和老年代(Tenured Generation)，老年代的特点是每次垃圾收集时只有少量对象需要被回收，而新生代的特点是每次垃圾回收时都有大量的对象需要被回收，那么就可以根据不同代的特点采取最适合的收集算法。 目前大部分垃圾收集器对于新生代都采取Copying算法，因为新生代中每次垃圾回收都要回收大部分对象，也就是说需要复制的操作次数较少，但是实际中并不是按照1：1的比例来划分新生代的空间的，一般来说是将新生代划分为一块较大的Eden空间和两块较小的Survivor空间，一般Eden空间,S0空间,S1空间的比率是8:1:1.每次使用Eden空间和其中的一块Survivor空间，当进行回收时，将Eden和Survivor中还存活的对象复制到另一块Survivor空间中，然后清理掉Eden和刚才使用过的Survivor空间。 而由于老年代的特点是每次回收都只回收少量对象，一般使用的是Mark-Compact算法。 注意，在堆区之外还有一个代就是永久代(Permanet Generation)，它用来存储class类、常量、方法描述等。对永久代的回收主要回收两部分内容：废弃常量和无用的类。 总结通过上面的三个问题和答案,其实已经解决了绝大部分有关Java GC的问题.至于一些细节的问题和没解答的问题,希望读者也能去找到答案.我这里也留几个问题: Java有了上述说的GC机制就万无一失,不会发生内存泄露了吗? System.gc()引起Full GC,那么它的使用场景是啥呢 只介绍了GC算法,其实它们都有具体的实现.叫做垃圾收集器.那么有哪些垃圾收集器,我们该怎么根据生产场景选择合适的垃圾收集器呢? 上面算是留了三个坑,未来会在java-GC是如何做的(二)中一一解答,敬请期待. 引用 https://tech.meituan.com/2017/12/29/jvm-optimize.htmlhttps://blog.csdn.net/wk51920/article/details/51550470https://www.zhihu.com/question/35164211/answer/68265045https://www.jianshu.com/p/5261a62e4d29https://blog.csdn.net/gzu_imis/article/details/38376429http://www.cnblogs.com/dolphin0520/p/3783345.html]]></content>
      <tags>
        <tag>jvm</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[扒一扒ReentrantLock利用AQS实现原理]]></title>
    <url>%2F2870231089%2F</url>
    <content type="text"><![CDATA[前言 ReetrantLock? AQS? 为什么会有 AQS 呢？(其中 AQS 是 AbstractQueuedSynchronizer 的缩写) 因为有人的地方就有江湖，所以有并发的地方就有资源共享，有资源共享的地方就有线程安全，有线程安全的地方就有 “线程同步”，有线程同步的地方就有 “锁”（有点长，但是理是这个理） AQS 就是 JDK 中为 “线程同步” 提供的一套基础工具类（网上其他帖子叫做 “框架” 我觉得这个就说的太大了，其实就是一个类而已（不算它衍生出来的子类）国内存在一些翻译会导致很多初学者很难理解，比如 classloader 的 parents 被翻译为 “双亲”，简直败笔，此处默哀 3 秒钟），因此 AQS 就成了非常重要的一个知识点，因为基于它可以写出 JAVA 中的很多“锁” 类。比如此文要分析的 ReetrantLock，它就是基于 AQS 而形成了一个“可重入锁” ReetrantLock 它是一个 “可重入” 锁。 什么是 “可重入”？ 简单地讲就是：“同一个线程对于已经获得到的锁，可以多次继续申请到该锁的使用权” 正经地讲就是：假如访问一个资源 A 需要获得其锁 lock，如果之前没有其他线程获取该锁，那么当前线程就获锁成功，此时该线程对该锁后续所有 “请求” 都将立即得到 “获锁成功” 的返回，即同一个线程可以多次成功的获取到之前获得的锁。“可重入”可以解释成“同一个线程可多次获取”。 我们来看一个使用 ReetrantLock 的例子，来一步步地理解和学习 1234567891011121314151617181920212223242526272829//未使用ReetrantLock进行多线程累加操作public class ReetrantLockForIncrease &#123; static int cnt = 0; static ReentrantLock reentrantLock = new ReentrantLock(); public static void main(String[] args) &#123; Runnable r = () -&gt; &#123; int n = 10000; while (n &gt; 0) &#123; cnt++; n--; &#125; &#125;; IntStream.range(0, 5) .forEach(value -&gt; new Thread(r).start()); try &#123; //等待足够长的时间 确保上述线程均执行完毕 Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(cnt); &#125;&#125;//输出的结果会小于50000 123456789101112131415161718192021222324252627282930//使用ReetrantLock的多线程累加操作public class ReetrantLockForIncrease &#123; static int cnt = 0; static ReentrantLock reentrantLock = new ReentrantLock(); public static void main(String[] args) &#123; Runnable r = () -&gt; &#123; int n = 10000; while (n &gt; 0) &#123; reentrantLock.lock(); cnt++; reentrantLock.unlock(); n--; &#125; &#125;; IntStream.range(0, 5) .forEach(value -&gt; new Thread(r).start()); try &#123; //等待足够长的时间 确保上述线程均执行完毕 Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(cnt); &#125;&#125;//输出结果将和预想中的一致:50000 通过上述的例子, 你可以在心里暂时把它看成 “就是一把普通的锁”(其他细节慢慢会讨论)，而作为一把锁, 当然要有锁的基本特性: 加锁 解锁 至于什么指纹解锁、人脸解锁、虹膜解锁啥的，其实也逃不出 “加锁”、“解锁”，只不过是在这两个基本动作上做了一些个性化。 同理，ReetrantLock 也不过就是在锁的基本特性上加了一些 “可重入”、“公平”、“非公平” 等特性。因此我们只要弄清楚基本锁是如何 “加锁” 和“解锁”，以及 ReetrantLock 如何实现 “可重入”、“公平” 和“非公平”，也就达到了对这个内容的理解和学习的目的。 总结一下学习要点（大纲）： 基本锁的特性 加锁 解锁 ReetrantLock 的补充特性 可重入 公平 非公平 接下去就按照大纲去梳理，就 OK 了 理解 ReetrantLock 的主要方法可以看出 ReetrantLock 对象实现了 Lock 接口 图 3: ReetrantLock 的类继承结构 而 Lock 接口的主要方法有以下几个 图 4: Lock 接口包含的基本方法 Lock 对象只是一个接口，上述方法具体的实现其实都在 ReetrantLock 中，因此我们只要在 ReetrantLock 对象中查看具体实现去理解锁的 “加锁” 和“解锁”操作是如何做的 ReetrantLock 的主要方法 图 5: ReetrantLock 的主要方法 其中加锁方法即为 lock()，解锁方法即为 unLock() 这两个方法在源码中的实现如下 123456789//加锁public void lock() &#123; sync.lock();&#125;//释放锁public void unlock() &#123; sync.release(1);&#125; 从上述可以知道这两个方法实际上是操作了一个叫做 sync 的对象，调用该对象的 lock 和 release 操作来实现 sync 是什么东西？ 我拷了一段 ReetrantLock 类的源码片段 1234public class ReentrantLock implements Lock, java.io.Serializable &#123; private static final long serialVersionUID = 7373984872572414699L; private final Sync sync;&#125; 可以看出，sync 是 ReetrantLock 中的一个私有的成员变量，且类型是 Sync 对象 Sync 是什么类？做啥的？是什么时候初始化的？ 不着急，我们先看简单的 “sync 是在什么时候初始化的” 在源码中，只有在 2 个构造函数的地方对 sync 对象做了初始化，可分别初始化为 NonfairSync 和 NonfairSync 123456789101112131415/** 所有锁操作都是基于这个字段 */private final Sync sync;/** * 通过该构造函数创建额ReetrantLock是一个非公平锁 */public ReentrantLock() &#123; sync = new NonfairSync();&#125;/** * 如果入参为true，则创建公平的ReetrantLock； * 否则，创建非公平锁 */public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 这两个对象（NonfairSync 和 NonfairSync）也是 ReetrantLock 的内部类 图 6: NonfairSync 和 FairSync 类继承结构 从上图可以看书 FairSync 和 NonFairSync 在类结构上完全一样且均继承于 Sync 而 Sync 对象的继承关系如下 图 7: ReetrantLock 的内部类 Sync 实现于 AQS 类 以上我们可以得出这么一个初步结论 ReetrantLock 实现了 Lock 接口, 操作其成员变量 sync 这个 AQS 的子类, 来完成锁的相关功能。而 sync 这个成员变量有 2 种形态：NonfairSync 和 FairSync ReentrantLock 的构造函数中，默认的无参构造函数将会把 Sync 对象创建为 NonfairSync 对象，这是一个 “非公平锁”；而另一个构造函数 ReentrantLock(boolean fair) 传入参数为 true 时将会把 Sync 对象创建为“公平锁”FairSync FairSync、NonfairSync、Sync 之间的关系 在上文中我们提到 ReetrantLock 的 lock 操作是调用 sync 的 lock 方法。而 sync 有 2 种形态，那么我们可以分别对比一下 NonfairSync 的 lock 方法和 FairSync 的 lock 方法有什么异同。 NoFairSync 的 lock() 方法的执行时序图 图 8: NoFairSync 的 lock() 方法执行时序图 FairSync 的 lock() 方法的执行时序图 图 9: FairSync 的 lock() 方法的执行时序图 通过对比 NofairSync 和 FairSync 的 lock 方法时序图可以看出两者的操作基本上是大同小异。FairSync 在 tryAquire 方法中，当判断到锁状态字段 state == 0 时，不会立马将当前线程设置为该锁的占用线程，而是去判断是在此线程之前是否有其他线程在等待这个锁（执行 hasQueuedPredecessors() 方法），如果是的话，则该线程会加入到等待队列中，进行排队（FIFO，先进先出的排队形式）。这也就是为什么 FairSync 可以让线程之间公平获得该锁。 NoFairSync 的 tryAquire 方法中，没有判断是否有在此之前的排队线程，而是直接进行获锁操作，因此多个线程之间同时争用一把锁的时候，谁先获取到就变得随机了，很有可能线程 A 比线程 B 更早等待这把锁，但是 B 却获取到了锁，A 继续等待（这种现象叫做：线程饥饿） 到此，我们已经大致理解了 ReetrantLock 是如何做到不同线程如何 “公平” 和“非公平”获锁。 线程之间是什么时候知道要排队的，如何排队的？排队的线程什么时候能获得到锁？排队的线程怎么感知到 “锁空闲”？ 我们一个个解答上面的疑问 线程是什么时候排队的？我们可以猜想一下，应该在获锁的时候，无法成功获取到该锁，然后进行排队等待。是不是这样的呢？ 源码贴上来！ 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 各位客官，看到了没，acquireQueued(addWaiter(Node.EXCLUSIVE), arg) 这个 addWaiter(Node.EXCLUSIVE) 就是请求排队的，通过上面的时序图（图 8，9）可知该动作是在 FairSync 或者 NoFairSync 调用 AQS 的 aquire(1) 方法时触发的，而且由该方法中的 if 块可知，只有当 if 中的 tryAcquire 为 false 的时候（也就是获锁失败的时候），才会执行后续的 acquireQueued 方法 线程是如何排队的？想要知道如何排队，那也就是去理解 addWaiter(Node.EXCLUSIVE) 这个方法具体是如何实现的 而在看源码解析前，各位同学可以思考一下，如果是你来实现一个队列来对线程进行排队和管理，你需要关心什么信息呢？ 线程，肯定要知道我是哪个线程（因为连哪个线程都不知道，你还排啥队，管理个球球？） 队列中线程状态，既然知道是哪一个线程，肯定还要知道线程当前处在什么状态，是已经取消了 “获锁” 请求，还是在 “” 等待中”，或者说“即将得到锁” 前驱和后继线程，因为是一个等待队列，那么也就需要知道当前线程前面的是哪个线程，当前线程后面的是哪个线程（因为当前线程释放锁以后，理当立马通知后继线程去获取锁） 而上述的数据，在 AQS 中被组织到了一个叫做 Node 的数据结构（内部类）中 图 11：Node 类的内部结构 线程的 2 种等待模式： SHARED：表示线程以共享的模式等待锁（如 ReadLock） EXCLUSIVE：表示线程以互斥的模式等待锁（如 ReetrantLock），互斥就是一把锁只能由一个线程持有，不能同时存在多个线程使用同一个锁 线程在队列中的状态枚举： CANCELLED：值为 1，表示线程的获锁请求已经 “取消” SIGNAL：值为 - 1，表示该线程一切都准备好了, 就等待锁空闲出来给我 CONDITION：值为 - 2，表示线程等待某一个条件（Condition）被满足 PROPAGATE：值为 - 3，当线程处在 “SHARED” 模式时，该字段才会被使用上（在后续讲共享锁的时候再细聊） 初始化 Node 对象时，默认为 0 成员变量： waitStatus：该 int 变量表示线程在队列中的状态，其值就是上述提到的 CANCELLED、SIGNAL、CONDITION、PROPAGATE prev：该变量类型为 Node 对象，表示该节点的前一个 Node 节点（前驱） next：该变量类型为 Node 对象，表示该节点的后一个 Node 节点（后继） thread：该变量类型为 Thread 对象，表示该节点的代表的线程 nextWaiter：该变量类型为 Node 对象，表示等待 condition 条件的 Node 节点（暂时不用管它，不影响我们理解主要知识点） 解释了 Node 的数据结构，那么我用几张图来表示多线程竞争下 ReetrantLock 锁时是如何排队的 初始状态（也就是锁未被任何线程占用的时候）线程 A 申请锁此时，成功获取到锁，无排队线程 线程 B 申请该锁，且上一个线程未释放 图 12：第一个进入排队的线程 这里需要关注的是 Head 节点，这个节点是一个空的 Node 节点，不存储任何线程相关的信息 3. 线程 C 申请该锁，且占有该锁的线程未释放 图 13：第二个进入排队的线程 4. 线程 D 申请该锁，且占有该锁的线程未释放 图 14：第三个进入排队的线程 通过以上几幅图，就可以大致了解该队列是链表的形式组织不同 Node（每一个 Node 代表一个线程）之间的先后顺序。Tips: 强烈建议没有学习过 “数据结构” 的同学先去学习一下数据结构！框架和花哨的知识点千变万化层出不穷，唯有底层的计算机原理是共通和基本不变的 等待中的线程如何感知到锁空闲并获得锁？上文我们提到 acquireQueued(addWaiter(Node.EXCLUSIVE), arg) 中的 addWaiter(Node.EXCLUSIVE) 方法是对获锁失败的线程放入到队列中排队等待，而该方法的外层方法 acquireQueued() 就是对已经排队中的线程进行 “获锁” 操作 简单地讲：就是一个线程获取锁失败了，被放到了线程等待队列中，而 acquireQueued 方法就是把放入队列中的这个线程不断进行 “获锁”, 直到它 “成功获锁” 或者 “不再需要锁（如被中断）” 这个方法的主要流程 图 15：排队中的 Node 获锁流程 这里需要注意的是：紫色箭头所在的流程实际上是一个 “while 循环”*，跳出该循环的唯一出口就是 “p 是 head 节点，并且当前线程获锁成功” 为什么要这个条件呢？因为这个条件满足就代表 “这个线程是排队线程中的最前面的节点（线程）了” 再提一句，别嫌啰嗦：“不管公平还是非公平模式下，ReetrantLock 对于排队中的线程都能保证，排在前面的一定比排在后面的线程优先获得锁” 但是，这里有个但是，非公平模式不保证 “队列中的第一个线程一定就比新来的（未加入到队列）的线程优先获锁” 因为队列中的第一个线程尝试获得锁时，可能刚好来了一个线程也要获取锁，而这个刚来的线程都还未加入到等待队列，此时两个线程同时随机竞争，很有可能，队列中的第一个线程竞争失败（而该线程等待的时间其实比这个刚来的线程等待时间要久）。拗口吗？哈哈，好好理解一下。我尽力了。 这里就有小伙伴问了:“如果就是那么不恰巧, 就是不符合这个唯一跳出循环的条件”, 那就一直在循环里面空跑了吗! 那 CPU 使用率不就会飙升?! 注意!! 流程图里有一个步骤 “判断当前线程是否需要被阻塞”，如果是的话，就 “阻塞线程”！ “阻塞线程”！ “阻塞线程”！ 当线程被阻塞了，也就没有循环什么事情了（阻塞的线程将会让出 CPU 资源，该线程不会被 CPU 运行）。直到下次被唤醒，该线程才会继续进行循环体内的操作 重点来了！“什么时候线程需要被阻塞呢？” 我们来看一下这个判断的执行流程 图 19：AQS 判断线程是否应该被阻塞 问题来了: 流程图中 “CAS 设置 pred 节点状态为 SIGNAL“并表示该线程“不应该” 被阻塞, 那么该线程就会继续在上述提到的 “while 循环”* 一直空跑吗? 其实认真看的同学应该就能知道, While 循环中必须要这个 node 符合 “它就是该队列中最早的 Node 并且获锁成功” 才会跳出 While 循环体, 如果不是, 则会继续执行到 “判断这个线程是否应该被阻塞”, 此时, 原本状态不是 SIGNAL 的线程, 因为在上一次 “判断这个线程是否应该被阻塞” 这个方法时被设置成了 SIGNAL, 那么第二次执行这个判断时, 就会被成功阻塞。也就不会出现 “空跑” 的情况 综上所述呢，只要有其他线程因为释放了锁，那么 “线程等待队列中的第一个 Node 节点就可以成功获取到锁（如果没有队列外的线程同时竞争这个锁）” 解锁在上一个知识点我提到 只要有其他线程因为释放了锁，那么 “线程等待队列中的第一个 Node 节点就可以成功获取到锁（如果没有队列外的线程同时竞争这个锁）” 实际上这并不是一个很准确的结论，因为 “线程等待队列” 中的第一个 Node 节点在其他线程未释放锁时，因为获取不到锁，那么也会被“阻塞” 这个时候，实际上所有在等待队列中的 Node 节点里代表的线程都是处于 “阻塞” 状态。 那什么时候唤醒这些阻塞的线程呢？ 哈哈，既然申请锁的时候会导致线程在得不到锁时被 “阻塞” 那么，肯定就是其他线程在释放锁时 “唤醒” 被阻塞着的线程去 “拿锁”。 ReetrantLock 中的源码走一个 12345678910111213public void unlock() &#123; sync.release(1);&#125;public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false; &#125; 其中，unparkSuccessor(h) 方法就是 “唤醒操作”，主要流程如代码所示 尝试释放当前线程持有的锁 如果成功释放，那么去唤醒头结点的后继节点（因为头节点 head 是不保存线程信息的节点，仅仅是因为数据结构设计上的需要，在数据结构上，这种做法往往叫做 “空头节点链表”。对应的就有 “非空头结点链表”） unparkSuccessor(h) 的执行流程源码解析 123456789101112131415161718192021222324private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); //如果head节点的下一个节点它是null或者已经被cancelled了（status&gt;0） //那么就从队列的尾巴往前找，找到一个最前面的并且状态不是cancelled的线程 //至于为什么要从后往前找，不是从前往后找，谁能跟我说一下，这点我也不知道为什么 Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; //将找到的队列中符合条件的第一个线程“唤醒” if (s != null) LockSupport.unpark(s.thread);&#125; 至此，申请锁的 “阻塞” 和释放锁的 “唤醒” 操作中 “队列什么时候进行排队”、“如何排队”、“什么时候移除队列”、“何时阻塞线程”、“何时唤醒线程” 基本都已经解释清楚了。 如何实现可重入在讲解 lock() 方法的图 8、图 9 中，我们有提到加锁操作会对 state 字段进行 + 1 操作 这里需要注意到 AQS 中很多内部变量的修饰符都是采用的 volitale, 然后配合 CAS 操作来保证 AQS 本身的线程安全 (因为 AQS 自己线程安全, 基于它的衍生类才能更好地保证线程安全), 这里的 state 字段就是 AQS 类中的一个用 volitale 修饰的 int 变量 state 字段初始化时, 值为 0。表示目前没有任何线程持有该锁。当一个线程每次获得该锁时，值就会在原来的基础上加 1，多次获锁就会多次加 1（指同一个线程），这里就是可重入。因为可以同一个线程多次获锁，只是对这个字段的值在原来基础上加 1; 相反 unlock 操作也就是解锁操作，实际是是调用 AQS 的 release 操作，而每执行一次这个操作，就会对 state 字段在原来的基础上减 1，当 state==0 的时候就表示当前线程已经完全释放了该锁。那么就会如上文提到的那样去调用 “唤醒” 动作，去把在 “线程等待队列中的线程” 叫醒 为了加深对个 AQS 的大致工作流程的理解，我对对 AQS 重点的几个内容画了一个粗略的流程图 图 20 以上就是全部，无法巨细，希望能帮到大家。有错误之处，留言，我会及时修改 如果充分理解了 AQS 那么很多 JDK 中的同步和锁的其他实现类理解起来就非常简单愉快了, 比如 CountDownLatch 这个不要太简单~ 小伙伴们可以自行看一下源码哦, 不超过 10 分钟, 你就能知道是怎么回事]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Http重定向301,302区别]]></title>
    <url>%2F1320346412%2F</url>
    <content type="text"><![CDATA[什么是301转向?什么是301重定向? 301转向(或叫301重定向，301跳转)是当用户或搜索引擎向网站服务器发出浏览请求时，服务器返回的HTTP数据流中头信息(header)中的状态码的一种，表示本网页永久性转移到另一个地址。 什么是302重定向? 302重定向又称之为302代表暂时性转移(Temporarily Moved )，英文名称：302 redirect。 也被认为是暂时重定向(temporary redirect)，一条对网站浏览器的指令来显示浏览器被要求显示的不同的URL，当一个网页经历过短期的URL的变化时使用。一个暂时重定向是一种服务器端的重定向，能够被搜索引擎蜘蛛正确地处理。 301重定向与302重定向的区别 302重定向是暂时的重定向，搜索引擎会抓取新的内容而保留旧的网址。因为服务器返回302代码，搜索引擎认为新的网址只是暂时的。 301重定向是永久的重定向，搜索引擎在抓取新内容的同时也将旧的网址替换为重定向之后的网址。 为什么302 重定向和网址劫持有关联 从网址A 做一个302 重定向到网址B 时，主机服务器的隐含意思是网址A 随时有可能改主意，重新显示本身的内容或转向其他的地方。大部分的搜索引擎在大部分情况下，当收到302 重定向时，一般只要去抓取目标网址就可以了，也就是说网址B。如果搜索引擎在遇到302 转向时，百分之百的都抓取目标网址B 的话，就不用担心网址URL 劫持了。问题就在于，有的时候搜索引擎，尤其是Google，并不能总是抓取目标网址。 比如说，有的时候A 网址很短，但是它做了一个302 重定向到B 网址，而B 网址是一个很长的乱七八糟的URL 网址，甚至还有可能包含一些问号之类的参数。很自然的，A 网址更加用户友好，而B 网址既难看，又不用户友好。这时Google 很有可能会仍然显示网址A。由于搜索引擎排名算法只是程序而不是人，在遇到302 重定向的时候，并不能像人一样的去准确判定哪一个网址更适当，这就造成了网址URL 劫持的可能性。也就是说，一个不道德的人在他自己的网址A 做一个302 重定向到你的网址B，出于某种原因， Google 搜索结果所显示的仍然是网址A，但是所用的网页内容却是你的网址B 上的内容，这种情况就叫做网址URL 劫持。你辛辛苦苦所写的内容就这样被别人偷走了。 302 重定向所造成的网址URL 劫持现象，已经存在一段时间了。不过到目前为止，似乎也没有什么更好的解决方法。在正在进行的数据中心转换中，302 重定向问题也是要被解决的目标之一。从一些搜索结果来看，网址劫持现象有所改善，但是并没有完全解决]]></content>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 四种事务隔离级别]]></title>
    <url>%2F3386238287%2F</url>
    <content type="text"><![CDATA[我们可以为数据库或分别的会话设置四种事务隔离级别. READ UNCOMMITTED（读取未提交数据） READ COMMITTED（可以读取其他事务提交的数据） REPEATABLE READ（可重读）—MySQL默认的隔离级别 SERIALIZABLE（串行化） 事务隔离级别里的名词解释 脏读: 脏读就是指当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据. 不可重复读: 是指在一个事务内，多次读同一数据.在这个事务还没有结束时，另外一个事务也访问该同一数据.那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的.这样就发生了在一个事务内两次读到的数据是不一样的，因此称为是不可重复读. 幻读: 第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行.同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据.那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样. 采用不同事务隔离级别所造成的效果有表account.结构和初始数据如下: id account 1 1000 2 1000 READ UNCOMMITTED允许脏读，也就是可能读取到其他会话中未提交事务修改的数据 会话A进行如下操作:123set session transaction isolation level read uncommitted;start transaction;select * from account; 结果如下: id account 1 1000 2 1000 会话B进行如下操作 123set session transaction isolation level read uncommitted；start transaction;update account set account=account+200 where id = 1; 会话A再进行查询 id account 1 1200 2 1000 结论即便是事务没有commit，但是我们仍然能读到未提交的数据，这是所有隔离级别中最低的一种. READ COMMITTED只能读取到已经提交的数据.Oracle数据库默认都是该级别 (不重复读) 会话B进行如下操作 1set session transaction isolation level read committed 会话A进行如下操作: 12update account set account=account-200 where id=1;select * from account; 得到结果: id account 1 800 2 1000 会话B进行查询 1select * from account; 得到结果: id account 1 1000 2 1000 会话A提交事务 1commit; 会话B进行查询 得到结果: id account 1 1000 2 1000 结论当我们将当前会话的隔离级别设置为READ COMMITTED的时候，当前会话只能读取到其他事务提交的数据，未提交的数据读不到. 同样会出现一个问题:会话B在同一个事务中，读取到两次不同的结果.这就造成了不可重复读，就是两次读取的结果不同.这种现象叫不可重复读. REPEATABLE READ为了在同一个事务中多次查询结果必须保持一致,出现了可重复读.这也是mysql默认的隔离级别. 会话B设置隔离级别为可重复读,然后查询 123set session transaction isolation level repeatable read;start transaction;select * from account; 得到结果: id account 1 1000 2 1000 会话A插入一条数据 12insert into account(id,account) value(3,1000);commit; 得到结果: id account 1 1000 2 1000 3 1000 会话B再次查询,结果与第一次是一样的: id account 1 1000 2 1000 但是 当会话B想要插入id为3的记录时: 12insert into account(id,account) value(3,1000);commit; mysql 肯定会报错,说数据重复.因为A已经提交了事务,而B为了保证可重复读做了”手脚”.这就是幻读 SERIALIZABLE完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞 会话B设置事务隔离级别,并查询,但不提交事务. 123set session transaction isolation level serializable;start transaction;select * from account; 得到结果: id account 1 1000 2 1000 会话A向表中写数据: 1insert into account(id,account) value(3,1000); 则在B未commit之前,这条插入会阻塞.当阻塞时间超时时,则会出现Lock wait time out提示. 结论当我们将当前会话的隔离级别设置为SERIALIZABLE的时候，其他会话对该表的写操作将被挂起.可以看到，这是隔离级别中最严格的，但是这样做势必对性能造成影响.所以在实际的选用上，我们要根据当前具体的情况选用合适的. 那么 mysql 5.5之后所采用的InnoDB是如何支持事务隔离级别的呢?作为扩展可以参考: MySQL事务隔离级别的实现原理 引用 https://www.jianshu.com/p/4e3edbedb9a8https://www.cnblogs.com/zhoujinyi/p/3437475.html]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么是InnoDB]]></title>
    <url>%2F1557438233%2F</url>
    <content type="text"><![CDATA[InnoDB和MyISAM的区别索引InnoDB 是聚集索引,数据文件是和索引绑在一起的,必须要有主键,通过主键索引效率很高,但是辅助索引需要两次查询,先查询到主键,然后再通过主键查询到数据.因此,主键不应该过大,否则其他索引也会很大.而 MyISAM 是非聚集索引,数据文件是分离的,索引保存的是数据文件的指针,主键索引和辅助索引是独立的. 事务InnoDB 支持事务功能,对于 InnoDB 每一条 SQL 语言都默认封装成事务,自动提交,这样会影响速度,所以最好把多条 SQL 语言放在 begin 和 commit 之间,组成一个事务.MyISAM 不支持,也因此执行速度更快,性能更好. 锁机制InnoDB 为行级锁，myisam 为表级锁.注意：当数据库无法确定，所找的行时，也会变为锁定整个表.如： 1update table set num = 10 where username like &quot;%test%&quot;; MVCC (Multi-Version Concurrency Control)阿里数据库内核‘2017/12’月报中对MVCC的解释是:多版本控制: 指的是一种提高并发的技术.最早的数据库系统，只有读读之间可以并发，读写，写读，写写都要阻塞.引入多版本之后，只有写写之间相互阻塞，其他三种操作都可以并行，这样大幅度提高了InnoDB的并发度.在内部实现中，与Postgres在数据行上实现多版本不同，InnoDB是在undolog中实现的，通过undolog可以找回数据的历史版本.找回的数据历史版本可以提供给用户读(按照隔离级别的定义，有些读请求只能看到比较老的数据版本)，也可以在回滚的时候覆盖数据页上的数据.在InnoDB内部中，会记录一个全局的活跃读写事务数组，其主要用来判断事务的可见性. &lt;高性能MySQL&gt;中对MVCC的部分介绍 MySQL的大多数事务型存储引擎实现的其实都不是简单的行级锁.基于提升并发性能的考虑,它们一般都同时实现了多版本并发控制(MVCC).不仅是MySQL,包括Oracle,PostgreSQL等其他数据库系统也都实现了MVCC,但各自的实现机制不尽相同,因为MVCC没有一个统一的实现标准. 可以认为MVCC是行级锁的一个变种,但是它在很多情况下避免了加锁操作,因此开销更低.虽然实现机制有所不同,但大都实现了非阻塞的读操作，写操作也只锁定必要的行. MVCC的实现方式有多种,典型的有乐观(optimistic)并发控制 和 悲观(pessimistic)并发控制. MVCC只在 READ COMMITTED 和 REPEATABLE READ 两个隔离级别下工作.其他两个隔离级别够和MVCC不兼容,因为 READ UNCOMMITTED 总是读取最新的数据行,而不是符合当前事务版本的数据行.而 SERIALIZABLE 则会对所有读取的行都加锁. 实现根据Mysql官方文档,可以看到,InnoDB存储引擎在数据库每行数据的后面添加了三个字段来实现MVCC,网上流传的两个字段是错的! 外键InnoDB 支持外键，而 MyISAM 不支持.对一个包含外键的 InnoDB 表转为 MYISAM 会失败. 表行数InnoDB 不保存表的具体行数，执行 select count(*) from table 时需要全表扫描.而 MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快，但如果上述语句还包含了 where 子句，那么两者执行效率是一样的. 选择InnoDB还是MyISAM的场景两种存储引擎的选择，要结合你的业务场景来做选型，可以参考以下基本原则： 是否要支持事务，如果要请选择 Innodb，如果不需要可以考虑 MyISAM。 如果表中绝大多数都是读查询（有人总结出 读:写比率大于100:1），可以考虑 MyISAM，如果既有读又有写，而且也挺频繁，请使用 InnoDB。 系统崩溃后，MyISAM 恢复起来更困难，能否接受。 MySQL 5.5 开始 InnoDB 已经成为 MySQL 的默认引擎(之前是 MyISAM )，说明其优势是有目共睹的，如果你不知道用什么，那就用InnoDB吧，至少不会差。 引用 https://juejin.im/post/5c43ee36518825254b5a3c3ahttps://segmentfault.com/a/1190000012650596https://blog.csdn.net/u011114896/article/details/38580389]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 聚簇索引和辅助索引]]></title>
    <url>%2F232040800%2F</url>
    <content type="text"><![CDATA[众所周知，mySQL 有两种常见的存储引擎。一种是 MyISAM，一种是 InnoDB。而mysql现在默认的存储引擎是InnoDB,那么为什么它选InnoDB作为存储引擎呢?网上很多回答会告诉是因为只有InnoDB使用了聚簇索引,那么聚簇索引究竟是啥东西?为了解答这个问题,笔者写下了这篇文章,除此之外也在文中解答了其他一些问题. 主键索引和聚簇索引是啥关系? 一般情况下主键会默认创建聚簇索引，且一张表只允许存在一个聚簇索引。 没有主键时，会用一个唯一且不为空的索引列做为主键，成为此表的聚簇索引 如果以上两个都不满足那innodb自己创建一个虚拟的聚集索引 注意!用户不能在有主键的情况下指定非主键列为聚簇索引 聚簇索引聚簇索引并不是一种单独的索引类型，而是一种数据存储方式。比如，InnoDB的聚簇索引使用B+Tree的数据结构存储索引和数据。当表有聚簇索引时，它的数据行实际上存放在索引的叶子页(leaf page)中。因为无法同时把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引（不过，覆盖索引可以模拟多个聚簇索引的情况）。 术语“聚簇”表示数据行和相邻的键值紧凑地存储在一起。 聚簇索引的二级索引：叶子节点不会保存引用的行的物理位置，而是保存行的主键值。 聚簇索引的列一定要是递增的!对于聚簇索引的存储引擎，数据的物理存放顺序与索引顺序是一致的，即：只要索引是相邻的，那么对应的数据一定也是相邻地存放在磁盘上的，如果主键不是自增id，可以想象，它会干些什么，不断地调整数据的物理地址、分页，当然也有其他一些措施来减少这些操作，但却无法彻底避免。但，如果是自增的，那就简单了，它只需要一页一页地写，索引结构相对紧凑，磁盘碎片少，效率也高。 辅助索引辅助索引（secondary index，也称二级索引），叶子节点并不包含行记录的全部数据，叶子节点除了包含键值以外，每个叶子节点中的索引行中还包含了一个书签。该书签用来告诉Innodb存储引擎哪里可以找到与索引相对应的行数据。由于Innodb存储引擎是索引组织表，因此Innodb存储引擎的辅助索引的书签就是相应行数据的聚集索引键。 辅助索引的存在并不影响数据在聚集索引中的组织，因此每张表上可以有多个辅助索引。当通过辅助索引来寻找数据时，InnoDB存储引擎会遍历辅助索引并通过叶级别的指针获得指向主键索引的主键，然后再通过主键索引来找到一个完整的行记录。 举例来说，如果在一棵高度为3的辅助索引树中查找数据，那需要对这棵辅助索引树遍历3次找到指定主键，如果聚集索引树的高度同样为3，那么还需要对聚集索引树进行3次查找，最终找到一个完整的行数据所在的页。因此一共需要6次逻辑IO访问以得到最终的一个数据页。从二级索引回到主键的过程称之为“回表”，在数据量大的情况下开销还是很大。 聚簇索引和非聚簇索引的图示 如下: MyISAM是没有聚簇索引的,无论主键还是其他列都是用的非聚簇索引,并且它的叶子节点存储的也不是所有列数据,而是磁盘物理地址,这里不再展开说. 索引和操作系统页的关系一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。 为了达到这个目的，磁盘按需读取，要求每次都会预读的长度一般为页的整数倍。而且数据库系统将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。并把B-tree中的m值设的非常大，就会让树的高度降低，有利于一次完全载入。 什么影响了B+树高度?IO次数取决于B+数的高度h。假设当前数据表的数据量为N，每个磁盘块的数据项的数量是m，则有h=㏒(m+1)N，当数据量N一定的情况下，m越大，h越小。而m = 磁盘块的大小 / 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低。这就是为什么每个数据项，即索引字段要尽量的小，比如int占4字节，要比bigint8字节少一半。这也是为什么b+树要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高。当数据项等于1时将会退化成线性表。 引用 http://www.ywnds.com/?p=9976https://blog.csdn.net/lisuyibmd/article/details/53004848https://blog.csdn.net/qq_16681169/article/details/50571952https://www.jianshu.com/p/54c6d5db4fe6]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式锁的实现-mysql&redis]]></title>
    <url>%2F1727393489%2F</url>
    <content type="text"><![CDATA[曾经我在一场真实面试中被问到分布式锁的实现,只能简单回答上来根据redis的setnx去做,而不知这里面其实还有很多坑.也不知是否还有其他方式.面试结束后就有了下文. 分布式锁在单进程环境中,当多个线程产生资源竞争时.程序员们会采用 Synchronize 或 Lock 去对临界资源进行加锁,使得在修改临界资源时,能够线性执行以消除并发.那么由于多线程是挂在同一个进程下的,我们就必须在这个进程内设置一个标记变量,来让所有线程都可以发现.而在分布式环境下,多进程可能会产生资源竞争,那么此时的锁就应该存放在多进程都能够看到的地方.由此我们想到了两种方式:数据库和redis. 基于数据库基于数据库的锁实现也有两种方式，一是基于数据库表，另一种是基于数据库排他锁。 基于数据库表的增删基于数据库表增删是最简单的方式，首先创建一张锁的表主要包含下列字段：方法名，时间戳等字段。 具体使用的方法，当需要锁住某个方法时，往该表中插入一条相关的记录。这边需要注意，方法名是有唯一性约束的，如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。 执行完毕，需要delete该记录。 当然，笔者这边只是简单介绍一下。对于上述方案可以进行优化，如应用主从数据库，数据之间双向同步。一旦挂掉快速切换到备库上；做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍；使用while循环，直到insert成功再返回成功，虽然并不推荐这样做；还可以记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了，实现可重入锁。 基于数据库排他锁在查询语句后面增加for update，数据库会在查询过程中给数据库表增加排他锁。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。其他没有获取到锁的就会阻塞在上述select语句上，可能的结果有2种，在超时之前获取到了锁，在超时之前仍未获取到锁。 获得排它锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，释放锁connection.commit()。 存在的问题主要是性能不高和sql超时的异常。 基于数据库的优缺点上面两种方式都是依赖数据库的一张表，一种是通过表中的记录的存在情况确定当前是否有锁存在，另外一种是通过数据库的排他锁来实现分布式锁。 优点是直接借助数据库，简单容易理解。 缺点是操作数据库需要一定的开销，性能问题需要考虑。 基于 redisSETNX 加锁使用redis的SET命令实现分布式锁，多个进程执行以下Redis命令： 1SET key value PX time NX 这条命令是当key不存在时,将字符串值value关联到key,并设置过期时间为time毫秒. 返回1，说明该进程获得锁. 返回0，说明其他进程已经获得了锁，进程不能进入临界区。进程可以在一个循环中不断地尝试 SET 操作，以获得锁。 解锁解锁很简单,直接把key删除就可以了.但是考虑一种情况. 进程A设置了一个较短的过期时间,在还未执行完之前锁已经过期被释放了.此时进程B拿到了锁进来,而A刚好又将锁删除.那这样由于过期时间设置过短,直接造成了所有redis锁失效. 为了避免这种情况,即错误删除了并非自己加的锁.我们需要在SET锁时,将UUID设置为value.在删除之前先确认这把锁是由自己加的,那么就需要有一个get的操作. 那因为get和del并不是原子操作,我们就需要采用lua脚本来保证原子性. 死锁问题死锁问题即由设置过期时间来解决,但过期时间设置会存在一个问题: 当锁过期后，该进程还没执行完，可能造成同时多个进程取得锁。 另一种redis 加解锁方式-getset我们同样假设进程P1已经首先获得了锁 lock.foo，然后进程P1挂掉了。接下来的情况： 进程P4执行 SETNX lock.foo 以尝试获取锁 由于进程P1已获得了锁，所以P4执行 SETNX lock.foo 返回0，即获取锁失败 P4执行 GET lock.foo 来检测锁是否已超时，如果没超时，则等待一段时间，再次检测 如果P4检测到锁已超时，即当前的时间大于键 lock.foo 的值，P4会执行以下操作 1GETSET lock.foo &lt;current Unix timestamp + lock timeout + 1&gt; 由于 GETSET 操作在设置键的值的同时，还会返回键的旧值，通过比较键 lock.foo 的旧值是否小于当前时间，可以判断进程是否已获得锁 假如另一个进程P5也检测到锁已超时，并在P4之前执行了 GETSET 操作，那么P4的 GETSET 操作返回的是一个大于当前时间的时间戳，这样P4就不会获得锁而继续等待。注意到，即使P4接下来将键 lock.foo 的值设置了比P5设置的更大的值也没影响。 如何解决单一进程执行时间超长,锁被抢走WATCH, MULTI, EXEC, DISCARD事务机制实现分布式锁Redis支持基本的事务操作 WATCH keyMULTIsome redis commandEXEC以上被MULTI和EXEC包裹的redis命令，保证所有事务内的命令将会串行顺序执行，保证不会在事务的执行过程中被其他客户端打断。而WATCH命令能够监视某个键，当事务执行时，如果被监视的键被其他客户端修改了值，事务运行失败，返回相应错误（被事务运行客户端在事务内修改了值，不会造成事务运行失败）。 运用Redis事务所支持的以上特性，可以实现一个分布式锁功能. 通过WATCH命令监视redis锁键，当该键未被其他客户端修改值时，事务成功执行。当事务运行过程中，发现该值被其他客户端更新了值，任务失败，进行重试。 参考 http://redisdoc.com/string/set.htmlhttps://www.cnblogs.com/crossoverJie/p/9339354.htmlhttps://juejin.im/entry/5a502ac2518825732b19a595https://blog.csdn.net/jj546630576/article/details/74910343https://blog.csdn.net/youbl/article/details/80273019]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[令牌桶限流算法(Token Bucket))]]></title>
    <url>%2F2207048324%2F</url>
    <content type="text"><![CDATA[今天学习一下什么是令牌桶算法。 1 简介令牌桶算法最初来源于计算机网络。在网络传输数据时，为了防止网络拥塞，需限制流出网络的流量，使流量以比较均匀的速度向外发送。令牌桶算法就实现了这个功能，可控制发送到网络上数据的数目，并允许突发数据的发送。 令牌桶算法是网络流量整形（Traffic Shaping）和速率限制（Rate Limiting）中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送。 大小固定的令牌桶可自行以恒定的速率源源不断地产生令牌。如果令牌不被消耗，或者被消耗的速度小于产生的速度，令牌就会不断地增多，直到把桶填满。后面再产生的令牌就会从桶中溢出。最后桶中可以保存的最大令牌数永远不会超过桶的大小。 传送到令牌桶的数据包需要消耗令牌。不同大小的数据包，消耗的令牌数量不一样。 令牌桶这种控制机制基于令牌桶中是否存在令牌来指示什么时候可以发送流量。令牌桶中的每一个令牌都代表一个字节。如果令牌桶中存在令牌，则允许发送流量；而如果令牌桶中不存在令牌，则不允许发送流量。因此，如果突发门限被合理地配置并且令牌桶中有足够的令牌，那么流量就可以以峰值速率发送。 2 算法过程 算法描述： 假如用户配置的平均发送速率为 r，则每隔 1/r 秒一个令牌被加入到桶中（每秒会有 r 个令牌放入桶中）； 假设桶中最多可以存放 b 个令牌。如果令牌到达时令牌桶已经满了，那么这个令牌会被丢弃； 当一个 n 个字节的数据包到达时，就从令牌桶中删除 n 个令牌（不同大小的数据包，消耗的令牌数量不一样），并且数据包被发送到网络； 如果令牌桶中少于 n 个令牌，那么不会删除令牌，并且认为这个数据包在流量限制之外（n 个字节，需要 n 个令牌。该数据包将被缓存或丢弃）； 算法允许最长 b 个字节的突发，但从长期运行结果看，数据包的速率被限制成常量 r。对于在流量限制外的数据包可以以不同的方式处理：（1）它们可以被丢弃；（2）它们可以排放在队列中以便当令牌桶中累积了足够多的令牌时再传输；（3）它们可以继续发送，但需要做特殊标记，网络过载的时候将这些特殊标记的包丢弃。 注意： 令牌桶算法不能与另外一种常见算法漏桶算法相混淆。这两种算法的主要区别在于漏桶算法能够强行限制数据的传输速率，而令牌桶算法在能够限制数据的平均传输速率外，还允许某种程度的突发传输。在令牌桶算法中，只要令牌桶中存在令牌，那么就允许突发地传输数据直到达到用户配置的门限，因此它适合于具有突发特性的流量。 Java 实现我们可以使用 Guava 的 RateLimiter 来实现基于令牌桶的流控，RateLimiter 令牌桶算法是单桶实现。RateLimiter 对简单的令牌桶算法做了一些工程上的优化，具体的实现是 SmoothBursty。需要注意的是，RateLimiter 的另一个实现 SmoothWarmingUp，就不是令牌桶了，而是漏桶算法。也许是出于简单起见，RateLimiter 中的时间窗口能且仅能为 1s。 SmoothBursty 有一个可以放 N 个时间窗口产生的令牌的桶，系统空闲的时候令牌就一直攒着，最好情况下可以扛 N 倍于限流值的高峰而不影响后续请求。RateLimite 允许某次请求拿走超出剩余令牌数的令牌，但是下一次请求将为此付出代价，一直等到令牌亏空补上，并且桶中有足够本次请求使用的令牌为止。当某次请求不能得到所需要的令牌时，这时涉及到一个权衡，是让前一次请求干等到令牌够用才走掉呢，还是让它先走掉后面的请求等一等呢？Guava 的设计者选择的是后者，先把眼前的活干了，后面的事后面再说。]]></content>
      <tags>
        <tag>限流</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈面试时从写一个单例开始究竟能问多深及终极解决方案]]></title>
    <url>%2F421584197%2F</url>
    <content type="text"><![CDATA[转 http://www.cnblogs.com/xiexj/p/6845029.html 看了左潇龙的《回答阿里社招面试如何准备，顺便谈谈对于 Java 程序猿学习当中各个阶段的建议》这篇文章，在想一个问题，从一个最简单的问题入手究竟能把问题问多深？下面就模拟一场面试问答，要是我是面试官，大概就只能问到下面的深度了。 旁白：一般的面试都是从最简单基本的问题开始。 面试官：请在黑板上写出一个线程安全的单例模式的例子。 面试者： 其实线程安全的实现有很多种，根据业务场景可以 new 一个实例作为私有静态成员变量，这样程序一启动，实例就生成，私有化构造函数，利用公用的静态函数 getInstance 返回实例。这种预加载的是能保证线程安全的但是如果不是确定会被使用，会造成内存的浪费，所以可以将实例放到私有静态类中作为成员变量。下面只写一种利用锁机制来保证的懒加载方法。 1234567891011121314public class Singleton &#123; private volatile static Singleton singleton; private Singleton ()&#123;&#125; public static Singleton getSingleton() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; &#125; 或者 12345678public class Singleton&#123; private static Singletoninstance = new Singleton(); private Singleton()&#123;&#125; public static Singleton getInstance() &#123; return instance; &#125;&#125; 旁白：从这个例子上我能想到的知识点主要有三个 ☆ volatile 关键字，可深入到 Java VM 内存相关 ☆ synchronized 关键字，可深入到 Java 锁机制，高并发相关 ☆ new 关键字，可深入到 Java VM 类加载机制相关 但是面试官一开始可能要先考察一下面试者是否真的理解自己写的代码 面试官：你写的这个程序是怎么保证线程安全的？ 面试者：将类的构造方法私有起来，外部调用进行初始化的时候只能通过调用 getSingleton 这个静态方法来获得实例，静态方法是整个 Java 虚拟机中只有一个实例。在创建的时候首先进行非空判断，这时候如果实例不存在，对整个类进行加锁同步，为了避免过程中非空状态的改变，同步块内再进行一次判断，如果不存在实例则创建实例返回。使用 volatile 关键字，下次访问这个方法就能直接看到实例的最新非空状态，直接返回实例。 面试官：volatile 起到了什么作用？ 面试者：volatile 这个英文单词意思是易变的，用在多线程中来同步变量。Java 的对象都是在内存堆中分配空间。但是 Java 有主内存和线程自己独有的内存拷贝。对于没有 volatile 修饰的局部变量，线程在运行过程中访问的是工作内存中的变量值，其修改对于主内存不是立即可见。而 volatile 修饰的值在线程独有的工作内存中无副本，线程直接和主内存交互，修改对主内存立即可见。 面试官：synchronized 起到了什么作用？ 面试者：锁定对象，限制当前对象只能被一个线程访问。 面试官：synchronized 里你传 Singleton.class 这个参数，起到什么作用，换成别的行不行？ 面试者：对当前类加锁，使得这个代码块一次只能被一个线程访问。这里 Singleton.class 可以换成一个常量字符串或者自己定义一个内部静态 Object。 面试官：那传 Singleton.class，常量字符串，自己定义一个内部静态 Object 有区别吗？ 面试者：因为这是一个静态方法，相当于一个概念上的类锁，所以在这里起到的效果是一样的。但是如果是原型模式，或者直接每个类都是 new 出来的，实例不同的话，在一个非静态方法里加这三种锁，这时是一个对象锁，因为 Singleton.class 或者是静态的一个 Object 或者是 JVM 只存一份的字符串常量，这些对象线程间是共享的，会对所有的实例的同步块都加同一把锁，每个实例访问到此对象的同步代码块都会被阻塞。但是如果这时 synchronized 的参数是 this，或者是内部 new 出来的一个内部非静态 Object，则各个实例拥有不同的锁，访问同一个代码相同同步块也是互不干扰。只有实例内部使用了同一个对象锁才会同步等待。 面试官：那你知道 synchronized 关键字实现同步的原理吗？ 面试者：synchronized 在 Java 虚拟机中使用监视器锁来实现。每个对象都有一个监视器锁，当监视器锁被占用时就会处于锁定状态。 线程执行一条叫 monitorenter 的指令来获取监视器锁的所有权。如果此监视器锁的进入数为 0，则线程进入并将进入数设置为 1，成为线程所有者。如果线程已经拥有该锁，因为是可重入锁，可以重新进入，则进入数加 1. 如果线程的监视器锁被其他线程占用，则阻塞直到此监视器锁的进入数为 0 时才能进入该锁。 线程执行一条叫 monitorexit 的指令来释放所有权。执行 monitorexit 的必须是线程的所有者。每次执行此指令，线程进入数减 1，直到进入数为 0。监视器锁被释放。 面试官：你刚才提到的可重入锁是什么概念，有不可重入锁吗？ 面试者：我说的可重入锁是广义的可重入锁，当然 jdk1.5 引入了 concurrent 包，里面有 Lock 接口，它有一个实现叫 ReentrantLock。广义的可重入锁也叫递归锁，是指同一线程外层函数获得锁之后，内层还可以再次获得此锁。可重入锁的设计是为了避免死锁。sun 的 corba 里的 mutex 互斥锁是一种不可重入锁的实现。自旋锁也是一种不可重入锁，本质上是一种忙等锁，CPU 一直循环执行 “测试并设置” 直到可用并取得该锁，在递归的调用该锁时必然会引起死锁。另外，如果锁占用时间较长，自旋锁会过多的占用 CPU 资源，这时使用基于睡眠原理来实现的锁更加合适。 面试官：你刚才提到了 concurrent 包，它里面有哪些锁的实现？ 面试者：常用的有 ReentrantLock, 它是一种独占锁。ReadWriteLock 接口也是一个锁接口，和 Lock 接口是一种关联关系，它返回一个只读的 Lock 和只写的 Lock。读写分离，在没有写锁的情况下，读锁是无阻塞的，提高了执行效率，它是一种共享锁。ReadWriteLock 的实现类为 ReentrantReadWriteLock。ReentrantLock 和 ReentrantReadWriteLock 实现都依赖于 AbstractQueuedSynchronizer 这种抽象队列同步器。 面试官：锁还有其他维度的分类吗？ 面试者：还可以分为公平锁和非公平锁。非公平锁是如果一个线程尝试获取锁时可以获取锁，就直接成功获取。公平锁则在锁被释放后将锁分配给等待队列队首的线程。 面试官：AQS 是什么？ 面试者：AQS 是一个简单的框架，这个框架为同步状态的原子性管理，线程的阻塞和非阻塞以及排队提供了一种通用机制。表现为一个同步器，主要支持获取锁和释放锁。获取锁的时候如果是独占锁就有可能阻塞，如果是共享锁就有可能失败。如果是阻塞，线程就要进入阻塞队列，当状态变成可获得锁就修改状态，已进入阻塞队列的要从阻塞队列中移除。释放锁时修改状态位及唤醒其他被阻塞的线程。 AQS 本质是采用 CHL 模型完成了一个先进先出的队列。对于入队，采用 CAS 操作，每次比较尾节点是否一致，然后插入到尾节点中。对于出队列，因为每个节点缓存了一个状态位，不满足条件时自旋等待，直到满足条件时将头节点设置为下一个节点。 面试官：那知道这个队列的数据结构吗？ 面试者：这个队列是用一个双向链表实现的。 面试官：你刚才提到 AQS 是一种通用机制，那它还有哪些应用? 面试者：AQS 除了刚才提到的可重入锁 ReentrantLock 和 ReentrantReadWriteLock 之外，还用于不可重入锁 Mutex 的实现。java 并发包中的同步器如：Semphore,CountDownLatch,FutureTask,CyclicBarrier 都是采用这个机制实现的。 旁白：既然问到了并发工具包中的东西，每个都可以引出一堆，但是基本原理已经问出来了，其他的问下去没什么意思。转向下一个问题。 面试官：你黑板上写的实例是通过 new 对象创建出来的，还可不可以采用别的方法来创建对象呢？ 面试者：还可以使用 class 类的 newInstance 方法，Constructor 构造器类的 newInstance 方法，克隆方法和反序列法方法。 面试官：两种 newInstance 方法有没有区别？ 面试者： ☆ Class 类位于 java 的 lang 包中，而构造器类是 java 反射机制的一部分。 ☆ Class 类的 newInstance 只能触发无参数的构造方法创建对象，而构造器类的 newInstance 能触发有参数或者任意参数的构造方法来创建对象。 ☆ Class 类的 newInstance 需要其构造方法是共有的或者对调用方法可见的，而构造器类的 newInstance 可以在特定环境下调用私有构造方法来创建对象。 ☆ Class 类的 newInstance 抛出类构造函数的异常，而构造器类的 newInstance 包装了一个 InvocationTargetException 异常。 Class 类本质上调用了反射包构造器类中无参数的 newInstance 方法，捕获了 InvocationTargetException，将构造器本身的异常抛出。 面试官：类加载的时候，自己定义了一个类和 java 自己的类类名和命名空间都一样，JVM 加载的是哪一个呢？ 面试者：调用的是 java 自身的，根据双亲委派模型，最委派 Bootstrap 的 ClassLoader 来加载，找不到才去使用 Extension 的 ClassLoader，还找不到才去用 Application 的 ClassLoader，这种机制利于保证 JVM 的安全。 面试官：你刚才提到的 java 的反射机制是什么概念？ 面试者：java 的反射机制是在运行状态中，对于任何一个类，都能够知道它所有的属性和方法；对于任何一个对象，都能够调用它的任何一个方法和属性。这种动态的获取信息和动态调用对象的方法的功能就是 java 的反射机制。它是 jdk 动态代理的实现方法。 面试官：java 还有没有其他的动态代理实现？ 面试者：还有 cglib 动态代理。 面试官：这两种动态代理哪个比较好呢？ 面试者：AOP 源码中同时使用了这两种动态代理，因为他们各有优劣。jdk 动态代理是利用 java 内部的反射机制来实现，在生成类的过程中比较高效，cglib 动态代理则是借助 asm 来实现，可以利用 asm 将生成的类进行缓存，所以在类生成之后的相关执行过程中比较高效。但是 jdk 的动态代理前提是目标类必须基于统一的接口，所以有一定的局限性。 旁白：面试者都已经提到 AOP 了，那么接下来横向，纵向，怎样都能问出一大堆问题，就不赘述。基于上面问题，读者也可以自己画出一棵知识树，然后就能找到能对答如流的终极方案：就是基本都没超过《深入理解 java 虚拟器》《java 并发编程实践》这两本书，大学学过的《数据结构与算法》《编译原理》掌握的好也可以在面试中加分哦。]]></content>
      <tags>
        <tag>interview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EMERGENCY! EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY'RE NOT. RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEING EXPIRED JUST TO BE SAFE]]></title>
    <url>%2F4205246882%2F</url>
    <content type="text"><![CDATA[警告！Eureka 可能存在维护了错误的实例列表（当它们没有启动的时候，Eureka 却把它当成启动的了）；Renews 值小于 Threshold 值，因此剩下未过期的都是安全的。 原因分析： 这个是 Eureka 的自我保护机制。Eureka Server 在运行期间，会统计心跳失败的比例在 15 分钟之内是否低于 85%，如果出现低于的情况（在单机调试的时候很容易满足，实际在生产环境上通常是由于网络不稳定导致），Eureka Server 会将当前的实例注册信息保护起来，同时提示这个警告。 Eureka server 和 client 之间每隔 30 秒会进行一次心跳通信，告诉 server，client 还活着。由此引出两个名词：Renews threshold：server 期望在每分钟中收到的心跳次数Renews (last min)：上一分钟内收到的心跳次数。 前文说到禁止注册 server 自己为 client，不管 server 是否禁止，阈值（threshold）是 1。client 个数为 n，阈值为 1+2n（此为一个 server 且禁止自注册的情况）如果是多个 server，且开启了自注册，那么就和 client 一样，是对于其他的 server 来说就是 client，是要 2 的 我开了两个 server，自注册，相关数据如下阈值：1+21renews：1）自注册 2 + 212）非自注册：2*1 Eurake 有一个配置参数 eureka.server.renewalPercentThreshold，定义了 renews 和 renews threshold 的比值，默认值为 0.85。当 server 在 15 分钟内，比值低于 percent，即少了 15% 的微服务心跳，server 会进入自我保护状态，Self-Preservation。在此状态下，server 不会删除注册信息，这就有可能导致在调用微服务时，实际上服务并不存在。这种保护状态实际上是考虑了 client 和 server 之间的心跳是因为网络问题，而非服务本身问题，不能简单的删除注册信息 stackoverflow 上，有人给出的建议是：1、在生产上可以开自注册，部署两个 server2、在本机器上测试的时候，可以把比值调低，比如 0.493、或者简单粗暴把自我保护模式关闭 **`eureka.server.enableSelfPreservation=false`** 参考文档 https://www.cnblogs.com/breath-taking/articles/7940364.html]]></content>
      <tags>
        <tag>spring</tag>
        <tag>spring cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP为什么是三次握手]]></title>
    <url>%2F3162095545%2F</url>
    <content type="text"><![CDATA[TCP为什么是三次握手TCP为什么建立连接是三次握手? 对于C和S来说,双方均需要确认对方和自己的发送信息能力和接受信息能力是OK的.拿一次完整的三次握手来举例: 第一次握手:C和S什么都不能确认. 第二次握手:C确认了自己的发送能力和接受能力,S确认了自己的接受能力. 第三次握手:S确认了自己的发送能力.]]></content>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql explain 详解]]></title>
    <url>%2F3714837258%2F</url>
    <content type="text"><![CDATA[mysql explain 详解语法及描述语法在 select 语句前加上 explain 关键字就可以 描述获取查询操作的执行顺序使用到的索引成功返回结果需要执行的行数 字段含义id标识符, 表示执行顺序. id 一样则自上而下, 否则大的先执行. select_type查询类型 simple: 不包含 union 操作或者不包含子查询的简单 select 查询 primary: 需要 union 操作或者含有子查询的 select, 位于最外层的 select.type 即为 primary, 且只有一个. union:union 链接的两个 select 查询, 第一个是 primiary, 第二个之后的都是 union. Dependent union: 出现在 union 或 union all 语句, 但是这个查询要收到外部查询的影响. union result: 包含 union 的结果集, 在 union 和 union all 语句中, 因为它不需要参与查询,, 所以 id 字段为 null subquery: 除了 from 子句中包含的子查询外, 其他地方出现的子查询都可能是 subquery Dependent subquery: 与 dependent union 类似, 表示这个 subquery 的查询要受到外部表查询的影响 derived:from 子句中出现的子查询, 也叫做派生表, 其他数据库中可能叫做内联师徒或嵌套 select 实例12345678910111213//外层是primary,内层是subqueryexplain select * from student s where s. classid = (select id from classes where classno=&apos;2017001&apos;);//结果有三行,第一行是primary,第二行是union,第三行是union resultexplain select * from student where id = 1 union select * from student where id = 2;//结果有四行,分别是primary,dependent subquery,dependent union,union resultexplain select * from student s where s.classid in (select id from classes where classno=&apos;2017001&apos; union select id from classes where classno=&apos;2017002&apos;);//跟mysql版本有关explain select * from (select * from student) s;table显示查询语句所查询的表名,如果查询使用了别名,那么这里使用的是别名.如果不涉及对数据表的操作,显示为null;有一种特殊情况,如果显示为,,则都是临时表.M,N代表的id,表示结果来自于这个查询产生 partitions表是分区表才行 type查询结果类型 const: 返回结果只有一个匹配行 range: 索引范围扫描，常见于使用 &gt;,&lt;,is null,between ,in ,like 等运算符的查询中 index: 索引全表扫描，把索引从头到尾扫一遍，常见于使用索引列就可以处理不需要读取数据文件的查询、可以使用索引排序或者分组的查询。 index_merge: 使用了一张表的多个索引, 实际上由于要读取所个索引，性能可能大部分时间都不如 range全表扫描数据文件 possible_keys &amp; keypossible_keys: 查询可能使用到的索引都会在这里列出来。 key: 查询真正使用到的索引，select_type 为 index_merge 时，这里可能出现两个以上的索引，其他的 select_type 这里只会出现一个。 key_len用于处理查询的索引长度，如果是单列索引，那就整个索引长度算进去，如果是多列索引，那么查询不一定都能使用到所有的列，具体使用到了多少个列的索引，这里就会计算进去，没有使用到的列，这里不会计算进去。 留意下这个列的值，算一下你的多列索引总长度就知道有没有使用到所有的列了. 总结通过对上面 explain 中的每个字段的详细讲解。我们不难看出，对查询性能影响最大的几个列是： select_type：查询类型 type: 连接使用了何种类型 rows: 查询数据需要用到的行 key: 查询真正使用到的索引 extra: 额外的信息尽量让自己的 SQL 用上索引，避免让 extra 里面出现 file sort(文件排序),using temporary(使用临时表)。]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring cloud 扫不到自定义controller]]></title>
    <url>%2F522943020%2F</url>
    <content type="text"><![CDATA[在 springboot 官网照着给的介绍写了个 springboot 程序 pom.xml 1234567891011&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.2.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; java 文件 123456789101112131415161718192021package hello;import org.springframework.boot.*;import org.springframework.boot.autoconfigure.*;import org.springframework.stereotype.*;import org.springframework.web.bind.annotation.*;@Controller@EnableAutoConfigurationpublic class Application&#123; @RequestMapping("/") @ResponseBody String home() &#123; return "Hello World!"; &#125; public static void main(String[] args) throws Exception &#123; SpringApplication.run(SampleController.class, args); &#125;&#125; 然后自己写了个 Controller 123456789@Controllerpublic class MyController &#123; @RequestMapping("/hello") @ResponseBody public String hello() &#123; System.out.println("hello"); return "hello"; &#125;&#125; 但是无论如何也无法扫描到自己定义的 Controller 访问之后,网页报错: Whitelabel Error Page 报错的原因是找不到对应的映射路径，即 Controller 没有被扫描到 ，。 郁闷至极，到晚上搜的结果说的是 LoginController 方的位置不对，应该让启动类和 Controller 的包在同一级目录下，然而对我却没有效果。 官方建议 application.java 放的位置： 最后尝试了下修改下 Application 上的注解，我本来复制官方的代码用的是 @Controller 和 @EnableAutoConfiguration，试着换成了 @**SpringBootApplication 注解**，出乎意外的可以扫描到 Controller 又查了下官方的文档终于找到原因了，原因是： 如果使用 @Controller 和 @EnableAutoConfiguration 注解还应该再加上一个注解：@ComponentScan 就可以了。@Controller 和 @EnableAutoConfiguration 没有扫描注解的功能，而 @ComponentScan 是 springboot 专门用来扫描 @Component, @Service, @Repository, @Controller 等注解的注解 总结： 使用 springboot 启动类配置扫描的两种注解配置方式： 1、@Controller @EnableAutoConfiguration @ComponentScan 2、@SpringBootApplication @SpringBootApplication 注解等价于 @Configuration, @EnableAutoConfiguration and @ComponentScan 另外application.java（启动类）也应该按照官方的建议放在root目录下，这样才能扫描到Service和dao，不然还会引起，扫描不到注解的问题。 **--- 更新日期：2018-10-14 ---** 最近用了最新的springboot 2.0.5.RELEASE 版本 多了一种新的扫描注解，新版的springboot application可以放在任意位置，只要加上 @ComponentScan(basePackages = {“com.oskyhang”, “com.frames”}) 注解就可以，注解指定扫描的包，就可以扫描到，更灵活方便。]]></content>
      <tags>
        <tag>spring</tag>
        <tag>spring boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么你需要一个VPS]]></title>
    <url>%2F3262901390%2F</url>
    <content type="text"><![CDATA[VPS 是什么VPS 是 Virtual private server 的简称，中文是 “虚拟专用服务器”，是指通过虚拟化技术在独立服务器中运行的专用服务器。每个使用 VPS 技术的虚拟独立服务器拥有各自独立的公网 IP 地址、操作系统、硬盘空间、内存空间、CPU 资源等，还可以进行安装程序、重启服务器等操作，与运行一台独立服务器基本相同。 很多人有点分不清 VPS 与虚拟主机的区别，网上也有很多人说过这个。博主这里就不长篇大论了，简单说，VPS 就相当于一台真正的电脑，只不过这台电脑是放在别人家的。你可以通过 ssh 工具对它做任何事，只要你开心，你砸了它也行。而虚拟主机说到底是别人家的电脑借给你用，你可以使用上面的计算资源，虚拟主机的服务商已经给你提供各种安装好的工具以及计算资源。但你对它的权限是比不上 VPS 大的。 VPS 可以用来做什么Shadowsocks使用 Python、C++、C# 等语言开发、基于 Apache 许可证的开放源代码软件，用于保护网络流量、加密数据传输。Shadowsocks 使用 Socks5 代理方式。Shadowsocks 分为服务器端和客户端。在使用之前，需要先将服务器端部署到服务器上面，然后通过客户端连接并创建本地代理。其实关于在 vps 搭建 SS 的教程已经很多了，但是博主之前搭梯子的时候发现很多教程存在一些问题，或者是太繁琐，或者是很多重要地方过了一段时间已经发生了变化，对小白用户不太友好。 因此博主决定写一篇新的教程分享出来。 Blog搭建一个属于自己的博客，搭配上 github education 提供的工具包，还可以获得一个免费域名及 SSL 认证。博主这个博客既是使用我说的这种方案搭建的。过程十分简单，按照博主的上一篇教程：在自己的 VPS 上从零开始搭建 Hexo 博客, 半天时间即可搭建完成并上线。 Seafile一套中国国产的开源、专业、可靠的云存储项目管理软件，[解决文件集中存储、共享和跨平台访问等问题。正式发布于 2012 年 10 月。除了一般网盘所提供的云存储以及共享功能外，Seafile 还提供消息通信、群组讨论等辅助功能，帮助员工更好的围绕文件展开协同工作，已有 10 多万用户使用。 作为一套比较成熟的管理软件，Seafile 的安装也十分简单。Install Seafile Client on Linux 此外，你还可以在 VPS 部署更多你自己写的脚本，比如爬虫类工具，抢票程序等等。一句话，只要是你的程序有 7*24h 的服务时间需求，你都可以把它放在你的 VPS 上跑。 VPS 哪家强看了上面的内容，如果你想选择一家 VPS 提供商，那么你大概有哪些选择呢？博主也给出了当下比较流行，有口碑的 VPS 服务商供大家参考。 DigitalOcean一家位于美国的云主机服务商，总部位于纽约，成立于 2012 年。由于价格低廉，高性能配置、灵活布置的优势，近些年来发展迅猛，成为中国站长圈们喜爱的品牌。该公司拥有多个数据中心：日本东京、美国 洛杉矶、纽约、新泽西、新加坡、英国伦敦、德国富兰克林. DigitailOcean，博主习惯称为 DO。也是博主选择的第一家 VPS 服务商，对于博主这种学生党而言，DO 是最具有性价比的一家服务商，由邀请链接注册自动赠送 $10 的优惠，再通过 paypal 充值 $5 即可使用。如果是学生用户的话使用 github education 提供的学生开发包可以再获得 $50 的优惠码。也就是说 $5 就可以使用 DO 的 1G 25gSSD 的 VPS 长达 13 个月，这性价比也是没谁了吧。 我的邀请链接是：$10 邀请链接, 另外为了选择合适的机房，再贴一个测速链接：SFO2 Speedtest | DigitalOcean Linode一个建立于美国新泽西州加洛伟的虚拟专用服务器（VPS）提供商。它的名字是由英文中 Linux 中的 Li 和 node（即 “节点” 一词）构成的混成词。如同它的名字一样，Linode 只提供运行 Linux 的服务器，而不提供运行 Windows Server 的服务器。它的服务一向以稳定著称。 知乎在发展初期使用的就是 Linode 的服务，现在口碑比较好的比较稳定的就是日本机房了，不过是要抢购，基本每每放出来都被抢完了。 搬瓦工隶属于加拿大 IT7 旗下的 VPS 服务品牌，主推 OPENVZ 架构方案，尤其是其中的 4 款便宜年付 VPS 深受广大用户的喜欢，支持支付宝付款，旗下有四个机房，均支持一键切换机房位置以及一键安装各类软件等功能。 这家前些年应该是最火的 vps 服务商了，记得曾经有 $5 的年 vps，小内存搭个 ss 还是很够用的。后来因为 ip 资源枯竭，搬瓦工拿不到什么 ip 就停了自家的超低资费服务。不过现在还是有 $19.99 的资费可以选。 Vultr一家 2014 年刚成立的 VPS 服务商，基于 KVM，采用 SSD 硬盘，拥有大量自建机房。有日本、美国洛杉矶、Dallas、Chicago、New York、Seattle、Atlanta、英国、德国等，价格便宜，配置又高。支持 Paypal、信用卡或比特币付款。 这家比较好的依然是日本主机，国内 ping 值在 100 以内，也较少抽风。另外他家的最低配置也比别家高，价格嘛，自然就水涨船高了。博主作为一个学生党目前觉得还没太必要用他家，以后说不定想试一试。]]></content>
      <tags>
        <tag>闲谈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么匿名内部类访问局部变量必须是final?]]></title>
    <url>%2F775929552%2F</url>
    <content type="text"><![CDATA[一个谜团如果你用过类似 guava 这种 “伪函数式编程” 风格的 library 的话，那下面这种风格的代码对你来说应该不陌生： 123456789public void tryUsingGuava() &#123; final int expectedLength = 4; Iterables.filter(Lists.newArrayList(&quot;123&quot;, &quot;1234&quot;), new Predicate&lt;String&gt;() &#123; @Override public boolean apply(String str) &#123; return str.length() == expectedLength; &#125; &#125;);&#125; 这段代码对一个字符串的 list 进行过滤，从中找出长度为 4 的字符串。看起来很是平常，没什么特别的。 但是，声明 expectedLength 时用的那个 final 看起来有点扎眼，把它去掉试试： error: local variable expectedLength is accessed from within inner class; needs to be declared final 结果 Java 编译器给出了如上的错误，看起来匿名内部类只能够访问 final 的局部变量。但是，为什么呢？其他的语言也有类似的规定吗？ 在开始用其他语言做实验之前我们先把问题简化一下，不要再带着 guava 了，我们去除掉噪音，把问题归结为： 为什么 Java 中的匿名内部类只可以访问 final 的局部变量呢？其他语言中的匿名函数也有类似的限制吗？ Scala 中有类似的规定吗？123456789101112def tryAccessingLocalVariable &#123; var number = 123 println(number) var lambda = () =&gt; &#123; number = 456 println(number) &#125; lambda.apply() println(number)&#125; | 上面的 Scala 代码是合法的，number 变量是声明为 var 的，不是 val（类似于 Java 中的 final）。而且在匿名函数中可以修改 number 的值。 看来 Scala 中没有类似的规定。 C# 中有类似的规定吗？12345678910111213public void tryUsingLambda ()&#123; int number = 123; Console.WriteLine (number); Action action = () =&gt; &#123; number = 456; Console.WriteLine (number); &#125;; action (); Console.WriteLine (number);&#125; 这段 C# 代码也是合法的，number 这个局部变量在 lambda 表达式内外都可以访问和赋值。 看来 C# 中也没有类似的规定。 分析谜团三门语言中只有 Java 有这种限制，那我们分析一下吧。先来看一下 Java 中的匿名内部类是如何实现的： 先定义一个接口： 123public interface MyInterface &#123; void doSomething();&#125; 然后创建这个接口的匿名子类： 12345678910111213141516public class TryUsingAnonymousClass &#123; public void useMyInterface() &#123; final Integer number = 123; System.out.println(number); MyInterface myInterface = new MyInterface() &#123; @Override public void doSomething() &#123; System.out.println(number); &#125; &#125;; myInterface.doSomething(); System.out.println(number); &#125;&#125; 这个匿名子类会被编译成一个单独的类，反编译的结果是这样的： 1234567891011121314class TryUsingAnonymousClass$1 implements MyInterface &#123; private final TryUsingAnonymousClass this$0; private final Integer paramInteger; TryUsingAnonymousClass$1(TryUsingAnonymousClass this$0, Integer paramInteger) &#123; this.this$0 = this$0; this.paramInteger = paramInteger; &#125; public void doSomething() &#123; System.out.println(this.paramInteger); &#125;&#125; 可以看到名为 number 的局部变量是作为构造方法的参数传入匿名内部类的（以上代码经过了手动修改，真实的反编译结果中有一些不可读的命名）。 如果 Java 允许匿名内部类访问非 final 的局部变量的话，那我们就可以在 TryUsingAnonymousClass$1 中修改 paramInteger，但是这不会对 number 的值有影响，因为它们是不同的 reference。 这就会造成数据不同步的问题。 所以，谜团解开了：Java 为了避免数据不同步的问题，做出了匿名内部类只可以访问 final 的局部变量的限制。 但是，新的谜团又出现了： Scala 和 C# 为什么没有类似的限制呢？它们是如何处理数据同步问题的呢？上面出现过的那段 Scala 代码中的 lambda 表达式会编译成这样： 123456789101112131415161718public final class TryUsingAnonymousClassInScala$$anonfun$1 extends AbstractFunction0.mcV.sp implements Serializable &#123; public static final long serialVersionUID = 0L; private final IntRef number$2; public final void apply() &#123; apply$mcV$sp(); &#125; public void apply$mcV$sp() &#123; this.number$2.elem = 456; Predef..MODULE$.println(BoxesRunTime.boxToInteger(this.number$2.elem)); &#125; public TryUsingAnonymousClassInScala$$anonfun$1(TryUsingAnonymousClassInScala $outer, IntRef number$2) &#123; this.number$2 = number$2; &#125;&#125; 可以看到 number 也是通过构造方法的参数传入的，但是与 Java 的不同是这里的 number 不是直接传入的，是被 IntRef 包装了一层然后才传入的。对 number 的值修改也是通过包装类进行的：this.number$2.elem = 456; 这样就保证了 lambda 表达式内外访问到的是同一个对象。 再来看看 C# 的处理方式，反编译一下，发现 C# 编译器生成了如下的一个类： 12345678910private sealed class &lt;tryUsingLambda&gt;c__AnonStorey0&#123; internal int number; internal void &lt;&gt;m__0 () &#123; this.number = 456; Console.WriteLine (this.number); &#125;&#125; 把 number 包装在这个类内，这样就保证了 lambda 表达式内外使用的都是同一个 number，即便重新赋值也可以保证内外部的数据是同步的。 小结Scala 和 C# 的编译器通过把局部变量包装在另一个对象中，来实现 lambda 表达式内外的数据同步。 而 Java 的编译器由于未知的原因（怀疑是为了图省事儿？）没有做包装局部变量这件事儿，于是就只好强制用户把局部变量声明为 final 才能在匿名内部类中使用来避免数据不同步的问题。]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[既然Java反射可以访问和修改私有成员变量，那封装成private还有意义么？]]></title>
    <url>%2F2868978503%2F</url>
    <content type="text"><![CDATA[既然Java反射可以访问和修改私有成员变量，那封装成private还有意义么？简单来说，private并不是解决“安全”问题的。安全是指不让代码被非法看到/访问。但是只要人能拿到代码，总会有办法去查看和改变代码。其他答案提到反射可以用SecurityManager来防止private被访问。但是从更高一层的角度，即便使用了SecurityManager，还是可以通过各种方式拿到java的bytecode，并做任意修改。比如有asm这样的lib，也有instrument api这种东西可以帮你。所以记得，如果你真有一段代码不允许被别人看/用，就不要把这段代码放到其他人可以碰到的地方，而是做一个server，通过接口允许有限制的访问。其他人想破解，只能破解你的服务器网关和跳板机器。关于真正的安全性，可以参考激活服务器的工作原理.private想表达的不是“安全性”的意思，而是OOP的封装概念，是一种编译器可以帮助你的设计上的hint。这就像是一家没人的店挂了个牌子“闲人免进”，但你真要进去还是有各种办法可以办到。所以private，以及所有其他的access modifier都有一层隐含的含义：如果你按照遵守这套规则，开发者可以保证不问题（不考虑bug的情况下）；否则，后果自负。比如，你在用spring的IoC的时候，你知道你要“注入”，不管它是不是private的，你知道“注入”是你自己控制的，是你设计好的效果。那么通过spring的IoC利用反射帮你注入一些private property是再正常不过的用法。再比如，单元测试，你就想测一个private方法。但是因为private的缘故就是测不了。于是你可以用反射绕开这个限制，开心的做测试。虽说某些人坚持“不应该测试private方法，而应该通过测试其他方法间接测试private方法，但并没有形成广泛的共识。这里不对这个问题展开。虽然能绕开，但绕开的代码很繁琐。久而久之就会厌倦。毕竟，代码应该为你工作，而不是你为代码工作。因此，我的经验是通常会用protected或者default来代替private。我曾设想runtime应该给一种运行模式，通过设定一个启动参数使其不管private这类的限制，这样做UT，做profiling等工作都会轻松许多。等到最后发布时，再用普通模式。但可惜现实当中并没有这种设定。评论区提到了Android里的VisibleForTesting，可以实现我期望的功能。大赞！感谢 @尤华杰我之所以敢用protected/default来代替private是因为现实当中非private不可的情景非常少见。实际上，很多时候private带来的麻烦比起带来的好处要多，这是因为很多时候对OOP的误用造成的。OOP的误用造成了无谓的private，然后逼着你必须得绕开private。其实private就是个约定而已。看看其他语言，比如python，它的“private“是一种很松散的约定，所有private的成员都用下划线开头，告诉调用者“不要随便调用我哦”，但是如果真调用了也就调用了。C++，通过指针就能绕开private。有人说，private会避免新手误用。但问题是，大家从出道开始，自己或者周围的同事朋友有谁曾经出过这个问题？IDE知道一个成员当前不能访问，就根本就不会提示。如果一个人已经开始通过源代码/反编译研究“我能不能调用这个私有方法了“，他还算是一个菜鸟吗？他会不知道这里的潜在风险吗？如果真的误用了，code review能过吗？测试能过吗？如果一个公司因为误用private成员，造成了重大的损失，那这个公司就活该倒闭算了，不要在世上丢人。OOP是一种编程思想，是众多编程思想中的一种。是开发者决定了一个问题应该用OOP合适，并且用了Java这样的语言来简化自己开发OOP代码时的工作。如果抱着这种态度，就不会误用，因为private在开发者的心中。其他人也不太可能误用，如果他上过几天java培训。不要因为语言是OOP的就去套，把不适合的OOP的代码强用OOP的各种套路实现，然后给自己后续的维护扩展埋坑。]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[蓄水池抽样算法（Reservoir Sampling）]]></title>
    <url>%2F4125998541%2F</url>
    <content type="text"><![CDATA[蓄水池抽样算法（Reservoir Sampling）许多年以后，当听说蓄水池抽样算法时,将会想起，那个小学数学老师带他做 “小明对水池边加水边放水，求何时能加满水” 应用题的下午。 问题我是在一次失败的面试经历中听说蓄水池算法的。之后上网搜了搜，知道是一个数据抽样算法，寥寥几行，却暗藏玄机。主要用来解决如下问题。 给定一个数据流，数据流长度 N 很大，且 N 直到处理完所有数据之前都不可知，请问如何在只遍历一遍数据（O(N)）的情况下，能够随机选取出 m 个不重复的数据。 这个场景强调了 3 件事： 数据流长度 N 很大且不可知，所以不能一次性存入内存。 时间复杂度为 O(N)。 随机选取 m 个数，每个数被选中的概率为 m/N。 第 1 点限制了不能直接取 N 内的 m 个随机数，然后按索引取出数据。第 2 点限制了不能先遍历一遍，然后分块存储数据，再随机选取。第 3 点是数据选取绝对随机的保证。讲真，在不知道蓄水池算法前，我想破脑袋也不知道该题做何解。 核心代码及原理蓄水池抽样算法的核心如下： 123456789101112131415161718int[] reservoir = new int[m];// initfor (int i = 0; i &lt; reservoir.length; i++)&#123; reservoir[i] = dataStream[i];&#125;for (int i = m; i &lt; dataStream.length; i++)&#123; // 随机获得一个[0, i]内的随机整数 int d = rand.nextInt(i + 1); // 如果随机整数落在[0, m-1]范围内，则替换蓄水池中的元素 if (d &lt; m) &#123; reservoir[d] = dataStream[i]; &#125;&#125; 注：这里使用已知长度的数组 dataStream 来表示未知长度的数据流，并假设数据流长度大于蓄水池容量 m。 算法思路大致如下： 如果接收的数据量小于 m，则依次放入蓄水池。 当接收到第 i 个数据时，i &gt;= m，在 [0, i] 范围内取以随机数 d，若 d 的落在 [0, m-1] 范围内，则用接收到的第 i 个数据替换蓄水池中的第 d 个数据。 重复步骤 2。 算法的精妙之处在于：当处理完所有的数据时，蓄水池中的每个数据都是以 m/N 的概率获得的。 下面用白话文推导验证该算法。假设数据开始编号为 1. 第 i 个接收到的数据最后能够留在蓄水池中的概率 = 第 i 个数据进入过蓄水池的概率 * 之后第 i 个数据不被替换的概率（第 i+1 到第 N 次处理数据都不会被替换）。 当 i&lt;=m 时，数据直接放进蓄水池，所以第 i 个数据进入过蓄水池的概率 = 1。 当 i&gt;m 时，在 [1,i] 内选取随机数 d，如果 d&lt;=m，则使用第 i 个数据替换蓄水池中第 d 个数据，因此第 i 个数据进入过蓄水池的概率 = m/i。 当 i&lt;=m 时，程序从接收到第 m+1 个数据时开始执行替换操作，第 m+1 次处理会替换池中数据的为 m/(m+1)，会替换掉第 i 个数据的概率为 1/m，则第 m+1 次处理替换掉第 i 个数据的概率为 (m/(m+1))(1/m)=1/(m+1)，不被替换的概率为 1-1/(m+1)=m/(m+1)。依次，第 m+2 次处理不替换掉第 i 个数据概率为 (m+1)/(m+2)… 第 N 次处理不替换掉第 i 个数据的概率为 (N-1)/N。所以，之后**第 i 个数据不被替换的概率 = m/(m+1)(m+1)/(m+2)…(N-1)/N=m/N**。 当 i&gt;m 时，程序从接收到第 i+1 个数据时开始有可能替换第 i 个数据。则参考上述第 3 点，之后第 i 个数据不被替换的概率 = i/N。 结合第 1 点和第 3 点可知，当 i&lt;=m 时，第 i 个接收到的数据最后留在蓄水池中的概率 = 1m/N=m/N。结合第 2 点和第 4 点可知，当 i&gt;m 时，第 i 个接收到的数据留在蓄水池中的概率 = m/ii/N=m/N。综上可知，每个数据最后被选中留在蓄水池中的概率为 m/N。 这个算法建立在统计学基础上，很巧妙地获得了 “m/N” 这个概率。 深入一些——分布式蓄水池抽样（Distributed/Parallel Reservoir Sampling）一块 CPU 的计算能力再强，也总有内存和磁盘 IO 拖他的后腿。因此为提高数据吞吐量，分布式的硬件搭配软件是现在的主流。 如果遇到超大的数据量，即使是 O(N) 的时间复杂度，蓄水池抽样程序完成抽样任务也将耗时很久。因此分布式的蓄水池抽样算法应运而生。运作原理如下： 假设有 K 台机器，将大数据集分成 K 个数据流，每台机器使用单机版蓄水池抽样处理一个数据流，抽样 m 个数据，并最后记录处理的数据量为 N1, N2, …, Nk, …, NK(假设 m&lt;Nk)。N1+N2+…+NK=N。 取 [1, N] 一个随机数 d，若 d&lt;N1，则在第一台机器的蓄水池中等概率不放回地（1/m）选取一个数据；若 N1&lt;=d&lt;(N1+N2)，则在第二台机器的蓄水池中等概率不放回地选取一个数据；一次类推，重复 m 次，则最终从 N 大数据集中选出 m 个数据。 m/N 的概率验证如下： 第 k 台机器中的蓄水池数据被选取的概率为 m/Nk。 从第 k 台机器的蓄水池中选取一个数据放进最终蓄水池的概率为 Nk/N。 第 k 台机器蓄水池的一个数据被选中的概率为 1/m。（不放回选取时等概率的） 重复 m 次选取，则每个数据被选中的概率为 m(m/NkNk/N*1/m)=m/N。 应用场景蓄水池抽样的 O(N) 时间复杂度，O(m) 空间复杂度令其适用于对流数据、大数据集的等概率抽样。比如一个大文本数据，随机输出其中的几行。 总结象征性总结：优雅巧妙的算法——蓄水池抽样。 参考文献 数据工程师必知算法：蓄水池抽样 【算法 34】蓄水池抽样算法 (Reservoir Sampling Algorithm) 分布式 / 并行蓄水池抽样 (Distributed/Parallel Reservoir Sampling) Distributed/Parallel Reservoir Sampling]]></content>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CPU100%问题定位实战]]></title>
    <url>%2F2008800739%2F</url>
    <content type="text"><![CDATA[功能问题，通过日志，单步调试相对比较好定位。性能问题，例如线上服务器 CPU100%，如何找到相关服务，如何定位问题代码，更考验技术人的功底题目 某服务器上部署了若干 tomcat 实例，即若干垂直切分的 Java 站点服务，以及若干 Java 微服务，突然收到运维的 CPU 异常告警问：如何定位是哪个服务进程导致 CPU 过载，哪个线程导致 CPU 过载，哪段代码导致 CPU 过载? 步骤一、找到最耗 CPU 的进程工具：top方法： 执行 top -c ，显示进程运行信息列表 键入 P (大写 p)，进程按照 CPU 使用率排序最耗 CPU 的进程 PID 为 10765 步骤二：找到最耗 CPU 的线程工具：top方法： top -Hp 10765 ，显示一个进程的线程运行信息列表 键入 P (大写 p)，线程按照 CPU 使用率排序，进程 10765 内，最耗 CPU 的线程 PID 为 10804 步骤三：将线程 PID 转化为 16 进制工具：printf 方法：printf “%x\n” 10804 ，10804 对应的 16 进制是 0x2a34，当然，这一步可以用计算器。 之所以要转化为 16 进制，是因为堆栈里，线程 id 是用 16 进制表示的。 步骤四：查看堆栈，找到线程在干嘛工具：pstack/jstack/grep方法：jstack 10765 | grep ‘0x2a34’ -C5 –color 打印进程堆栈 通过线程 id，过滤得到线程堆栈找到了耗 CPU 高的线程对应的线程名称 “AsyncLogger-1”，以及看到了该线程正在执行代码的堆栈。希望对经常进行线上 CPU 问题排查的同学有帮助，如果有更好的实践，也欢迎分享。 想要印象深刻，请大家务必线上实操练习哟。]]></content>
      <tags>
        <tag>实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何优雅的使用和理解线程池]]></title>
    <url>%2F1328518056%2F</url>
    <content type="text"><![CDATA[前言平时接触过多线程开发的童鞋应该都或多或少了解过线程池，之前发布的《阿里巴巴 Java 手册》里也有一条： 可见线程池的重要性。 简单来说使用线程池有以下几个目的： 线程是稀缺资源，不能频繁的创建。 解耦作用；线程的创建于执行完全分开，方便维护。 应当将其放入一个池子中，可以给其他任务进行复用。 线程池原理谈到线程池就会想到池化技术，其中最核心的思想就是把宝贵的资源放到一个池子中；每次使用都从里面获取，用完之后又放回池子供其他人使用，有点吃大锅饭的意思。 那在 Java 中又是如何实现的呢？ 在 JDK 1.5 之后推出了相关的 api，常见的创建线程池方式有以下几种： Executors.newCachedThreadPool()：无限线程池。 Executors.newFixedThreadPool(nThreads)：创建固定大小的线程池。 Executors.newSingleThreadExecutor()：创建单个线程的线程池。 其实看这三种方式创建的源码就会发现： 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 实际上还是利用 ThreadPoolExecutor 类实现的。 所以我们重点来看下 ThreadPoolExecutor 是怎么玩的。 首先是创建线程的 api： 1ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) 这几个核心参数的作用： corePoolSize 为线程池的基本大小。 maximumPoolSize 为线程池最大线程大小。 keepAliveTime 和 unit 则是线程空闲后的存活时间。 workQueue 用于存放任务的阻塞队列。 handler 当队列和最大线程池都满了之后的饱和策略。 了解了这几个参数再来看看实际的运用。 通常我们都是使用: 1threadPool.execute(new Job()); 这样的方式来提交一个任务到线程池中，所以核心的逻辑就是 execute() 函数了。 在具体分析之前先了解下线程池中所定义的状态，这些状态都和线程的执行密切相关： RUNNING 自然是运行状态，指可以接受任务执行队列里的任务 SHUTDOWN 指调用了 shutdown() 方法，不再接受新任务了，但是队列里的任务得执行完毕。 STOP 指调用了 shutdownNow() 方法，不再接受新任务，同时抛弃阻塞队列里的所有任务并中断所有正在执行任务。 TIDYING 所有任务都执行完毕，在调用 shutdown()/shutdownNow() 中都会尝试更新为这个状态。 TERMINATED 终止状态，当执行 terminated() 后会更新为这个状态。 用图表示为： 然后看看 execute() 方法是如何处理的： 获取当前线程池的状态。 当前线程数量小于 coreSize 时创建一个新的线程运行。 如果当前线程处于运行状态，并且写入阻塞队列成功。 双重检查，再次获取线程状态；如果线程状态变了（非运行状态）就需要从阻塞队列移除任务，并尝试判断线程是否全部执行完毕。同时执行拒绝策略。 如果当前线程池为空就新创建一个线程并执行。 如果在第三步的判断为非运行状态，尝试新建线程，如果失败则执行拒绝策略。 这里借助《聊聊并发》的一张图来描述这个流程： 如何配置线程流程聊完了再来看看上文提到了几个核心参数应该如何配置呢？ 有一点是肯定的，线程池肯定是不是越大越好。 通常我们是需要根据这批任务执行的性质来确定的。 IO 密集型任务：由于线程并不是一直在运行，所以可以尽可能的多配置线程，比如 CPU 个数 * 2 CPU 密集型任务（大量复杂的运算）应当分配较少的线程，比如 CPU 个数相当的大小。 当然这些都是经验值，最好的方式还是根据实际情况测试得出最佳配置。 优雅的关闭线程池有运行任务自然也有关闭任务，从上文提到的 5 个状态就能看出如何来关闭线程池。 其实无非就是两个方法 shutdown()/shutdownNow()。 但他们有着重要的区别： shutdown() 执行后停止接受新任务，会把队列的任务执行完毕。 shutdownNow() 也是停止接受新任务，但会中断所有的任务，将线程池状态变为 stop。 两个方法都会中断线程，用户可自行判断是否需要响应中断。 shutdownNow() 要更简单粗暴，可以根据实际场景选择不同的方法。 我通常是按照以下方式关闭线程池的： 123456789101112long start = System.currentTimeMillis();for (int i = 0; i &lt;= 5; i++) &#123; pool.execute(new Job());&#125;pool.shutdown();while (!pool.awaitTermination(1, TimeUnit.SECONDS)) &#123; LOGGER.info("线程还在执行。。。");&#125;long end = System.currentTimeMillis();LOGGER.info("一共处理了【&#123;&#125;】", (end - start)); pool.awaitTermination(1, TimeUnit.SECONDS) 会每隔一秒钟检查一次是否执行完毕（状态为 TERMINATED），当从 while 循环退出时就表明线程池已经完全终止了。 线程池隔离 线程池看似很美好，但也会带来一些问题。 如果我们很多业务都依赖于同一个线程池, 当其中一个业务因为各种不可控的原因消耗了所有的线程，导致线程池全部占满。 这样其他的业务也就不能正常运转了，这对系统的打击是巨大的。 比如我们 Tomcat 接受请求的线程池，假设其中一些响应特别慢，线程资源得不到回收释放；线程池慢慢被占满，最坏的情况就是整个应用都不能提供服务。 所以我们需要将线程池进行隔离。 通常的做法是按照业务进行划分： 比如下单的任务用一个线程池，获取数据的任务用另一个线程池。这样即使其中一个出现问题把线程池耗尽，那也不会影响其他的任务运行。 hystrix 隔离这样的需求 Hystrix 已经帮我们实现了。 Hystrix 是一款开源的容错插件，具有依赖隔离、系统容错降级等功能。 下面来看看 Hystrix 简单的应用： 首先需要定义两个线程池，分别用于执行订单、处理用户。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687/** * Function:订单服务 * */public class CommandOrder extends HystrixCommand&lt;String&gt; &#123; private final static Logger LOGGER = LoggerFactory.getLogger(CommandOrder.class); private String orderName; public CommandOrder(String orderName) &#123; super(Setter.withGroupKey( //服务分组 HystrixCommandGroupKey.Factory.asKey(&quot;OrderGroup&quot;)) //线程分组 .andThreadPoolKey(HystrixThreadPoolKey.Factory.asKey(&quot;OrderPool&quot;)) //线程池配置 .andThreadPoolPropertiesDefaults(HystrixThreadPoolProperties.Setter() .withCoreSize(10) .withKeepAliveTimeMinutes(5) .withMaxQueueSize(10) .withQueueSizeRejectionThreshold(10000)) .andCommandPropertiesDefaults( HystrixCommandProperties.Setter() .withExecutionIsolationStrategy(HystrixCommandProperties.ExecutionIsolationStrategy.THREAD)) ) ; this.orderName = orderName; &#125; @Override public String run() throws Exception &#123; LOGGER.info(&quot;orderName=[&#123;&#125;]&quot;, orderName); TimeUnit.MILLISECONDS.sleep(100); return &quot;OrderName=&quot; + orderName; &#125;&#125;/** * Function:用户服务 */public class CommandUser extends HystrixCommand&lt;String&gt; &#123; private final static Logger LOGGER = LoggerFactory.getLogger(CommandUser.class); private String userName; public CommandUser(String userName) &#123; super(Setter.withGroupKey( //服务分组 HystrixCommandGroupKey.Factory.asKey(&quot;UserGroup&quot;)) //线程分组 .andThreadPoolKey(HystrixThreadPoolKey.Factory.asKey(&quot;UserPool&quot;)) //线程池配置 .andThreadPoolPropertiesDefaults(HystrixThreadPoolProperties.Setter() .withCoreSize(10) .withKeepAliveTimeMinutes(5) .withMaxQueueSize(10) .withQueueSizeRejectionThreshold(10000)) //线程池隔离 .andCommandPropertiesDefaults( HystrixCommandProperties.Setter() .withExecutionIsolationStrategy(HystrixCommandProperties.ExecutionIsolationStrategy.THREAD)) ) ; this.userName = userName; &#125; @Override public String run() throws Exception &#123; LOGGER.info(&quot;userName=[&#123;&#125;]&quot;, userName); TimeUnit.MILLISECONDS.sleep(100); return &quot;userName=&quot; + userName; &#125;&#125; api 特别简洁易懂，具体详情请查看官方文档。 然后模拟运行： 1234567891011121314151617public static void main(String[] args) throws Exception &#123; CommandOrder commandPhone = new CommandOrder(&quot;手机&quot;); CommandOrder command = new CommandOrder(&quot;电视&quot;); //阻塞方式执行 String execute = commandPhone.execute(); LOGGER.info(&quot;execute=[&#123;&#125;]&quot;, execute); //异步非阻塞方式 Future&lt;String&gt; queue = command.queue(); String value = queue.get(200, TimeUnit.MILLISECONDS); LOGGER.info(&quot;value=[&#123;&#125;]&quot;, value); CommandUser commandUser = new CommandUser(&quot;张三&quot;); String name = commandUser.execute(); LOGGER.info(&quot;name=[&#123;&#125;]&quot;, name);&#125; 运行结果： 可以看到两个任务分成了两个线程池运行，他们之间互不干扰。 获取任务任务结果支持同步阻塞和异步非阻塞方式，可自行选择。 它的实现原理其实容易猜到： 利用一个 Map 来存放不同业务对应的线程池。 通过刚才的构造函数也能证明： 还要注意的一点是： 自定义的 Command 并不是一个单例，每次执行需要 new 一个实例，不然会报 This instance can only be executed once. Please instantiate a new instance. 异常。 总结池化技术确实在平时应用广泛，熟练掌握能提高不少效率。]]></content>
      <tags>
        <tag>multi-thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解B树,B+树特点及使用场景]]></title>
    <url>%2F1643632136%2F</url>
    <content type="text"><![CDATA[读完本文你将了解： B 树 对比平衡二叉树和 B 树 B 树中如何查找数据 B 树如何保证平衡 使用场景 B+ 树 Thanks 大家好，前面那篇文章《3 分钟理解完全二叉树、平衡二叉树、二叉查找树》中我们了解了几种特殊的二叉树的功能及特点，知道了它们在进行查找数据时可以提高效率，但需要注意的是，这是指在内存中进行查找。如果有海量的数据，不可能一次性读取到内存中，这时候就要考虑的是，如何在磁盘中快速找到需要的数据。 今天这篇文章中要介绍的 “B 树、B+ 树”，他们的使用场景是：查找磁盘中的大量数据。 B 树B 树就是常说的 “B 减树（B- 树）”，又名平衡多路（即不止两个子树）查找树，它和平衡二叉树的不同有这么几点： 平衡二叉树节点最多有两个子树，而 B 树每个节点可以有多个子树，M 阶 B 树表示该树每个节点最多有 M 个子树 平衡二叉树每个节点只有一个数据和两个指向孩子的指针，而 B 树每个中间节点有 k-1 个关键字（可以理解为数据）和 k 个子树（ **k 介于阶数 M 和 M/2 之间，M/2 向上取整） B 树的所有叶子节点都在同一层，并且叶子节点只有关键字，指向孩子的指针为 null 和平衡二叉树相同的点在于：B 树的节点数据大小也是按照左小右大，子树与节点的大小比较决定了子树指针所处位置。 看着概念可能有点难理解，来看看图对比下平衡二叉树和 B 树。 对比平衡二叉树和 B 树首先是节点， 平衡二叉树的节点如下图所示，每个节点有一个数据和最多两个子树： B 树中的每个节点由两部分组成： 关键字（可以理解为数据） 指向孩子节点的指针 B 树的节点如下图所示，每个节点可以有不只一个数据，同时拥有数据数加一个子树，同时每个节点左子树的数据比当前节点都小、右子树的数据都比当前节点的数据大： 上图是为了方便读者理解 B 树每个节点的内容，实际绘制图形还是以圆表示每个节点。 了解了节点的差异后，来看看 B 树的定义，一棵 B 树必须满足以下条件： 若根结点不是终端结点，则至少有 2 棵子树 除根节点以外的所有非叶结点至少有 M/2 棵子树，至多有 M 个子树（关键字数为子树减一） 所有的叶子结点都位于同一层 用一张图对比平衡二叉树和 B 树： 可以看到，B 树的每个节点可以表示的信息更多，因此整个树更加 “矮胖”，这在从磁盘中查找数据（先读取到内存、后查找）的过程中，可以减少磁盘 IO 的次数，从而提升查找速度。 B 树中如何查找数据因为 B 树的子树大小排序规则，因此在 B 树中查找数据时，一般需要这样： 从根节点开始，如果查找的数据比根节点小，就去左子树找，否则去右子树 和子树的多个关键字进行比较，找到它所处的范围，然后去范围对应的子树中继续查找 以此循环，直到找到或者到叶子节点还没找到为止 B 树如何保证平衡我们知道，平衡的树之所以能够加快查找速度，是因为在添加、删除的时候做了某些操作以保证平衡。 平衡二叉树的平衡条件是：左右子树的高度差不大于 1；而 B 树的平衡条件则有三点： 叶子节点都在同一层 每个节点的关键字数为子树个数减一（子树个数 k 介于树的阶 M 和它的二分之一 子树的关键字保证左小右大的顺序 也就是说，一棵 3 阶的 B 树（即节点最多有三个子树），每个节点的关键字数最少为 1，最多为 2，如果要添加数据的子树的关键字数已经是最多，就需要拆分节点，调整树的结构。 网上找到一张很不错的动图，我们来根据它分析下 B 树添加元素时如何保证平衡。 这个图用以表示往 4 阶 B 树中依次插入下面这组数据的过程： 6 10 4 14 5 11 15 3 2 12 1 7 8 8 6 3 6 21 5 15 15 6 32 23 45 65 7 8 6 5 4 建议放大图查看。 由于我比较懒，我们来根据前几步分析下 B 树的添加流程： 首先明确：4 阶 B 树表示每个节点最多有 4 个子树、3 个关键字，最少有 2 个子树、一个关键字 添加 6，第一个节点，没什么好说的 添加 10，根节点最多能放三个关键字，按顺序添到根节点中 添加 4，还能放到根节点中 添加 14，这时超出了关键字最大限制，需要把 14 添加为子树，同时为了保证 “所有叶子节点在同一层”，就需要拆几个关键字作为子树： 拆为： 这个拆的过程比较复杂，首先要确定根节点保留几个关键字，由于 “非叶子节点的根节点至少有 2 棵子树” 的限制，那就至少需要两个关键字分出去，又因为 “子树数是关键字数 + 1”，如果根节点有两个关键字，就得有三个子树，无法满足，所以只好把除 6 以外的三个关键字都拆为子树。 谁和谁在一个子树上呢，根据 “左子树比关键字小、右子树比关键字大” 的规律，4 在左子树，10 和 14 在右子树。 继续添加 ： 添加 5，放到 4 所在的子树上 添加 11，放在 10 和 14 所在的右子树上 添加 15，按大小应该放到 10、11 和 14 所在的子树上，但因为超过了关键字数限制，又得拆分 因为 “根节点必须都在同一层”，因此我们不能给现有的左右子树添加子树，只能添加给 6 了；但是如果 6 有三个子树，就必须得有 2 个关键字，提升谁做关键字好呢，这得看谁做 6 中间的子树，因为右子树的所有关键字都得比父节点的关键字大，所以这个提升的关键字只能比未来右子树中的关键字都小，那就只有 10 和 11 可以考虑了。 提升 10 吧，没有比它小的做子树，那就只能提升 11 了： 再添加元素也是类似的逻辑： 首先考虑要插入的子树是否已经超出了关键字数的限制 超出的话，如果要插入的位置是叶子节点，就只能拆一个关键字添加到要插入位置的父节点 如果非叶子节点，就得从其他子树拆子树给新插入的元素做孩子 删除也是一样的，要考虑删除孩子后，父节点是否还满足子树 k 介于 M/2 和 M 的条件，不满足就得从别的节点拆子树甚至修改相关子树结构来保持平衡。 总之添加、删除的过程很复杂，要考虑的条件很多，具体实现就不细追究了，这里我们有个基本认识即可。 正是这个复杂的保持平衡操作，使得平衡后的 B 树能够发挥出磁盘中快速查找的作用。 使用场景 这部分摘自：浅谈算法和数据结构：平衡查找树之 B 树 文件系统和数据库系统中常用的 B/B+ 树，他通过对每个节点存储个数的扩展，使得对连续的数据能够进行较快的定位和访问，能够有效减少查找时间，提高存储的空间局部性从而减少 IO 操作。他广泛用于文件系统及数据库中，如： Windows：HPFS 文件系统 Mac：HFS，HFS+ 文件系统 Linux：ResiserFS，XFS，Ext3FS，JFS 文件系统 数据库：ORACLE，MYSQL，SQLSERVER 等中 数据库：ORACLE，MYSQL，SQLSERVER 等中 B+ 树 这部分主要学习自 “程序员小灰” 的 漫画：什么是 B + 树？ 了解了 B 树后再来了解下它的变形版：B+ 树，它比 B 树的查询性能更高。 一棵 B+ 树需要满足以下条件： 节点的子树数和关键字数相同（B 树是关键字数比子树数少一） 节点的关键字表示的是子树中的最大数，在子树中同样含有这个数据 叶子节点包含了全部数据，同时符合左小右大的顺序 简单概括下 B+ 树的三个特点： 关键字数和子树相同 非叶子节点仅用作索引，它的关键字和子节点有重复元素 叶子节点用指针连在一起 首先第一点不用特别介绍了，在 B 树中，节点的关键字用于在查询时确定查询区间，因此关键字数比子树数少一；而在 B+ 树中，节点的关键字代表子树的最大值，因此关键字数等于子树数。 第二点，除叶子节点外的所有节点的关键字，都在它的下一级子树中同样存在，最后所有数据都存储在叶子节点中。 根节点的最大关键字其实就表示整个 B+ 树的最大元素。 第三点，叶子节点包含了全部的数据，并且按顺序排列，B+ 树使用一个链表将它们排列起来，这样在查询时效率更快。 由于 B+ 树的中间节点不含有实际数据，只有子树的最大数据和子树指针，因此磁盘页中可以容纳更多节点元素，也就是说同样数据情况下，B+ 树会 B 树更加 “矮胖”，因此查询效率更快。 B+ 树的查找必会查到叶子节点，更加稳定。 有时候需要查询某个范围内的数据，由于 B+ 树的叶子节点是一个有序链表，只需在叶子节点上遍历即可，不用像 B 树那样挨个中序遍历比较大小。 B+ 树的三个优点： 层级更低，IO 次数更少 每次都需要查询到叶子节点，查询性能稳定 叶子节点形成有序链表，范围查询方便 添加过程就不深入研究了，后面用到再看吧，这里先贴一个 B+ 树动态添加元素图： Thanks www.zhihu.com/question/30… zhuanlan.zhihu.com/p/27700617 mp.weixin.qq.com/s/jRZMMONW3… blog.jobbole.com/79311/]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类加载器与双亲委派模型]]></title>
    <url>%2F3288749768%2F</url>
    <content type="text"><![CDATA[类加载器加载类的开放性类加载器（ClassLoader）是 Java 语言的一项创新，也是 Java 流行的一个重要原因。在类加载的第一阶段 “加载” 过程中，需要通过一个类的全限定名来获取定义此类的二进制字节流，完成这个动作的代码块就是类加载器。这一动作是放在 Java 虚拟机外部去实现的，以便让应用程序自己决定如何获取所需的类。 虚拟机规范并没有指明二进制字节流要从一个 Class 文件获取，或者说根本没有指明从哪里获取、怎样获取。这种开放使得 Java 在很多领域得到充分运用，例如： 从 ZIP 包中读取，这很常见，成为 JAR，EAR，WAR 格式的基础 从网络中获取，最典型的应用就是 Applet 运行时计算生成，最典型的是动态代理技术，在 java.lang.reflect.Proxy 中，就是用了 ProxyGenerator.generateProxyClass 来为特定接口生成形式为 “*$Proxy” 的代理类的二进制字节流 有其他文件生成，最典型的 JSP 应用，由 JSP 文件生成对应的 Class 类…… 类加载器与类的唯一性类加载器虽然只用于实现类的加载动作，但是对于任意一个类，都需要由加载它的类加载器和这个类本身共同确立其在 Java 虚拟机中的唯一性。通俗的说，JVM 中两个类是否 “相等”，首先就必须是同一个类加载器加载的，否则，即使这两个类来源于同一个 Class 文件，被同一个虚拟机加载，只要类加载器不同，那么这两个类必定是不相等的。 这里的 “相等”，包括代表类的 Class 对象的 equals() 方法、isAssignableFrom()方法、isInstance()方法的返回结果，也包括使用 instanceof 关键字做对象所属关系判定等情况。 以下代码说明了不同的类加载器对 instanceof 关键字运算的结果的影响。 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.jvm.classloading;import java.io.IOException;import java.io.InputStream;/** * 类加载器在类相等判断中的影响 * * instanceof关键字 * */public class ClassLoaderTest &#123; public static void main(String[] args) throws Exception &#123; // 自定义类加载器 ClassLoader myLoader = new ClassLoader() &#123; @Override public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; try &#123; String fileName = name.substring(name.lastIndexOf(".") + 1) + ".class"; InputStream is = getClass().getResourceAsStream(fileName); if (is == null) &#123; return super.loadClass(fileName); &#125; byte[] b = new byte[is.available()]; is.read(b); return defineClass(name, b, 0, b.length); &#125; catch (IOException e) &#123; throw new ClassNotFoundException(); &#125; &#125; &#125;; // 使用ClassLoaderTest的类加载器加载本类 Object obj1 = ClassLoaderTest.class.getClassLoader().loadClass("com.jvm.classloading.ClassLoaderTest").newInstance(); System.out.println(obj1.getClass()); System.out.println(obj1 instanceof com.jvm.classloading.ClassLoaderTest); // 使用自定义类加载器加载本类 Object obj2 = myLoader.loadClass("com.jvm.classloading.ClassLoaderTest").newInstance(); System.out.println(obj2.getClass()); System.out.println(obj2 instanceof com.jvm.classloading.ClassLoaderTest); &#125;&#125; 输出结果： 1234class com.jvm.classloading.ClassLoaderTesttrueclass com.jvm.classloading.ClassLoaderTestfalse myLoader 是自定义的类加载器，可以用来加载与自己在同一路径下的 Class 文件。main 函数的第一部分使用系统加载主类 ClassLoaderTest 的类加载器加载 ClassLoaderTest，输出显示，obj1 的所属类型检查正确，这是虚拟机中有 2 个 ClassLoaderTest 类，一个是主类，另一个是 main() 方法中加载的类，由于这两个类使用同一个类加载器加载并且来源于同一个 Class 文件，因此这两个类是完全相同的。 第二部分使用自定义的类加载器加载 ClassLoaderTest，class com.jvm.classloading.ClassLoderTest显示，obj2 确实是类com.jvm.classloading.ClassLoaderTest实例化出来的对象，但是第二句输出 false。此时虚拟机中有 3 个 ClassLoaderTest 类，由于第 3 个类的类加载器与前面 2 个类加载器不同，虽然来源于同一个 Class 文件，但它是一个独立的类，所属类型检查是返回结果自然是 false。 双亲委派模型类加载器种类从 Java 虚拟机的角度来说，只存在两种不同的类加载器：一种是启动类加载器（Bootstrap ClassLoader），这个类加载器使用 C++ 语言实现（HotSpot 虚拟机中），是虚拟机自身的一部分；另一种就是所有其他的类加载器，这些类加载器都有 Java 语言实现，独立于虚拟机外部，并且全部继承自 java.lang.ClassLoader。 从开发者的角度，类加载器可以细分为： 启动（Bootstrap）类加载器：负责将 Java_Home/lib 下面的类库加载到内存中（比如 rt.jar）。由于引导类加载器涉及到虚拟机本地实现细节，开发者无法直接获取到启动类加载器的引用，所以不允许直接通过引用进行操作。 标准扩展（Extension）类加载器：是由 Sun 的 ExtClassLoader（sun.misc.Launcher$ExtClassLoader）实现的。它负责将 Java_Home /lib/ext 或者由系统变量 java.ext.dir 指定位置中的类库加载到内存中。开发者可以直接使用标准扩展类加载器。 应用程序（Application）类加载器：是由 Sun 的 AppClassLoader（sun.misc.Launcher$AppClassLoader）实现的。它负责将系统类路径（CLASSPATH）中指定的类库加载到内存中。开发者可以直接使用系统类加载器。由于这个类加载器是 ClassLoader 中的 getSystemClassLoader() 方法的返回值，因此一般称为系统（System）加载器。 除此之外，还有自定义的类加载器，它们之间的层次关系被称为类加载器的双亲委派模型。该模型要求除了顶层的启动类加载器外，其余的类加载器都应该有自己的父类加载器，而这种父子关系一般通过组合（Composition）关系来实现，而不是通过继承（Inheritance）。 双亲委派模型双亲委派模型过程 某个特定的类加载器在接到加载类的请求时，首先将加载任务委托给父类加载器，依次递归，如果父类加载器可以完成类加载任务，就成功返回；只有父类加载器无法完成此加载任务时，才自己去加载。 使用双亲委派模型的好处在于 Java 类随着它的类加载器一起具备了一种带有优先级的层次关系。例如类 java.lang.Object，它存在在 rt.jar 中，无论哪一个类加载器要加载这个类，最终都是委派给处于模型最顶端的 Bootstrap ClassLoader 进行加载，因此 Object 类在程序的各种类加载器环境中都是同一个类。相反，如果没有双亲委派模型而是由各个类加载器自行加载的话，如果用户编写了一个 java.lang.Object 的同名类并放在 ClassPath 中，那系统中将会出现多个不同的 Object 类，程序将混乱。因此，如果开发者尝试编写一个与 rt.jar 类库中重名的 Java 类，可以正常编译，但是永远无法被加载运行。 双亲委派模型的系统实现 在 java.lang.ClassLoader 的 loadClass() 方法中，先检查是否已经被加载过，若没有加载则调用父类加载器的 loadClass() 方法，若父加载器为空则默认使用启动类加载器作为父加载器。如果父加载失败，则抛出 ClassNotFoundException 异常后，再调用自己的 findClass() 方法进行加载。 12345678910111213141516171819202122protected synchronized Class&lt;?&gt; loadClass(String name,boolean resolve)throws ClassNotFoundException&#123; //check the class has been loaded or not Class c = findLoadedClass(name); if(c == null)&#123; try&#123; if(parent != null)&#123; c = parent.loadClass(name,false); &#125;else&#123; c = findBootstrapClassOrNull(name); &#125; &#125;catch(ClassNotFoundException e)&#123; //if throws the exception ,the father can not complete the load &#125; if(c == null)&#123; c = findClass(name); &#125; &#125; if(resolve)&#123; resolveClass(c); &#125; return c;&#125; 注意，双亲委派模型是 Java 设计者推荐给开发者的类加载器的实现方式，并不是强制规定的。大多数的类加载器都遵循这个模型，但是 JDK 中也有较大规模破坏双亲模型的情况，例如线程上下文类加载器（Thread Context ClassLoader）的出现，具体分析可以参见周志明著《深入理解 Java 虚拟机》。 参考1、周志明，深入理解 Java 虚拟机：JVM 高级特性与最佳实践，机械工业出版社2、Alexia(minmin) 博客，http://www.cnblogs.com/lanxuezaipiao/p/4138511.html]]></content>
      <tags>
        <tag>jvm</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单例模式–双重检验锁真的线程安全吗]]></title>
    <url>%2F766337335%2F</url>
    <content type="text"><![CDATA[单例模式–双重检验锁真的线程安全吗单例模式是我们最熟悉不过的一种设计模式，用来保证内存中只有一个对象的实例。虽然容易，但里面的坑也有很多，比如双重检验锁模式 (double checked locking pattern) 真的是线程安全的吗？ 起因在对项目进行 PMD 静态代码检测时，遇到了这样一个问题 Partially created objects can be returned by the Double Checked Locking pattern when used in Java. An optimizing JRE may assign a reference to the baz variable before it calls the constructor of the object the reference points to. Note: With Java 5, you can make Double checked locking work, if you declare the variable to be volatile. 大概意思是，使用双重检验锁模式，可能会返回一个部分初始化的对象。可能大家有些疑虑，什么是部分初始化的对象，我们下面继续分析 什么是双重检验锁模式12345678910public static Singleton getSingleton() &#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance;&#125; 我们看到，在同步代码块的内部和外部都判断了 instance == null，这时因为，可能会有多个线程同时进入到同步代码块外的 if 判断中，如果在同步代码块内部不进行判空的话，可能会初始化多个实例。 问题所在这种写法看似完美无缺，但它却是有问题的，或者说它并不担保一定完美无缺。主要原因在于 instance = new Singleton(); 并不是原子性的操作。创建一个对象可以分为三部： 1231.分配对象的内存空间2.初始化对象3.设置instance指向刚分配的内存地址,当instance指向分配地址时，instance不为空 但是，2、3 步之间，可能会被重排序，造成创建对象顺序变为 1-3-2. 试想一个场景：线程 A 第一次创建对象 Singleton，对象创建顺序为 1-3-2；当给 instance 分配完内存后，这时来了一个线程 B 调用了 getSingleton() 方法这时候进行 instance == null 的判断，发现 instance 并不为 null。但注意这时候 instance 并没有初始化对象，线程 B 则会将这个未初始化完成的对象返回。那 B 线程使用 instance 时就可能会出现问题，这就是双重检查锁问题所在。 使用 volatile对于上述的问题，我们可以通过把 instance 声明为 volatile 型来解决 1234567891011121314public class Singleton &#123; private volatile static Singleton instance; public static Singleton getSingleton() &#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 有些人认为使用 volatile 的原因是可见性，也就是可以保证线程在本地不会存有 instance 的副本，每次都是去主内存中读取。但其实是不对的。使用 volatile 的主要原因是其另一个特性：禁止指令重排序优化。也就是说，在 volatile 变量的赋值操作后面会有一个内存屏障，读操作不会被重排序到内存屏障之前。比如上面的例子，取操作必须在执行完 1-2-3 之后或者 1-3-2 之后，不存在执行到 1-3 然后取到值的情况。从「先行发生原则」的角度理解的话，就是对于一个 volatile 变量的写操作都先行发生于后面对这个变量的读操作（这里的“后面”是时间上的先后顺序. 但是特别注意在 Java 5 以前的版本使用了 volatile 的双检锁还是有问题的。其原因是 Java 5 以前的 JMM （Java 内存模型）是存在缺陷的，即时将变量声明成 volatile 也不能完全避免重排序，主要是 volatile 变量前后的代码仍然存在重排序问题。这个 volatile 屏蔽重排序的问题在 Java 5 中才得以修复，所以在这之后才可以放心使用 volatile。 必须在 JDK5 版本以上使用。 静态内部类123456789101112public class Singleton &#123; private static class SingletonHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; private Singleton() &#123; &#125; public static final Singleton getInstance() &#123; return SingletonHolder.INSTANCE; &#125;&#125; 这种写法是目前比较推荐的一种写法，采用静态内部类的方式，即实现了懒加载又不会出现线程安全问题。而且减少了 synchronized 的开销。 Learn more双重检查锁定与延迟初始化PMD-DoubleCheckedLockingDouble-checked locking: Clever, but broken]]></content>
      <tags>
        <tag>java</tag>
        <tag>multi-thread</tag>
      </tags>
  </entry>
</search>
