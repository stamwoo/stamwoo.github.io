<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[分布式锁的实现-mysql&redis]]></title>
    <url>%2F1727393489%2F</url>
    <content type="text"><![CDATA[曾经我在一场真实面试中被问到分布式锁的实现,只能简单回答上来根据redis的setnx去做,而不知这里面其实还有很多坑.也不知是否还有其他方式.面试结束后就有了下文. 分布式锁在单进程环境中,当多个线程产生资源竞争时.程序员们会采用 Synchronize 或 Lock 去对临界资源进行加锁,使得在修改临界资源时,能够线性执行以消除并发.那么由于多线程是挂在同一个进程下的,我们就必须在这个进程内设置一个标记变量,来让所有线程都可以发现.而在分布式环境下,多进程可能会产生资源竞争,那么此时的锁就应该存放在多进程都能够看到的地方.由此我们想到了两种方式:数据库和redis. 基于数据库基于数据库的锁实现也有两种方式，一是基于数据库表，另一种是基于数据库排他锁。 基于数据库表的增删基于数据库表增删是最简单的方式，首先创建一张锁的表主要包含下列字段：方法名，时间戳等字段。 具体使用的方法，当需要锁住某个方法时，往该表中插入一条相关的记录。这边需要注意，方法名是有唯一性约束的，如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。 执行完毕，需要delete该记录。 当然，笔者这边只是简单介绍一下。对于上述方案可以进行优化，如应用主从数据库，数据之间双向同步。一旦挂掉快速切换到备库上；做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍；使用while循环，直到insert成功再返回成功，虽然并不推荐这样做；还可以记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了，实现可重入锁。 基于数据库排他锁在查询语句后面增加for update，数据库会在查询过程中给数据库表增加排他锁。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。其他没有获取到锁的就会阻塞在上述select语句上，可能的结果有2种，在超时之前获取到了锁，在超时之前仍未获取到锁。 获得排它锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，释放锁connection.commit()。 存在的问题主要是性能不高和sql超时的异常。 基于数据库的优缺点上面两种方式都是依赖数据库的一张表，一种是通过表中的记录的存在情况确定当前是否有锁存在，另外一种是通过数据库的排他锁来实现分布式锁。 优点是直接借助数据库，简单容易理解。 缺点是操作数据库需要一定的开销，性能问题需要考虑。 基于 redisSETNX 加锁使用redis的SET命令实现分布式锁，多个进程执行以下Redis命令： 1SET key value PX time NX 这条命令是当key不存在时,将字符串值value关联到key,并设置过期时间为time毫秒. 返回1，说明该进程获得锁. 返回0，说明其他进程已经获得了锁，进程不能进入临界区。进程可以在一个循环中不断地尝试 SET 操作，以获得锁。 解锁解锁很简单,直接把key删除就可以了.但是考虑一种情况. 进程A设置了一个较短的过期时间,在还未执行完之前锁已经过期被释放了.此时进程B拿到了锁进来,而A刚好又将锁删除.那这样由于过期时间设置过短,直接造成了所有redis锁失效. 为了避免这种情况,即错误删除了并非自己加的锁.我们需要在SET锁时,将UUID设置为value.在删除之前先确认这把锁是由自己加的,那么就需要有一个get的操作. 那因为get和del并不是原子操作,我们就需要采用lua脚本来保证原子性. 死锁问题死锁问题即由设置过期时间来解决,但过期时间设置会存在一个问题: 当锁过期后，该进程还没执行完，可能造成同时多个进程取得锁。 另一种redis 加解锁方式-getset我们同样假设进程P1已经首先获得了锁 lock.foo，然后进程P1挂掉了。接下来的情况： 进程P4执行 SETNX lock.foo 以尝试获取锁 由于进程P1已获得了锁，所以P4执行 SETNX lock.foo 返回0，即获取锁失败 P4执行 GET lock.foo 来检测锁是否已超时，如果没超时，则等待一段时间，再次检测 如果P4检测到锁已超时，即当前的时间大于键 lock.foo 的值，P4会执行以下操作 1GETSET lock.foo &lt;current Unix timestamp + lock timeout + 1&gt; 由于 GETSET 操作在设置键的值的同时，还会返回键的旧值，通过比较键 lock.foo 的旧值是否小于当前时间，可以判断进程是否已获得锁 假如另一个进程P5也检测到锁已超时，并在P4之前执行了 GETSET 操作，那么P4的 GETSET 操作返回的是一个大于当前时间的时间戳，这样P4就不会获得锁而继续等待。注意到，即使P4接下来将键 lock.foo 的值设置了比P5设置的更大的值也没影响。 参考 http://redisdoc.com/string/set.htmlhttps://www.cnblogs.com/crossoverJie/p/9339354.htmlhttps://juejin.im/entry/5a502ac2518825732b19a595https://blog.csdn.net/jj546630576/article/details/74910343]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈面试时从写一个单例开始究竟能问多深及终极解决方案]]></title>
    <url>%2F421584197%2F</url>
    <content type="text"><![CDATA[转 http://www.cnblogs.com/xiexj/p/6845029.html 看了左潇龙的《回答阿里社招面试如何准备，顺便谈谈对于 Java 程序猿学习当中各个阶段的建议》这篇文章，在想一个问题，从一个最简单的问题入手究竟能把问题问多深？下面就模拟一场面试问答，要是我是面试官，大概就只能问到下面的深度了。 旁白：一般的面试都是从最简单基本的问题开始。 面试官：请在黑板上写出一个线程安全的单例模式的例子。 面试者： 其实线程安全的实现有很多种，根据业务场景可以 new 一个实例作为私有静态成员变量，这样程序一启动，实例就生成，私有化构造函数，利用公用的静态函数 getInstance 返回实例。这种预加载的是能保证线程安全的但是如果不是确定会被使用，会造成内存的浪费，所以可以将实例放到私有静态类中作为成员变量。下面只写一种利用锁机制来保证的懒加载方法。 public class Singleton { private volatile static Singleton singleton; private Singleton (){} public static Singleton getSingleton() { if (singleton == null) { synchronized (Singleton.class) { if (singleton == null) { singleton = new Singleton(); } } } return singleton; } } 或者 public class Singleton{ private static Singletoninstance = new Singleton(); private Singleton(){} public static Singleton getInstance() { return instance; } } 旁白：从这个例子上我能想到的知识点主要有三个 ☆ volatile 关键字，可深入到 Java VM 内存相关 ☆ synchronized 关键字，可深入到 Java 锁机制，高并发相关 ☆ new 关键字，可深入到 Java VM 类加载机制相关 但是面试官一开始可能要先考察一下面试者是否真的理解自己写的代码 面试官：你写的这个程序是怎么保证线程安全的？ 面试者：将类的构造方法私有起来，外部调用进行初始化的时候只能通过调用 getSingleton 这个静态方法来获得实例，静态方法是整个 Java 虚拟机中只有一个实例。在创建的时候首先进行非空判断，这时候如果实例不存在，对整个类进行加锁同步，为了避免过程中非空状态的改变，同步块内再进行一次判断，如果不存在实例则创建实例返回。使用 volatile 关键字，下次访问这个方法就能直接看到实例的最新非空状态，直接返回实例。 面试官：volatile 起到了什么作用？ 面试者：volatile 这个英文单词意思是易变的，用在多线程中来同步变量。Java 的对象都是在内存堆中分配空间。但是 Java 有主内存和线程自己独有的内存拷贝。对于没有 volatile 修饰的局部变量，线程在运行过程中访问的是工作内存中的变量值，其修改对于主内存不是立即可见。而 volatile 修饰的值在线程独有的工作内存中无副本，线程直接和主内存交互，修改对主内存立即可见。 面试官：synchronized 起到了什么作用？ 面试者：锁定对象，限制当前对象只能被一个线程访问。 面试官：synchronized 里你传 Singleton.class 这个参数，起到什么作用，换成别的行不行？ 面试者：对当前类加锁，使得这个代码块一次只能被一个线程访问。这里 Singleton.class 可以换成一个常量字符串或者自己定义一个内部静态 Object。 面试官：那传 Singleton.class，常量字符串，自己定义一个内部静态 Object 有区别吗？ 面试者：因为这是一个静态方法，相当于一个概念上的类锁，所以在这里起到的效果是一样的。但是如果是原型模式，或者直接每个类都是 new 出来的，实例不同的话，在一个非静态方法里加这三种锁，这时是一个对象锁，因为 Singleton.class 或者是静态的一个 Object 或者是 JVM 只存一份的字符串常量，这些对象线程间是共享的，会对所有的实例的同步块都加同一把锁，每个实例访问到此对象的同步代码块都会被阻塞。但是如果这时 synchronized 的参数是 this，或者是内部 new 出来的一个内部非静态 Object，则各个实例拥有不同的锁，访问同一个代码相同同步块也是互不干扰。只有实例内部使用了同一个对象锁才会同步等待。 面试官：那你知道 synchronized 关键字实现同步的原理吗？ 面试者：synchronized 在 Java 虚拟机中使用监视器锁来实现。每个对象都有一个监视器锁，当监视器锁被占用时就会处于锁定状态。 线程执行一条叫 monitorenter 的指令来获取监视器锁的所有权。如果此监视器锁的进入数为 0，则线程进入并将进入数设置为 1，成为线程所有者。如果线程已经拥有该锁，因为是可重入锁，可以重新进入，则进入数加 1. 如果线程的监视器锁被其他线程占用，则阻塞直到此监视器锁的进入数为 0 时才能进入该锁。 线程执行一条叫 monitorexit 的指令来释放所有权。执行 monitorexit 的必须是线程的所有者。每次执行此指令，线程进入数减 1，直到进入数为 0。监视器锁被释放。 面试官：你刚才提到的可重入锁是什么概念，有不可重入锁吗？ 面试者：我说的可重入锁是广义的可重入锁，当然 jdk1.5 引入了 concurrent 包，里面有 Lock 接口，它有一个实现叫 ReentrantLock。广义的可重入锁也叫递归锁，是指同一线程外层函数获得锁之后，内层还可以再次获得此锁。可重入锁的设计是为了避免死锁。sun 的 corba 里的 mutex 互斥锁是一种不可重入锁的实现。自旋锁也是一种不可重入锁，本质上是一种忙等锁，CPU 一直循环执行 “测试并设置” 直到可用并取得该锁，在递归的调用该锁时必然会引起死锁。另外，如果锁占用时间较长，自旋锁会过多的占用 CPU 资源，这时使用基于睡眠原理来实现的锁更加合适。 面试官：你刚才提到了 concurrent 包，它里面有哪些锁的实现？ 面试者：常用的有 ReentrantLock, 它是一种独占锁。ReadWriteLock 接口也是一个锁接口，和 Lock 接口是一种关联关系，它返回一个只读的 Lock 和只写的 Lock。读写分离，在没有写锁的情况下，读锁是无阻塞的，提高了执行效率，它是一种共享锁。ReadWriteLock 的实现类为 ReentrantReadWriteLock。ReentrantLock 和 ReentrantReadWriteLock 实现都依赖于 AbstractQueuedSynchronizer 这种抽象队列同步器。 面试官：锁还有其他维度的分类吗？ 面试者：还可以分为公平锁和非公平锁。非公平锁是如果一个线程尝试获取锁时可以获取锁，就直接成功获取。公平锁则在锁被释放后将锁分配给等待队列队首的线程。 面试官：AQS 是什么？ 面试者：AQS 是一个简单的框架，这个框架为同步状态的原子性管理，线程的阻塞和非阻塞以及排队提供了一种通用机制。表现为一个同步器，主要支持获取锁和释放锁。获取锁的时候如果是独占锁就有可能阻塞，如果是共享锁就有可能失败。如果是阻塞，线程就要进入阻塞队列，当状态变成可获得锁就修改状态，已进入阻塞队列的要从阻塞队列中移除。释放锁时修改状态位及唤醒其他被阻塞的线程。 AQS 本质是采用 CHL 模型完成了一个先进先出的队列。对于入队，采用 CAS 操作，每次比较尾节点是否一致，然后插入到尾节点中。对于出队列，因为每个节点缓存了一个状态位，不满足条件时自旋等待，直到满足条件时将头节点设置为下一个节点。 面试官：那知道这个队列的数据结构吗？ 面试者：这个队列是用一个双向链表实现的。 面试官：你刚才提到 AQS 是一种通用机制，那它还有哪些应用? 面试者：AQS 除了刚才提到的可重入锁 ReentrantLock 和 ReentrantReadWriteLock 之外，还用于不可重入锁 Mutex 的实现。java 并发包中的同步器如：Semphore,CountDownLatch,FutureTask,CyclicBarrier 都是采用这个机制实现的。 旁白：既然问到了并发工具包中的东西，每个都可以引出一堆，但是基本原理已经问出来了，其他的问下去没什么意思。转向下一个问题。 面试官：你黑板上写的实例是通过 new 对象创建出来的，还可不可以采用别的方法来创建对象呢？ 面试者：还可以使用 class 类的 newInstance 方法，Constructor 构造器类的 newInstance 方法，克隆方法和反序列法方法。 面试官：两种 newInstance 方法有没有区别？ 面试者： ☆ Class 类位于 java 的 lang 包中，而构造器类是 java 反射机制的一部分。 ☆ Class 类的 newInstance 只能触发无参数的构造方法创建对象，而构造器类的 newInstance 能触发有参数或者任意参数的构造方法来创建对象。 ☆ Class 类的 newInstance 需要其构造方法是共有的或者对调用方法可见的，而构造器类的 newInstance 可以在特定环境下调用私有构造方法来创建对象。 ☆ Class 类的 newInstance 抛出类构造函数的异常，而构造器类的 newInstance 包装了一个 InvocationTargetException 异常。 Class 类本质上调用了反射包构造器类中无参数的 newInstance 方法，捕获了 InvocationTargetException，将构造器本身的异常抛出。 面试官：类加载的时候，自己定义了一个类和 java 自己的类类名和命名空间都一样，JVM 加载的是哪一个呢？ 面试者：调用的是 java 自身的，根据双亲委派模型，最委派 Bootstrap 的 ClassLoader 来加载，找不到才去使用 Extension 的 ClassLoader，还找不到才去用 Application 的 ClassLoader，这种机制利于保证 JVM 的安全。 面试官：你刚才提到的 java 的反射机制是什么概念？ 面试者：java 的反射机制是在运行状态中，对于任何一个类，都能够知道它所有的属性和方法；对于任何一个对象，都能够调用它的任何一个方法和属性。这种动态的获取信息和动态调用对象的方法的功能就是 java 的反射机制。它是 jdk 动态代理的实现方法。 面试官：java 还有没有其他的动态代理实现？ 面试者：还有 cglib 动态代理。 面试官：这两种动态代理哪个比较好呢？ 面试者：AOP 源码中同时使用了这两种动态代理，因为他们各有优劣。jdk 动态代理是利用 java 内部的反射机制来实现，在生成类的过程中比较高效，cglib 动态代理则是借助 asm 来实现，可以利用 asm 将生成的类进行缓存，所以在类生成之后的相关执行过程中比较高效。但是 jdk 的动态代理前提是目标类必须基于统一的接口，所以有一定的局限性。 旁白：面试者都已经提到 AOP 了，那么接下来横向，纵向，怎样都能问出一大堆问题，就不赘述。基于上面问题，读者也可以自己画出一棵知识树，然后就能找到能对答如流的终极方案：就是基本都没超过《深入理解 java 虚拟器》《java 并发编程实践》这两本书，大学学过的《数据结构与算法》《编译原理》掌握的好也可以在面试中加分哦。]]></content>
      <tags>
        <tag>interview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EMERGENCY! EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY'RE NOT. RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEING EXPIRED JUST TO BE SAFE]]></title>
    <url>%2F4205246882%2F</url>
    <content type="text"><![CDATA[警告！Eureka 可能存在维护了错误的实例列表（当它们没有启动的时候，Eureka 却把它当成启动的了）；Renews 值小于 Threshold 值，因此剩下未过期的都是安全的。 原因分析： 这个是 Eureka 的自我保护机制。Eureka Server 在运行期间，会统计心跳失败的比例在 15 分钟之内是否低于 85%，如果出现低于的情况（在单机调试的时候很容易满足，实际在生产环境上通常是由于网络不稳定导致），Eureka Server 会将当前的实例注册信息保护起来，同时提示这个警告。 Eureka server 和 client 之间每隔 30 秒会进行一次心跳通信，告诉 server，client 还活着。由此引出两个名词：Renews threshold：server 期望在每分钟中收到的心跳次数Renews (last min)：上一分钟内收到的心跳次数。 前文说到禁止注册 server 自己为 client，不管 server 是否禁止，阈值（threshold）是 1。client 个数为 n，阈值为 1+2n（此为一个 server 且禁止自注册的情况）如果是多个 server，且开启了自注册，那么就和 client 一样，是对于其他的 server 来说就是 client，是要 2 的 我开了两个 server，自注册，相关数据如下阈值：1+21renews：1）自注册 2 + 212）非自注册：2*1 Eurake 有一个配置参数 eureka.server.renewalPercentThreshold，定义了 renews 和 renews threshold 的比值，默认值为 0.85。当 server 在 15 分钟内，比值低于 percent，即少了 15% 的微服务心跳，server 会进入自我保护状态，Self-Preservation。在此状态下，server 不会删除注册信息，这就有可能导致在调用微服务时，实际上服务并不存在。这种保护状态实际上是考虑了 client 和 server 之间的心跳是因为网络问题，而非服务本身问题，不能简单的删除注册信息 stackoverflow 上，有人给出的建议是：1、在生产上可以开自注册，部署两个 server2、在本机器上测试的时候，可以把比值调低，比如 0.493、或者简单粗暴把自我保护模式关闭 **`eureka.server.enableSelfPreservation=false`** 参考文档 https://www.cnblogs.com/breath-taking/articles/7940364.html]]></content>
      <tags>
        <tag>spring</tag>
        <tag>spring cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql explain 详解]]></title>
    <url>%2F3714837258%2F</url>
    <content type="text"><![CDATA[mysql explain 详解语法及描述语法在 select 语句前加上 explain 关键字就可以 描述获取查询操作的执行顺序使用到的索引成功返回结果需要执行的行数 字段含义id标识符, 表示执行顺序. id 一样则自上而下, 否则大的先执行. select_type查询类型 simple: 不包含 union 操作或者不包含子查询的简单 select 查询 primary: 需要 union 操作或者含有子查询的 select, 位于最外层的 select.type 即为 primary, 且只有一个. union:union 链接的两个 select 查询, 第一个是 primiary, 第二个之后的都是 union. Dependent union: 出现在 union 或 union all 语句, 但是这个查询要收到外部查询的影响. union result: 包含 union 的结果集, 在 union 和 union all 语句中, 因为它不需要参与查询,, 所以 id 字段为 null subquery: 除了 from 子句中包含的子查询外, 其他地方出现的子查询都可能是 subquery Dependent subquery: 与 dependent union 类似, 表示这个 subquery 的查询要受到外部表查询的影响 derived:from 子句中出现的子查询, 也叫做派生表, 其他数据库中可能叫做内联师徒或嵌套 select 实例12345678910111213//外层是primary,内层是subqueryexplain select * from student s where s. classid = (select id from classes where classno=&apos;2017001&apos;);//结果有三行,第一行是primary,第二行是union,第三行是union resultexplain select * from student where id = 1 union select * from student where id = 2;//结果有四行,分别是primary,dependent subquery,dependent union,union resultexplain select * from student s where s.classid in (select id from classes where classno=&apos;2017001&apos; union select id from classes where classno=&apos;2017002&apos;);//跟mysql版本有关explain select * from (select * from student) s;table显示查询语句所查询的表名,如果查询使用了别名,那么这里使用的是别名.如果不涉及对数据表的操作,显示为null;有一种特殊情况,如果显示为,,则都是临时表.M,N代表的id,表示结果来自于这个查询产生 partitions表是分区表才行 type查询结果类型 const: 返回结果只有一个匹配行 range: 索引范围扫描，常见于使用 &gt;,&lt;,is null,between ,in ,like 等运算符的查询中 index: 索引全表扫描，把索引从头到尾扫一遍，常见于使用索引列就可以处理不需要读取数据文件的查询、可以使用索引排序或者分组的查询。 index_merge: 使用了一张表的多个索引, 实际上由于要读取所个索引，性能可能大部分时间都不如 range全表扫描数据文件 possible_keys &amp; keypossible_keys: 查询可能使用到的索引都会在这里列出来。 key: 查询真正使用到的索引，select_type 为 index_merge 时，这里可能出现两个以上的索引，其他的 select_type 这里只会出现一个。 key_len用于处理查询的索引长度，如果是单列索引，那就整个索引长度算进去，如果是多列索引，那么查询不一定都能使用到所有的列，具体使用到了多少个列的索引，这里就会计算进去，没有使用到的列，这里不会计算进去。 留意下这个列的值，算一下你的多列索引总长度就知道有没有使用到所有的列了. 总结通过对上面 explain 中的每个字段的详细讲解。我们不难看出，对查询性能影响最大的几个列是： select_type：查询类型 type: 连接使用了何种类型 rows: 查询数据需要用到的行 key: 查询真正使用到的索引 extra: 额外的信息尽量让自己的 SQL 用上索引，避免让 extra 里面出现 file sort(文件排序),using temporary(使用临时表)。]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP为什么是三次握手]]></title>
    <url>%2F3162095545%2F</url>
    <content type="text"><![CDATA[TCP为什么是三次握手TCP为什么建立连接是三次握手? 对于C和S来说,双方均需要确认对方和自己的发送信息能力和接受信息能力是OK的.拿一次完整的三次握手来举例: 第一次握手:C和S什么都不能确认. 第二次握手:C确认了自己的发送能力和接受能力,S确认了自己的接受能力. 第三次握手:S确认了自己的发送能力.]]></content>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么你需要一个VPS]]></title>
    <url>%2F3262901390%2F</url>
    <content type="text"><![CDATA[VPS 是什么VPS 是 Virtual private server 的简称，中文是 “虚拟专用服务器”，是指通过虚拟化技术在独立服务器中运行的专用服务器。每个使用 VPS 技术的虚拟独立服务器拥有各自独立的公网 IP 地址、操作系统、硬盘空间、内存空间、CPU 资源等，还可以进行安装程序、重启服务器等操作，与运行一台独立服务器基本相同。 很多人有点分不清 VPS 与虚拟主机的区别，网上也有很多人说过这个。博主这里就不长篇大论了，简单说，VPS 就相当于一台真正的电脑，只不过这台电脑是放在别人家的。你可以通过 ssh 工具对它做任何事，只要你开心，你砸了它也行。而虚拟主机说到底是别人家的电脑借给你用，你可以使用上面的计算资源，虚拟主机的服务商已经给你提供各种安装好的工具以及计算资源。但你对它的权限是比不上 VPS 大的。 VPS 可以用来做什么Shadowsocks使用 Python、C++、C# 等语言开发、基于 Apache 许可证的开放源代码软件，用于保护网络流量、加密数据传输。Shadowsocks 使用 Socks5 代理方式。Shadowsocks 分为服务器端和客户端。在使用之前，需要先将服务器端部署到服务器上面，然后通过客户端连接并创建本地代理。其实关于在 vps 搭建 SS 的教程已经很多了，但是博主之前搭梯子的时候发现很多教程存在一些问题，或者是太繁琐，或者是很多重要地方过了一段时间已经发生了变化，对小白用户不太友好。 因此博主决定写一篇新的教程分享出来。 Blog搭建一个属于自己的博客，搭配上 github education 提供的工具包，还可以获得一个免费域名及 SSL 认证。博主这个博客既是使用我说的这种方案搭建的。过程十分简单，按照博主的上一篇教程：在自己的 VPS 上从零开始搭建 Hexo 博客, 半天时间即可搭建完成并上线。 Seafile一套中国国产的开源、专业、可靠的云存储项目管理软件，[解决文件集中存储、共享和跨平台访问等问题。正式发布于 2012 年 10 月。除了一般网盘所提供的云存储以及共享功能外，Seafile 还提供消息通信、群组讨论等辅助功能，帮助员工更好的围绕文件展开协同工作，已有 10 多万用户使用。 作为一套比较成熟的管理软件，Seafile 的安装也十分简单。Install Seafile Client on Linux 此外，你还可以在 VPS 部署更多你自己写的脚本，比如爬虫类工具，抢票程序等等。一句话，只要是你的程序有 7*24h 的服务时间需求，你都可以把它放在你的 VPS 上跑。 VPS 哪家强看了上面的内容，如果你想选择一家 VPS 提供商，那么你大概有哪些选择呢？博主也给出了当下比较流行，有口碑的 VPS 服务商供大家参考。 DigitalOcean一家位于美国的云主机服务商，总部位于纽约，成立于 2012 年。由于价格低廉，高性能配置、灵活布置的优势，近些年来发展迅猛，成为中国站长圈们喜爱的品牌。该公司拥有多个数据中心：日本东京、美国 洛杉矶、纽约、新泽西、新加坡、英国伦敦、德国富兰克林. DigitailOcean，博主习惯称为 DO。也是博主选择的第一家 VPS 服务商，对于博主这种学生党而言，DO 是最具有性价比的一家服务商，由邀请链接注册自动赠送 $10 的优惠，再通过 paypal 充值 $5 即可使用。如果是学生用户的话使用 github education 提供的学生开发包可以再获得 $50 的优惠码。也就是说 $5 就可以使用 DO 的 1G 25gSSD 的 VPS 长达 13 个月，这性价比也是没谁了吧。 我的邀请链接是：$10 邀请链接, 另外为了选择合适的机房，再贴一个测速链接：SFO2 Speedtest | DigitalOcean Linode一个建立于美国新泽西州加洛伟的虚拟专用服务器（VPS）提供商。它的名字是由英文中 Linux 中的 Li 和 node（即 “节点” 一词）构成的混成词。如同它的名字一样，Linode 只提供运行 Linux 的服务器，而不提供运行 Windows Server 的服务器。它的服务一向以稳定著称。 知乎在发展初期使用的就是 Linode 的服务，现在口碑比较好的比较稳定的就是日本机房了，不过是要抢购，基本每每放出来都被抢完了。 搬瓦工隶属于加拿大 IT7 旗下的 VPS 服务品牌，主推 OPENVZ 架构方案，尤其是其中的 4 款便宜年付 VPS 深受广大用户的喜欢，支持支付宝付款，旗下有四个机房，均支持一键切换机房位置以及一键安装各类软件等功能。 这家前些年应该是最火的 vps 服务商了，记得曾经有 $5 的年 vps，小内存搭个 ss 还是很够用的。后来因为 ip 资源枯竭，搬瓦工拿不到什么 ip 就停了自家的超低资费服务。不过现在还是有 $19.99 的资费可以选。 Vultr一家 2014 年刚成立的 VPS 服务商，基于 KVM，采用 SSD 硬盘，拥有大量自建机房。有日本、美国洛杉矶、Dallas、Chicago、New York、Seattle、Atlanta、英国、德国等，价格便宜，配置又高。支持 Paypal、信用卡或比特币付款。 这家比较好的依然是日本主机，国内 ping 值在 100 以内，也较少抽风。另外他家的最低配置也比别家高，价格嘛，自然就水涨船高了。博主作为一个学生党目前觉得还没太必要用他家，以后说不定想试一试。]]></content>
      <tags>
        <tag>闲谈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么匿名内部类访问局部变量必须是final?]]></title>
    <url>%2F775929552%2F</url>
    <content type="text"><![CDATA[一个谜团如果你用过类似 guava 这种 “伪函数式编程” 风格的 library 的话，那下面这种风格的代码对你来说应该不陌生： 123456789public void tryUsingGuava() &#123; final int expectedLength = 4; Iterables.filter(Lists.newArrayList(&quot;123&quot;, &quot;1234&quot;), new Predicate&lt;String&gt;() &#123; @Override public boolean apply(String str) &#123; return str.length() == expectedLength; &#125; &#125;);&#125; 这段代码对一个字符串的 list 进行过滤，从中找出长度为 4 的字符串。看起来很是平常，没什么特别的。 但是，声明 expectedLength 时用的那个 final 看起来有点扎眼，把它去掉试试： error: local variable expectedLength is accessed from within inner class; needs to be declared final 结果 Java 编译器给出了如上的错误，看起来匿名内部类只能够访问 final 的局部变量。但是，为什么呢？其他的语言也有类似的规定吗？ 在开始用其他语言做实验之前我们先把问题简化一下，不要再带着 guava 了，我们去除掉噪音，把问题归结为： 为什么 Java 中的匿名内部类只可以访问 final 的局部变量呢？其他语言中的匿名函数也有类似的限制吗？ Scala 中有类似的规定吗？123456789101112def tryAccessingLocalVariable &#123; var number = 123 println(number) var lambda = () =&gt; &#123; number = 456 println(number) &#125; lambda.apply() println(number)&#125; | 上面的 Scala 代码是合法的，number 变量是声明为 var 的，不是 val（类似于 Java 中的 final）。而且在匿名函数中可以修改 number 的值。 看来 Scala 中没有类似的规定。 C# 中有类似的规定吗？12345678910111213public void tryUsingLambda ()&#123; int number = 123; Console.WriteLine (number); Action action = () =&gt; &#123; number = 456; Console.WriteLine (number); &#125;; action (); Console.WriteLine (number);&#125; 这段 C# 代码也是合法的，number 这个局部变量在 lambda 表达式内外都可以访问和赋值。 看来 C# 中也没有类似的规定。 分析谜团三门语言中只有 Java 有这种限制，那我们分析一下吧。先来看一下 Java 中的匿名内部类是如何实现的： 先定义一个接口： 123public interface MyInterface &#123; void doSomething();&#125; 然后创建这个接口的匿名子类： 12345678910111213141516public class TryUsingAnonymousClass &#123; public void useMyInterface() &#123; final Integer number = 123; System.out.println(number); MyInterface myInterface = new MyInterface() &#123; @Override public void doSomething() &#123; System.out.println(number); &#125; &#125;; myInterface.doSomething(); System.out.println(number); &#125;&#125; 这个匿名子类会被编译成一个单独的类，反编译的结果是这样的： 1234567891011121314class TryUsingAnonymousClass$1 implements MyInterface &#123; private final TryUsingAnonymousClass this$0; private final Integer paramInteger; TryUsingAnonymousClass$1(TryUsingAnonymousClass this$0, Integer paramInteger) &#123; this.this$0 = this$0; this.paramInteger = paramInteger; &#125; public void doSomething() &#123; System.out.println(this.paramInteger); &#125;&#125; 可以看到名为 number 的局部变量是作为构造方法的参数传入匿名内部类的（以上代码经过了手动修改，真实的反编译结果中有一些不可读的命名）。 如果 Java 允许匿名内部类访问非 final 的局部变量的话，那我们就可以在 TryUsingAnonymousClass$1 中修改 paramInteger，但是这不会对 number 的值有影响，因为它们是不同的 reference。 这就会造成数据不同步的问题。 所以，谜团解开了：Java 为了避免数据不同步的问题，做出了匿名内部类只可以访问 final 的局部变量的限制。 但是，新的谜团又出现了： Scala 和 C# 为什么没有类似的限制呢？它们是如何处理数据同步问题的呢？上面出现过的那段 Scala 代码中的 lambda 表达式会编译成这样： 123456789101112131415161718public final class TryUsingAnonymousClassInScala$$anonfun$1 extends AbstractFunction0.mcV.sp implements Serializable &#123; public static final long serialVersionUID = 0L; private final IntRef number$2; public final void apply() &#123; apply$mcV$sp(); &#125; public void apply$mcV$sp() &#123; this.number$2.elem = 456; Predef..MODULE$.println(BoxesRunTime.boxToInteger(this.number$2.elem)); &#125; public TryUsingAnonymousClassInScala$$anonfun$1(TryUsingAnonymousClassInScala $outer, IntRef number$2) &#123; this.number$2 = number$2; &#125;&#125; 可以看到 number 也是通过构造方法的参数传入的，但是与 Java 的不同是这里的 number 不是直接传入的，是被 IntRef 包装了一层然后才传入的。对 number 的值修改也是通过包装类进行的：this.number$2.elem = 456; 这样就保证了 lambda 表达式内外访问到的是同一个对象。 再来看看 C# 的处理方式，反编译一下，发现 C# 编译器生成了如下的一个类： 12345678910private sealed class &lt;tryUsingLambda&gt;c__AnonStorey0&#123; internal int number; internal void &lt;&gt;m__0 () &#123; this.number = 456; Console.WriteLine (this.number); &#125;&#125; 把 number 包装在这个类内，这样就保证了 lambda 表达式内外使用的都是同一个 number，即便重新赋值也可以保证内外部的数据是同步的。 小结Scala 和 C# 的编译器通过把局部变量包装在另一个对象中，来实现 lambda 表达式内外的数据同步。 而 Java 的编译器由于未知的原因（怀疑是为了图省事儿？）没有做包装局部变量这件事儿，于是就只好强制用户把局部变量声明为 final 才能在匿名内部类中使用来避免数据不同步的问题。]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[既然Java反射可以访问和修改私有成员变量，那封装成private还有意义么？]]></title>
    <url>%2F2868978503%2F</url>
    <content type="text"><![CDATA[既然Java反射可以访问和修改私有成员变量，那封装成private还有意义么？简单来说，private并不是解决“安全”问题的。安全是指不让代码被非法看到/访问。但是只要人能拿到代码，总会有办法去查看和改变代码。其他答案提到反射可以用SecurityManager来防止private被访问。但是从更高一层的角度，即便使用了SecurityManager，还是可以通过各种方式拿到java的bytecode，并做任意修改。比如有asm这样的lib，也有instrument api这种东西可以帮你。所以记得，如果你真有一段代码不允许被别人看/用，就不要把这段代码放到其他人可以碰到的地方，而是做一个server，通过接口允许有限制的访问。其他人想破解，只能破解你的服务器网关和跳板机器。关于真正的安全性，可以参考激活服务器的工作原理.private想表达的不是“安全性”的意思，而是OOP的封装概念，是一种编译器可以帮助你的设计上的hint。这就像是一家没人的店挂了个牌子“闲人免进”，但你真要进去还是有各种办法可以办到。所以private，以及所有其他的access modifier都有一层隐含的含义：如果你按照遵守这套规则，开发者可以保证不问题（不考虑bug的情况下）；否则，后果自负。比如，你在用spring的IoC的时候，你知道你要“注入”，不管它是不是private的，你知道“注入”是你自己控制的，是你设计好的效果。那么通过spring的IoC利用反射帮你注入一些private property是再正常不过的用法。再比如，单元测试，你就想测一个private方法。但是因为private的缘故就是测不了。于是你可以用反射绕开这个限制，开心的做测试。虽说某些人坚持“不应该测试private方法，而应该通过测试其他方法间接测试private方法，但并没有形成广泛的共识。这里不对这个问题展开。虽然能绕开，但绕开的代码很繁琐。久而久之就会厌倦。毕竟，代码应该为你工作，而不是你为代码工作。因此，我的经验是通常会用protected或者default来代替private。我曾设想runtime应该给一种运行模式，通过设定一个启动参数使其不管private这类的限制，这样做UT，做profiling等工作都会轻松许多。等到最后发布时，再用普通模式。但可惜现实当中并没有这种设定。评论区提到了Android里的VisibleForTesting，可以实现我期望的功能。大赞！感谢 @尤华杰我之所以敢用protected/default来代替private是因为现实当中非private不可的情景非常少见。实际上，很多时候private带来的麻烦比起带来的好处要多，这是因为很多时候对OOP的误用造成的。OOP的误用造成了无谓的private，然后逼着你必须得绕开private。其实private就是个约定而已。看看其他语言，比如python，它的“private“是一种很松散的约定，所有private的成员都用下划线开头，告诉调用者“不要随便调用我哦”，但是如果真调用了也就调用了。C++，通过指针就能绕开private。有人说，private会避免新手误用。但问题是，大家从出道开始，自己或者周围的同事朋友有谁曾经出过这个问题？IDE知道一个成员当前不能访问，就根本就不会提示。如果一个人已经开始通过源代码/反编译研究“我能不能调用这个私有方法了“，他还算是一个菜鸟吗？他会不知道这里的潜在风险吗？如果真的误用了，code review能过吗？测试能过吗？如果一个公司因为误用private成员，造成了重大的损失，那这个公司就活该倒闭算了，不要在世上丢人。OOP是一种编程思想，是众多编程思想中的一种。是开发者决定了一个问题应该用OOP合适，并且用了Java这样的语言来简化自己开发OOP代码时的工作。如果抱着这种态度，就不会误用，因为private在开发者的心中。其他人也不太可能误用，如果他上过几天java培训。不要因为语言是OOP的就去套，把不适合的OOP的代码强用OOP的各种套路实现，然后给自己后续的维护扩展埋坑。]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring cloud 扫不到自定义controller]]></title>
    <url>%2F522943020%2F</url>
    <content type="text"><![CDATA[在 springboot 官网照着给的介绍写了个 springboot 程序 pom.xml 1234567891011&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.2.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; java 文件 123456789101112131415161718192021package hello;import org.springframework.boot.*;import org.springframework.boot.autoconfigure.*;import org.springframework.stereotype.*;import org.springframework.web.bind.annotation.*;@Controller@EnableAutoConfigurationpublic class Application&#123; @RequestMapping(&quot;/&quot;) @ResponseBody String home() &#123; return &quot;Hello World!&quot;; &#125; public static void main(String[] args) throws Exception &#123; SpringApplication.run(SampleController.class, args); &#125;&#125; 然后自己写了个 Controller 123456789@Controllerpublic class MyController &#123; @RequestMapping(&quot;/hello&quot;) @ResponseBody public String hello() &#123; System.out.println(&quot;hello&quot;); return &quot;hello&quot;; &#125;&#125; 但是无论如何也无法扫描到自己定义的 Controller 访问之后,网页报错: Whitelabel Error Page 报错的原因是找不到对应的映射路径，即 Controller 没有被扫描到 ，。 郁闷至极，到晚上搜的结果说的是 LoginController 方的位置不对，应该让启动类和 Controller 的包在同一级目录下，然而对我却没有效果。 官方建议 application.java 放的位置： 最后尝试了下修改下 Application 上的注解，我本来复制官方的代码用的是 @Controller 和 @EnableAutoConfiguration，试着换成了 @**SpringBootApplication 注解**，出乎意外的可以扫描到 Controller 又查了下官方的文档终于找到原因了，原因是： 如果使用 @Controller 和 @EnableAutoConfiguration 注解还应该再加上一个注解：@ComponentScan 就可以了。@Controller 和 @EnableAutoConfiguration 没有扫描注解的功能，而 @ComponentScan 是 springboot 专门用来扫描 @Component, @Service, @Repository, @Controller 等注解的注解 总结： 使用 springboot 启动类配置扫描的两种注解配置方式： 1、@Controller @EnableAutoConfiguration @ComponentScan 2、@SpringBootApplication @SpringBootApplication 注解等价于 @Configuration, @EnableAutoConfiguration and @ComponentScan 另外application.java（启动类）也应该按照官方的建议放在root目录下，这样才能扫描到Service和dao，不然还会引起，扫描不到注解的问题。 **--- 更新日期：2018-10-14 ---** 最近用了最新的springboot 2.0.5.RELEASE 版本 多了一种新的扫描注解，新版的springboot application可以放在任意位置，只要加上 @ComponentScan(basePackages = {“com.oskyhang”, “com.frames”}) 注解就可以，注解指定扫描的包，就可以扫描到，更灵活方便。]]></content>
      <tags>
        <tag>spring</tag>
        <tag>spring boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CPU100%问题定位实战]]></title>
    <url>%2F2008800739%2F</url>
    <content type="text"><![CDATA[功能问题，通过日志，单步调试相对比较好定位。性能问题，例如线上服务器 CPU100%，如何找到相关服务，如何定位问题代码，更考验技术人的功底题目 某服务器上部署了若干 tomcat 实例，即若干垂直切分的 Java 站点服务，以及若干 Java 微服务，突然收到运维的 CPU 异常告警问：如何定位是哪个服务进程导致 CPU 过载，哪个线程导致 CPU 过载，哪段代码导致 CPU 过载? 步骤一、找到最耗 CPU 的进程工具：top方法： 执行 top -c ，显示进程运行信息列表 键入 P (大写 p)，进程按照 CPU 使用率排序最耗 CPU 的进程 PID 为 10765 步骤二：找到最耗 CPU 的线程工具：top方法： top -Hp 10765 ，显示一个进程的线程运行信息列表 键入 P (大写 p)，线程按照 CPU 使用率排序，进程 10765 内，最耗 CPU 的线程 PID 为 10804 步骤三：将线程 PID 转化为 16 进制工具：printf 方法：printf “%x\n” 10804 ，10804 对应的 16 进制是 0x2a34，当然，这一步可以用计算器。 之所以要转化为 16 进制，是因为堆栈里，线程 id 是用 16 进制表示的。 步骤四：查看堆栈，找到线程在干嘛工具：pstack/jstack/grep方法：jstack 10765 | grep ‘0x2a34’ -C5 –color 打印进程堆栈 通过线程 id，过滤得到线程堆栈找到了耗 CPU 高的线程对应的线程名称 “AsyncLogger-1”，以及看到了该线程正在执行代码的堆栈。希望对经常进行线上 CPU 问题排查的同学有帮助，如果有更好的实践，也欢迎分享。 想要印象深刻，请大家务必线上实操练习哟。]]></content>
      <tags>
        <tag>实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何优雅的使用和理解线程池]]></title>
    <url>%2F1328518056%2F</url>
    <content type="text"><![CDATA[前言平时接触过多线程开发的童鞋应该都或多或少了解过线程池，之前发布的《阿里巴巴 Java 手册》里也有一条： 可见线程池的重要性。 简单来说使用线程池有以下几个目的： 线程是稀缺资源，不能频繁的创建。 解耦作用；线程的创建于执行完全分开，方便维护。 应当将其放入一个池子中，可以给其他任务进行复用。 线程池原理谈到线程池就会想到池化技术，其中最核心的思想就是把宝贵的资源放到一个池子中；每次使用都从里面获取，用完之后又放回池子供其他人使用，有点吃大锅饭的意思。 那在 Java 中又是如何实现的呢？ 在 JDK 1.5 之后推出了相关的 api，常见的创建线程池方式有以下几种： Executors.newCachedThreadPool()：无限线程池。 Executors.newFixedThreadPool(nThreads)：创建固定大小的线程池。 Executors.newSingleThreadExecutor()：创建单个线程的线程池。 其实看这三种方式创建的源码就会发现： 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 实际上还是利用 ThreadPoolExecutor 类实现的。 所以我们重点来看下 ThreadPoolExecutor 是怎么玩的。 首先是创建线程的 api： 1ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) 这几个核心参数的作用： corePoolSize 为线程池的基本大小。 maximumPoolSize 为线程池最大线程大小。 keepAliveTime 和 unit 则是线程空闲后的存活时间。 workQueue 用于存放任务的阻塞队列。 handler 当队列和最大线程池都满了之后的饱和策略。 了解了这几个参数再来看看实际的运用。 通常我们都是使用: 1threadPool.execute(new Job()); 这样的方式来提交一个任务到线程池中，所以核心的逻辑就是 execute() 函数了。 在具体分析之前先了解下线程池中所定义的状态，这些状态都和线程的执行密切相关： RUNNING 自然是运行状态，指可以接受任务执行队列里的任务 SHUTDOWN 指调用了 shutdown() 方法，不再接受新任务了，但是队列里的任务得执行完毕。 STOP 指调用了 shutdownNow() 方法，不再接受新任务，同时抛弃阻塞队列里的所有任务并中断所有正在执行任务。 TIDYING 所有任务都执行完毕，在调用 shutdown()/shutdownNow() 中都会尝试更新为这个状态。 TERMINATED 终止状态，当执行 terminated() 后会更新为这个状态。 用图表示为： 然后看看 execute() 方法是如何处理的： 获取当前线程池的状态。 当前线程数量小于 coreSize 时创建一个新的线程运行。 如果当前线程处于运行状态，并且写入阻塞队列成功。 双重检查，再次获取线程状态；如果线程状态变了（非运行状态）就需要从阻塞队列移除任务，并尝试判断线程是否全部执行完毕。同时执行拒绝策略。 如果当前线程池为空就新创建一个线程并执行。 如果在第三步的判断为非运行状态，尝试新建线程，如果失败则执行拒绝策略。 这里借助《聊聊并发》的一张图来描述这个流程： 如何配置线程流程聊完了再来看看上文提到了几个核心参数应该如何配置呢？ 有一点是肯定的，线程池肯定是不是越大越好。 通常我们是需要根据这批任务执行的性质来确定的。 IO 密集型任务：由于线程并不是一直在运行，所以可以尽可能的多配置线程，比如 CPU 个数 * 2 CPU 密集型任务（大量复杂的运算）应当分配较少的线程，比如 CPU 个数相当的大小。 当然这些都是经验值，最好的方式还是根据实际情况测试得出最佳配置。 优雅的关闭线程池有运行任务自然也有关闭任务，从上文提到的 5 个状态就能看出如何来关闭线程池。 其实无非就是两个方法 shutdown()/shutdownNow()。 但他们有着重要的区别： shutdown() 执行后停止接受新任务，会把队列的任务执行完毕。 shutdownNow() 也是停止接受新任务，但会中断所有的任务，将线程池状态变为 stop。 两个方法都会中断线程，用户可自行判断是否需要响应中断。 shutdownNow() 要更简单粗暴，可以根据实际场景选择不同的方法。 我通常是按照以下方式关闭线程池的： 123456789101112long start = System.currentTimeMillis();for (int i = 0; i &lt;= 5; i++) &#123; pool.execute(new Job());&#125;pool.shutdown();while (!pool.awaitTermination(1, TimeUnit.SECONDS)) &#123; LOGGER.info(&quot;线程还在执行。。。&quot;);&#125;long end = System.currentTimeMillis();LOGGER.info(&quot;一共处理了【&#123;&#125;】&quot;, (end - start)); pool.awaitTermination(1, TimeUnit.SECONDS) 会每隔一秒钟检查一次是否执行完毕（状态为 TERMINATED），当从 while 循环退出时就表明线程池已经完全终止了。 线程池隔离 线程池看似很美好，但也会带来一些问题。 如果我们很多业务都依赖于同一个线程池, 当其中一个业务因为各种不可控的原因消耗了所有的线程，导致线程池全部占满。 这样其他的业务也就不能正常运转了，这对系统的打击是巨大的。 比如我们 Tomcat 接受请求的线程池，假设其中一些响应特别慢，线程资源得不到回收释放；线程池慢慢被占满，最坏的情况就是整个应用都不能提供服务。 所以我们需要将线程池进行隔离。 通常的做法是按照业务进行划分： 比如下单的任务用一个线程池，获取数据的任务用另一个线程池。这样即使其中一个出现问题把线程池耗尽，那也不会影响其他的任务运行。 hystrix 隔离这样的需求 Hystrix 已经帮我们实现了。 Hystrix 是一款开源的容错插件，具有依赖隔离、系统容错降级等功能。 下面来看看 Hystrix 简单的应用： 首先需要定义两个线程池，分别用于执行订单、处理用户。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687/** * Function:订单服务 * */public class CommandOrder extends HystrixCommand&lt;String&gt; &#123; private final static Logger LOGGER = LoggerFactory.getLogger(CommandOrder.class); private String orderName; public CommandOrder(String orderName) &#123; super(Setter.withGroupKey( //服务分组 HystrixCommandGroupKey.Factory.asKey(&quot;OrderGroup&quot;)) //线程分组 .andThreadPoolKey(HystrixThreadPoolKey.Factory.asKey(&quot;OrderPool&quot;)) //线程池配置 .andThreadPoolPropertiesDefaults(HystrixThreadPoolProperties.Setter() .withCoreSize(10) .withKeepAliveTimeMinutes(5) .withMaxQueueSize(10) .withQueueSizeRejectionThreshold(10000)) .andCommandPropertiesDefaults( HystrixCommandProperties.Setter() .withExecutionIsolationStrategy(HystrixCommandProperties.ExecutionIsolationStrategy.THREAD)) ) ; this.orderName = orderName; &#125; @Override public String run() throws Exception &#123; LOGGER.info(&quot;orderName=[&#123;&#125;]&quot;, orderName); TimeUnit.MILLISECONDS.sleep(100); return &quot;OrderName=&quot; + orderName; &#125;&#125;/** * Function:用户服务 */public class CommandUser extends HystrixCommand&lt;String&gt; &#123; private final static Logger LOGGER = LoggerFactory.getLogger(CommandUser.class); private String userName; public CommandUser(String userName) &#123; super(Setter.withGroupKey( //服务分组 HystrixCommandGroupKey.Factory.asKey(&quot;UserGroup&quot;)) //线程分组 .andThreadPoolKey(HystrixThreadPoolKey.Factory.asKey(&quot;UserPool&quot;)) //线程池配置 .andThreadPoolPropertiesDefaults(HystrixThreadPoolProperties.Setter() .withCoreSize(10) .withKeepAliveTimeMinutes(5) .withMaxQueueSize(10) .withQueueSizeRejectionThreshold(10000)) //线程池隔离 .andCommandPropertiesDefaults( HystrixCommandProperties.Setter() .withExecutionIsolationStrategy(HystrixCommandProperties.ExecutionIsolationStrategy.THREAD)) ) ; this.userName = userName; &#125; @Override public String run() throws Exception &#123; LOGGER.info(&quot;userName=[&#123;&#125;]&quot;, userName); TimeUnit.MILLISECONDS.sleep(100); return &quot;userName=&quot; + userName; &#125;&#125; api 特别简洁易懂，具体详情请查看官方文档。 然后模拟运行： 1234567891011121314151617public static void main(String[] args) throws Exception &#123; CommandOrder commandPhone = new CommandOrder(&quot;手机&quot;); CommandOrder command = new CommandOrder(&quot;电视&quot;); //阻塞方式执行 String execute = commandPhone.execute(); LOGGER.info(&quot;execute=[&#123;&#125;]&quot;, execute); //异步非阻塞方式 Future&lt;String&gt; queue = command.queue(); String value = queue.get(200, TimeUnit.MILLISECONDS); LOGGER.info(&quot;value=[&#123;&#125;]&quot;, value); CommandUser commandUser = new CommandUser(&quot;张三&quot;); String name = commandUser.execute(); LOGGER.info(&quot;name=[&#123;&#125;]&quot;, name);&#125; 运行结果： 可以看到两个任务分成了两个线程池运行，他们之间互不干扰。 获取任务任务结果支持同步阻塞和异步非阻塞方式，可自行选择。 它的实现原理其实容易猜到： 利用一个 Map 来存放不同业务对应的线程池。 通过刚才的构造函数也能证明： 还要注意的一点是： 自定义的 Command 并不是一个单例，每次执行需要 new 一个实例，不然会报 This instance can only be executed once. Please instantiate a new instance. 异常。 总结池化技术确实在平时应用广泛，熟练掌握能提高不少效率。]]></content>
      <tags>
        <tag>multi-thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解B树,B+树特点及使用场景]]></title>
    <url>%2F1643632136%2F</url>
    <content type="text"><![CDATA[读完本文你将了解： B 树 对比平衡二叉树和 B 树 B 树中如何查找数据 B 树如何保证平衡 使用场景 B+ 树 Thanks 大家好，前面那篇文章《3 分钟理解完全二叉树、平衡二叉树、二叉查找树》中我们了解了几种特殊的二叉树的功能及特点，知道了它们在进行查找数据时可以提高效率，但需要注意的是，这是指在内存中进行查找。如果有海量的数据，不可能一次性读取到内存中，这时候就要考虑的是，如何在磁盘中快速找到需要的数据。 今天这篇文章中要介绍的 “B 树、B+ 树”，他们的使用场景是：查找磁盘中的大量数据。 B 树B 树就是常说的 “B 减树（B- 树）”，又名平衡多路（即不止两个子树）查找树，它和平衡二叉树的不同有这么几点： 平衡二叉树节点最多有两个子树，而 B 树每个节点可以有多个子树，M 阶 B 树表示该树每个节点最多有 M 个子树 平衡二叉树每个节点只有一个数据和两个指向孩子的指针，而 B 树每个中间节点有 k-1 个关键字（可以理解为数据）和 k 个子树（ **k 介于阶数 M 和 M/2 之间，M/2 向上取整） B 树的所有叶子节点都在同一层，并且叶子节点只有关键字，指向孩子的指针为 null 和平衡二叉树相同的点在于：B 树的节点数据大小也是按照左小右大，子树与节点的大小比较决定了子树指针所处位置。 看着概念可能有点难理解，来看看图对比下平衡二叉树和 B 树。 对比平衡二叉树和 B 树首先是节点， 平衡二叉树的节点如下图所示，每个节点有一个数据和最多两个子树： B 树中的每个节点由两部分组成： 关键字（可以理解为数据） 指向孩子节点的指针 B 树的节点如下图所示，每个节点可以有不只一个数据，同时拥有数据数加一个子树，同时每个节点左子树的数据比当前节点都小、右子树的数据都比当前节点的数据大： 上图是为了方便读者理解 B 树每个节点的内容，实际绘制图形还是以圆表示每个节点。 了解了节点的差异后，来看看 B 树的定义，一棵 B 树必须满足以下条件： 若根结点不是终端结点，则至少有 2 棵子树 除根节点以外的所有非叶结点至少有 M/2 棵子树，至多有 M 个子树（关键字数为子树减一） 所有的叶子结点都位于同一层 用一张图对比平衡二叉树和 B 树： 可以看到，B 树的每个节点可以表示的信息更多，因此整个树更加 “矮胖”，这在从磁盘中查找数据（先读取到内存、后查找）的过程中，可以减少磁盘 IO 的次数，从而提升查找速度。 B 树中如何查找数据因为 B 树的子树大小排序规则，因此在 B 树中查找数据时，一般需要这样： 从根节点开始，如果查找的数据比根节点小，就去左子树找，否则去右子树 和子树的多个关键字进行比较，找到它所处的范围，然后去范围对应的子树中继续查找 以此循环，直到找到或者到叶子节点还没找到为止 B 树如何保证平衡我们知道，平衡的树之所以能够加快查找速度，是因为在添加、删除的时候做了某些操作以保证平衡。 平衡二叉树的平衡条件是：左右子树的高度差不大于 1；而 B 树的平衡条件则有三点： 叶子节点都在同一层 每个节点的关键字数为子树个数减一（子树个数 k 介于树的阶 M 和它的二分之一 子树的关键字保证左小右大的顺序 也就是说，一棵 3 阶的 B 树（即节点最多有三个子树），每个节点的关键字数最少为 1，最多为 2，如果要添加数据的子树的关键字数已经是最多，就需要拆分节点，调整树的结构。 网上找到一张很不错的动图，我们来根据它分析下 B 树添加元素时如何保证平衡。 这个图用以表示往 4 阶 B 树中依次插入下面这组数据的过程： 6 10 4 14 5 11 15 3 2 12 1 7 8 8 6 3 6 21 5 15 15 6 32 23 45 65 7 8 6 5 4 建议放大图查看。 由于我比较懒，我们来根据前几步分析下 B 树的添加流程： 首先明确：4 阶 B 树表示每个节点最多有 4 个子树、3 个关键字，最少有 2 个子树、一个关键字 添加 6，第一个节点，没什么好说的 添加 10，根节点最多能放三个关键字，按顺序添到根节点中 添加 4，还能放到根节点中 添加 14，这时超出了关键字最大限制，需要把 14 添加为子树，同时为了保证 “所有叶子节点在同一层”，就需要拆几个关键字作为子树： 拆为： 这个拆的过程比较复杂，首先要确定根节点保留几个关键字，由于 “非叶子节点的根节点至少有 2 棵子树” 的限制，那就至少需要两个关键字分出去，又因为 “子树数是关键字数 + 1”，如果根节点有两个关键字，就得有三个子树，无法满足，所以只好把除 6 以外的三个关键字都拆为子树。 谁和谁在一个子树上呢，根据 “左子树比关键字小、右子树比关键字大” 的规律，4 在左子树，10 和 14 在右子树。 继续添加 ： 添加 5，放到 4 所在的子树上 添加 11，放在 10 和 14 所在的右子树上 添加 15，按大小应该放到 10、11 和 14 所在的子树上，但因为超过了关键字数限制，又得拆分 因为 “根节点必须都在同一层”，因此我们不能给现有的左右子树添加子树，只能添加给 6 了；但是如果 6 有三个子树，就必须得有 2 个关键字，提升谁做关键字好呢，这得看谁做 6 中间的子树，因为右子树的所有关键字都得比父节点的关键字大，所以这个提升的关键字只能比未来右子树中的关键字都小，那就只有 10 和 11 可以考虑了。 提升 10 吧，没有比它小的做子树，那就只能提升 11 了： 再添加元素也是类似的逻辑： 首先考虑要插入的子树是否已经超出了关键字数的限制 超出的话，如果要插入的位置是叶子节点，就只能拆一个关键字添加到要插入位置的父节点 如果非叶子节点，就得从其他子树拆子树给新插入的元素做孩子 删除也是一样的，要考虑删除孩子后，父节点是否还满足子树 k 介于 M/2 和 M 的条件，不满足就得从别的节点拆子树甚至修改相关子树结构来保持平衡。 总之添加、删除的过程很复杂，要考虑的条件很多，具体实现就不细追究了，这里我们有个基本认识即可。 正是这个复杂的保持平衡操作，使得平衡后的 B 树能够发挥出磁盘中快速查找的作用。 使用场景 这部分摘自：浅谈算法和数据结构：平衡查找树之 B 树 文件系统和数据库系统中常用的 B/B+ 树，他通过对每个节点存储个数的扩展，使得对连续的数据能够进行较快的定位和访问，能够有效减少查找时间，提高存储的空间局部性从而减少 IO 操作。他广泛用于文件系统及数据库中，如： Windows：HPFS 文件系统 Mac：HFS，HFS+ 文件系统 Linux：ResiserFS，XFS，Ext3FS，JFS 文件系统 数据库：ORACLE，MYSQL，SQLSERVER 等中 数据库：ORACLE，MYSQL，SQLSERVER 等中 B+ 树 这部分主要学习自 “程序员小灰” 的 漫画：什么是 B + 树？ 了解了 B 树后再来了解下它的变形版：B+ 树，它比 B 树的查询性能更高。 一棵 B+ 树需要满足以下条件： 节点的子树数和关键字数相同（B 树是关键字数比子树数少一） 节点的关键字表示的是子树中的最大数，在子树中同样含有这个数据 叶子节点包含了全部数据，同时符合左小右大的顺序 简单概括下 B+ 树的三个特点： 关键字数和子树相同 非叶子节点仅用作索引，它的关键字和子节点有重复元素 叶子节点用指针连在一起 首先第一点不用特别介绍了，在 B 树中，节点的关键字用于在查询时确定查询区间，因此关键字数比子树数少一；而在 B+ 树中，节点的关键字代表子树的最大值，因此关键字数等于子树数。 第二点，除叶子节点外的所有节点的关键字，都在它的下一级子树中同样存在，最后所有数据都存储在叶子节点中。 根节点的最大关键字其实就表示整个 B+ 树的最大元素。 第三点，叶子节点包含了全部的数据，并且按顺序排列，B+ 树使用一个链表将它们排列起来，这样在查询时效率更快。 由于 B+ 树的中间节点不含有实际数据，只有子树的最大数据和子树指针，因此磁盘页中可以容纳更多节点元素，也就是说同样数据情况下，B+ 树会 B 树更加 “矮胖”，因此查询效率更快。 B+ 树的查找必会查到叶子节点，更加稳定。 有时候需要查询某个范围内的数据，由于 B+ 树的叶子节点是一个有序链表，只需在叶子节点上遍历即可，不用像 B 树那样挨个中序遍历比较大小。 B+ 树的三个优点： 层级更低，IO 次数更少 每次都需要查询到叶子节点，查询性能稳定 叶子节点形成有序链表，范围查询方便 添加过程就不深入研究了，后面用到再看吧，这里先贴一个 B+ 树动态添加元素图： Thanks www.zhihu.com/question/30… zhuanlan.zhihu.com/p/27700617 mp.weixin.qq.com/s/jRZMMONW3… blog.jobbole.com/79311/]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类加载器与双亲委派模型]]></title>
    <url>%2F3288749768%2F</url>
    <content type="text"><![CDATA[类加载器加载类的开放性类加载器（ClassLoader）是 Java 语言的一项创新，也是 Java 流行的一个重要原因。在类加载的第一阶段 “加载” 过程中，需要通过一个类的全限定名来获取定义此类的二进制字节流，完成这个动作的代码块就是类加载器。这一动作是放在 Java 虚拟机外部去实现的，以便让应用程序自己决定如何获取所需的类。 虚拟机规范并没有指明二进制字节流要从一个 Class 文件获取，或者说根本没有指明从哪里获取、怎样获取。这种开放使得 Java 在很多领域得到充分运用，例如： 从 ZIP 包中读取，这很常见，成为 JAR，EAR，WAR 格式的基础 从网络中获取，最典型的应用就是 Applet 运行时计算生成，最典型的是动态代理技术，在 java.lang.reflect.Proxy 中，就是用了 ProxyGenerator.generateProxyClass 来为特定接口生成形式为 “*$Proxy” 的代理类的二进制字节流 有其他文件生成，最典型的 JSP 应用，由 JSP 文件生成对应的 Class 类…… 类加载器与类的唯一性类加载器虽然只用于实现类的加载动作，但是对于任意一个类，都需要由加载它的类加载器和这个类本身共同确立其在 Java 虚拟机中的唯一性。通俗的说，JVM 中两个类是否 “相等”，首先就必须是同一个类加载器加载的，否则，即使这两个类来源于同一个 Class 文件，被同一个虚拟机加载，只要类加载器不同，那么这两个类必定是不相等的。 这里的 “相等”，包括代表类的 Class 对象的 equals() 方法、isAssignableFrom()方法、isInstance()方法的返回结果，也包括使用 instanceof 关键字做对象所属关系判定等情况。 以下代码说明了不同的类加载器对 instanceof 关键字运算的结果的影响。 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.jvm.classloading;import java.io.IOException;import java.io.InputStream;/** * 类加载器在类相等判断中的影响 * * instanceof关键字 * */public class ClassLoaderTest &#123; public static void main(String[] args) throws Exception &#123; // 自定义类加载器 ClassLoader myLoader = new ClassLoader() &#123; @Override public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; try &#123; String fileName = name.substring(name.lastIndexOf(&quot;.&quot;) + 1) + &quot;.class&quot;; InputStream is = getClass().getResourceAsStream(fileName); if (is == null) &#123; return super.loadClass(fileName); &#125; byte[] b = new byte[is.available()]; is.read(b); return defineClass(name, b, 0, b.length); &#125; catch (IOException e) &#123; throw new ClassNotFoundException(); &#125; &#125; &#125;; // 使用ClassLoaderTest的类加载器加载本类 Object obj1 = ClassLoaderTest.class.getClassLoader().loadClass(&quot;com.jvm.classloading.ClassLoaderTest&quot;).newInstance(); System.out.println(obj1.getClass()); System.out.println(obj1 instanceof com.jvm.classloading.ClassLoaderTest); // 使用自定义类加载器加载本类 Object obj2 = myLoader.loadClass(&quot;com.jvm.classloading.ClassLoaderTest&quot;).newInstance(); System.out.println(obj2.getClass()); System.out.println(obj2 instanceof com.jvm.classloading.ClassLoaderTest); &#125;&#125; 输出结果： 1234class com.jvm.classloading.ClassLoaderTesttrueclass com.jvm.classloading.ClassLoaderTestfalse myLoader 是自定义的类加载器，可以用来加载与自己在同一路径下的 Class 文件。main 函数的第一部分使用系统加载主类 ClassLoaderTest 的类加载器加载 ClassLoaderTest，输出显示，obj1 的所属类型检查正确，这是虚拟机中有 2 个 ClassLoaderTest 类，一个是主类，另一个是 main() 方法中加载的类，由于这两个类使用同一个类加载器加载并且来源于同一个 Class 文件，因此这两个类是完全相同的。 第二部分使用自定义的类加载器加载 ClassLoaderTest，class com.jvm.classloading.ClassLoderTest显示，obj2 确实是类com.jvm.classloading.ClassLoaderTest实例化出来的对象，但是第二句输出 false。此时虚拟机中有 3 个 ClassLoaderTest 类，由于第 3 个类的类加载器与前面 2 个类加载器不同，虽然来源于同一个 Class 文件，但它是一个独立的类，所属类型检查是返回结果自然是 false。 双亲委派模型类加载器种类从 Java 虚拟机的角度来说，只存在两种不同的类加载器：一种是启动类加载器（Bootstrap ClassLoader），这个类加载器使用 C++ 语言实现（HotSpot 虚拟机中），是虚拟机自身的一部分；另一种就是所有其他的类加载器，这些类加载器都有 Java 语言实现，独立于虚拟机外部，并且全部继承自 java.lang.ClassLoader。 从开发者的角度，类加载器可以细分为： 启动（Bootstrap）类加载器：负责将 Java_Home/lib 下面的类库加载到内存中（比如 rt.jar）。由于引导类加载器涉及到虚拟机本地实现细节，开发者无法直接获取到启动类加载器的引用，所以不允许直接通过引用进行操作。 标准扩展（Extension）类加载器：是由 Sun 的 ExtClassLoader（sun.misc.Launcher$ExtClassLoader）实现的。它负责将 Java_Home /lib/ext 或者由系统变量 java.ext.dir 指定位置中的类库加载到内存中。开发者可以直接使用标准扩展类加载器。 应用程序（Application）类加载器：是由 Sun 的 AppClassLoader（sun.misc.Launcher$AppClassLoader）实现的。它负责将系统类路径（CLASSPATH）中指定的类库加载到内存中。开发者可以直接使用系统类加载器。由于这个类加载器是 ClassLoader 中的 getSystemClassLoader() 方法的返回值，因此一般称为系统（System）加载器。 除此之外，还有自定义的类加载器，它们之间的层次关系被称为类加载器的双亲委派模型。该模型要求除了顶层的启动类加载器外，其余的类加载器都应该有自己的父类加载器，而这种父子关系一般通过组合（Composition）关系来实现，而不是通过继承（Inheritance）。 双亲委派模型双亲委派模型过程 某个特定的类加载器在接到加载类的请求时，首先将加载任务委托给父类加载器，依次递归，如果父类加载器可以完成类加载任务，就成功返回；只有父类加载器无法完成此加载任务时，才自己去加载。 使用双亲委派模型的好处在于 Java 类随着它的类加载器一起具备了一种带有优先级的层次关系。例如类 java.lang.Object，它存在在 rt.jar 中，无论哪一个类加载器要加载这个类，最终都是委派给处于模型最顶端的 Bootstrap ClassLoader 进行加载，因此 Object 类在程序的各种类加载器环境中都是同一个类。相反，如果没有双亲委派模型而是由各个类加载器自行加载的话，如果用户编写了一个 java.lang.Object 的同名类并放在 ClassPath 中，那系统中将会出现多个不同的 Object 类，程序将混乱。因此，如果开发者尝试编写一个与 rt.jar 类库中重名的 Java 类，可以正常编译，但是永远无法被加载运行。 双亲委派模型的系统实现 在 java.lang.ClassLoader 的 loadClass() 方法中，先检查是否已经被加载过，若没有加载则调用父类加载器的 loadClass() 方法，若父加载器为空则默认使用启动类加载器作为父加载器。如果父加载失败，则抛出 ClassNotFoundException 异常后，再调用自己的 findClass() 方法进行加载。 12345678910111213141516171819202122protected synchronized Class&lt;?&gt; loadClass(String name,boolean resolve)throws ClassNotFoundException&#123; //check the class has been loaded or not Class c = findLoadedClass(name); if(c == null)&#123; try&#123; if(parent != null)&#123; c = parent.loadClass(name,false); &#125;else&#123; c = findBootstrapClassOrNull(name); &#125; &#125;catch(ClassNotFoundException e)&#123; //if throws the exception ,the father can not complete the load &#125; if(c == null)&#123; c = findClass(name); &#125; &#125; if(resolve)&#123; resolveClass(c); &#125; return c;&#125; 注意，双亲委派模型是 Java 设计者推荐给开发者的类加载器的实现方式，并不是强制规定的。大多数的类加载器都遵循这个模型，但是 JDK 中也有较大规模破坏双亲模型的情况，例如线程上下文类加载器（Thread Context ClassLoader）的出现，具体分析可以参见周志明著《深入理解 Java 虚拟机》。 参考1、周志明，深入理解 Java 虚拟机：JVM 高级特性与最佳实践，机械工业出版社2、Alexia(minmin) 博客，http://www.cnblogs.com/lanxuezaipiao/p/4138511.html]]></content>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[蓄水池抽样算法（Reservoir Sampling）]]></title>
    <url>%2F4125998541%2F</url>
    <content type="text"><![CDATA[蓄水池抽样算法（Reservoir Sampling）许多年以后，当听说蓄水池抽样算法时,将会想起，那个小学数学老师带他做 “小明对水池边加水边放水，求何时能加满水” 应用题的下午。 一、问题我是在一次失败的面试经历中听说蓄水池算法的。之后上网搜了搜，知道是一个数据抽样算法，寥寥几行，却暗藏玄机。主要用来解决如下问题。 给定一个数据流，数据流长度 N 很大，且 N 直到处理完所有数据之前都不可知，请问如何在只遍历一遍数据（O(N)）的情况下，能够随机选取出 m 个不重复的数据。 这个场景强调了 3 件事： 数据流长度 N 很大且不可知，所以不能一次性存入内存。 时间复杂度为 O(N)。 随机选取 m 个数，每个数被选中的概率为 m/N。 第 1 点限制了不能直接取 N 内的 m 个随机数，然后按索引取出数据。第 2 点限制了不能先遍历一遍，然后分块存储数据，再随机选取。第 3 点是数据选取绝对随机的保证。讲真，在不知道蓄水池算法前，我想破脑袋也不知道该题做何解。 二、核心代码及原理蓄水池抽样算法的核心如下： 123456789101112131415161718int[] reservoir = new int[m];// initfor (int i = 0; i &lt; reservoir.length; i++)&#123; reservoir[i] = dataStream[i];&#125;for (int i = m; i &lt; dataStream.length; i++)&#123; // 随机获得一个[0, i]内的随机整数 int d = rand.nextInt(i + 1); // 如果随机整数落在[0, m-1]范围内，则替换蓄水池中的元素 if (d &lt; m) &#123; reservoir[d] = dataStream[i]; &#125;&#125; 注：这里使用已知长度的数组 dataStream 来表示未知长度的数据流，并假设数据流长度大于蓄水池容量 m。 算法思路大致如下： 如果接收的数据量小于 m，则依次放入蓄水池。 当接收到第 i 个数据时，i &gt;= m，在 [0, i] 范围内取以随机数 d，若 d 的落在 [0, m-1] 范围内，则用接收到的第 i 个数据替换蓄水池中的第 d 个数据。 重复步骤 2。 算法的精妙之处在于：当处理完所有的数据时，蓄水池中的每个数据都是以 m/N 的概率获得的。 下面用白话文推导验证该算法。假设数据开始编号为 1. 第 i 个接收到的数据最后能够留在蓄水池中的概率 = 第 i 个数据进入过蓄水池的概率 * 之后第 i 个数据不被替换的概率（第 i+1 到第 N 次处理数据都不会被替换）。 当 i&lt;=m 时，数据直接放进蓄水池，所以第 i 个数据进入过蓄水池的概率 = 1。 当 i&gt;m 时，在 [1,i] 内选取随机数 d，如果 d&lt;=m，则使用第 i 个数据替换蓄水池中第 d 个数据，因此第 i 个数据进入过蓄水池的概率 = m/i。 当 i&lt;=m 时，程序从接收到第 m+1 个数据时开始执行替换操作，第 m+1 次处理会替换池中数据的为 m/(m+1)，会替换掉第 i 个数据的概率为 1/m，则第 m+1 次处理替换掉第 i 个数据的概率为 (m/(m+1))(1/m)=1/(m+1)，不被替换的概率为 1-1/(m+1)=m/(m+1)。依次，第 m+2 次处理不替换掉第 i 个数据概率为 (m+1)/(m+2)… 第 N 次处理不替换掉第 i 个数据的概率为 (N-1)/N。所以，之后**第 i 个数据不被替换的概率 = m/(m+1)(m+1)/(m+2)…(N-1)/N=m/N**。 当 i&gt;m 时，程序从接收到第 i+1 个数据时开始有可能替换第 i 个数据。则参考上述第 3 点，之后第 i 个数据不被替换的概率 = i/N。 结合第 1 点和第 3 点可知，当 i&lt;=m 时，第 i 个接收到的数据最后留在蓄水池中的概率 = 1m/N=m/N。结合第 2 点和第 4 点可知，当 i&gt;m 时，第 i 个接收到的数据留在蓄水池中的概率 = m/ii/N=m/N。综上可知，每个数据最后被选中留在蓄水池中的概率为 m/N。 这个算法建立在统计学基础上，很巧妙地获得了 “m/N” 这个概率。 三、深入一些——分布式蓄水池抽样（Distributed/Parallel Reservoir Sampling）一块 CPU 的计算能力再强，也总有内存和磁盘 IO 拖他的后腿。因此为提高数据吞吐量，分布式的硬件搭配软件是现在的主流。 如果遇到超大的数据量，即使是 O(N) 的时间复杂度，蓄水池抽样程序完成抽样任务也将耗时很久。因此分布式的蓄水池抽样算法应运而生。运作原理如下： 假设有 K 台机器，将大数据集分成 K 个数据流，每台机器使用单机版蓄水池抽样处理一个数据流，抽样 m 个数据，并最后记录处理的数据量为 N1, N2, …, Nk, …, NK(假设 m&lt;Nk)。N1+N2+…+NK=N。 取 [1, N] 一个随机数 d，若 d&lt;N1，则在第一台机器的蓄水池中等概率不放回地（1/m）选取一个数据；若 N1&lt;=d&lt;(N1+N2)，则在第二台机器的蓄水池中等概率不放回地选取一个数据；一次类推，重复 m 次，则最终从 N 大数据集中选出 m 个数据。 m/N 的概率验证如下： 第 k 台机器中的蓄水池数据被选取的概率为 m/Nk。 从第 k 台机器的蓄水池中选取一个数据放进最终蓄水池的概率为 Nk/N。 第 k 台机器蓄水池的一个数据被选中的概率为 1/m。（不放回选取时等概率的） 重复 m 次选取，则每个数据被选中的概率为 m(m/NkNk/N*1/m)=m/N。 四、算法验证写一份完整的代码，用来验证蓄水池抽样的随机性。数据集大小为 1000，蓄水池容量为 10，做 10_0000 次抽样。如果程序正确，那么每个数被抽中的次数接近 1000 次。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272package cn.edu.njupt.qyz;import java.util.ArrayList;import java.util.Arrays;import java.util.LinkedList;import java.util.List;import java.util.Random;import java.util.Set;import java.util.TreeSet;import java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Future;public class ReservoirSampling &#123; static ExecutorService exec = Executors.newFixedThreadPool(4); // 抽样任务，用作模拟并行抽样 private static class SampleTask implements Callable&lt;int[]&gt; &#123; // 输入该任务的数据 private int[] innerData; // 蓄水池容量 private int m; SampleTask (int m, int[] innerData) &#123; this.innerData = innerData; this.m = m; &#125; @Override public int[] call() throws Exception &#123; int[] reservoir = sample(this.m, this.innerData); return reservoir; &#125; &#125; // 并行抽样 public static int[] mutiSample(int m, int[] dataStream) throws InterruptedException, ExecutionException &#123; Random rand = new Random(); int[] reservoir = initReservoir(m, dataStream); // 生成3个范围内随机数，将数据切成4份 List&lt;Integer&gt; list = getRandInt(rand, dataStream.length); int s1 = list.get(0); int s2 = list.get(1); int s3 = list.get(2); // 每个任务处理的数据量 double n1 = s1 - 0; double n2 = s2 - s1; double n3 = s3 - s2; double n4 = dataStream.length - s3; // 并行抽样 Future&lt;int[]&gt; f1 = exec.submit(new SampleTask(m, Arrays.copyOfRange(dataStream, 0, s1))); Future&lt;int[]&gt; f2 = exec.submit(new SampleTask(m, Arrays.copyOfRange(dataStream, s1, s2))); Future&lt;int[]&gt; f3 = exec.submit(new SampleTask(m, Arrays.copyOfRange(dataStream, s2, s3))); Future&lt;int[]&gt; f4 = exec.submit(new SampleTask(m, Arrays.copyOfRange(dataStream, s3, dataStream.length))); List&lt;Integer&gt; r1 = getList(f1.get()); List&lt;Integer&gt; r2 = getList(f2.get()); List&lt;Integer&gt; r3 = getList(f3.get()); List&lt;Integer&gt; r4 = getList(f4.get()); // 进行m次抽样 for (int i = 0; i &lt; m; i++) &#123; int p = rand.nextInt(dataStream.length); // 根据随机数落在的范围选择元素 if (p &lt; s1) &#123; reservoir[i] = getRandEle(r1, rand.nextInt(r1.size())); &#125; else if (p &lt; s2) &#123; reservoir[i] = getRandEle(r2, rand.nextInt(r2.size())); &#125; else if (p &lt; s3) &#123; reservoir[i] = getRandEle(r3, rand.nextInt(r3.size())); &#125; else &#123; reservoir[i] = getRandEle(r4, rand.nextInt(r4.size())); &#125; &#125; return reservoir; &#125; // 根据输入返回随机位置的元素，并且删除该元素，模拟不放回 private static int getRandEle(List&lt;Integer&gt; list, int idx) &#123; return list.remove(idx); &#125; // 获取bound范围内的3个随机数，用来分割数据集 private static List&lt;Integer&gt; getRandInt(Random rand, int bound) &#123; Set&lt;Integer&gt; set = new TreeSet&lt;&gt;(); List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); while (set.size() &lt; 3) &#123; set.add(rand.nextInt(bound)); &#125; for (int e: set) &#123; list.add(e); &#125; return list; &#125; // 数据转换成List private static List&lt;Integer&gt; getList(int[] arr) &#123; List&lt;Integer&gt; list = new LinkedList&lt;&gt;(); for (int a : arr) &#123; list.add(a); &#125; return list; &#125; // 单机版蓄水池抽样 public static int[] sample(int m, int[] dataStream) &#123; // 随机数生成器，以系统当前nano时间作为种子 Random rand = new Random(); int[] reservoir = initReservoir(m, dataStream); // init for (int i = 0; i &lt; reservoir.length; i++) &#123; reservoir[i] = dataStream[i]; &#125; for (int i = m; i &lt; dataStream.length; i++) &#123; // 随机获得一个[0, i]内的随机整数 int d = rand.nextInt(i + 1); // 如果随机整数在[0, m-1]范围内，则替换蓄水池中的元素 if (d &lt; m) &#123; reservoir[d] = dataStream[i]; &#125; &#125; return reservoir; &#125; private static int[] initReservoir (int m, int[] dataStream) &#123; int[] reservoir; if (m &gt; dataStream.length) &#123; reservoir = new int[dataStream.length]; &#125; else &#123; reservoir = new int[m]; &#125; return reservoir; &#125; // 单机版测试 public void test() &#123; // 样本长度 int len = 1000; // 蓄水池容量 int m = 10; // 抽样次数，用作验证抽样的随机性 int iterTime = 100000; // 每个数字被抽到的次数 int[] freq = new int[len]; // 样本 int[] dataStream = new int[len]; // init dataStream for (int i = 0; i &lt; dataStream.length; i++) &#123; dataStream[i] = i; &#125; // count freq for (int k = 0; k &lt; iterTime; k++) &#123; // 进行抽样 int[] reservoir = sample(m, dataStream); // 计算出现次数 for (int i = 0; i &lt; reservoir.length; i++) &#123; int ele = reservoir[i]; freq[ele] += 1; &#125; &#125; printStaticInfo(freq); &#125; // 测试并行抽样 public void mutiTest() throws InterruptedException, ExecutionException &#123; // 样本长度 int len = 1000; // 蓄水池容量 int m = 10; // 抽样次数，用作验证抽样的随机性 int iterTime = 10_0000; // 每个数字被抽到的次数 int[] freq = new int[len]; // 样本 int[] dataStream = new int[len]; // init dataStream for (int i = 0; i &lt; dataStream.length; i++) &#123; dataStream[i] = i; &#125; // count freq for (int k = 0; k &lt; iterTime; k++) &#123; // 进行抽样 int[] reservoir = mutiSample(m, dataStream); // 计算出现次数 for (int i = 0; i &lt; reservoir.length; i++) &#123; int ele = reservoir[i]; freq[ele] += 1; &#125; &#125; printStaticInfo(freq); &#125; // 打印统计信息 private void printStaticInfo (int[] freq) &#123; // 期望、方差和标准差 double avg = 0; double var = 0; double sigma = 0; // print for (int i = 0; i &lt; freq.length; i++) &#123; if (i % 10 == 9) System.out.println(); System.out.print(freq[i] + &quot;, &quot;); avg += ((double)(freq[i]) / freq.length); var += (double)(freq[i] * freq[i]) / freq.length; &#125; // 输出统计信息 System.out.println(&quot;\n===============================&quot;); var = var - avg * avg; sigma = Math.sqrt(var); System.out.println(&quot;Average: &quot; + avg); System.out.println(&quot;Variance: &quot; + var); System.out.println(&quot;Standard deviation: &quot; + sigma); &#125; public static void main (String[] args) throws InterruptedException, ExecutionException &#123; ReservoirSampling rs = new ReservoirSampling(); rs.mutiTest(); &#125;&#125; 单机版输出和并行版的输出类似，截取片段如下： 1234567891011121314151617948, 1006, 1014, 1019, 1033, 1040, 948, 1014, 1000, 951, 1014, 987, 1049, 1043, 1034, 983, 1006, 974, 1060, 1009, 986, 1021, 1024, 963, 1041, 1028, 988, 1011, 975, 980, 1055, 1017, 1010, 1018, 1013, 983, 942, 1056, 1003, 1063, 1004, 1004, 999, 976, 957, 935, 1061, 1018, 1002, 1018, 1019, 946, 985, 1057, 1012, 965, 978, 1040, 1026, 1064, 1026, 1018, 980, 996, 1025, 1028, 1006, 944, 986, 981, 923, 1015, 991, 1019, 1024, 1143, 989, 985, 1022, 1019, 1004, 1000, 989, 972, 1041, 988, 1050, 932, 975, 1037, 1016, 983, 1051, 1003, 983, 986, 1017, 1009, 936, 993, 965, 976, 1001, 1000, 988, 1030, 1050, 1024, 981, 985, 935, 1023, 996, 1007, 1013, 1046, 1003, 1006, 973, 989, 943, ===============================Average: 1000.0000000000002Variance: 1011.8799999983748Standard deviation: 31.81006130139291 此外，为了对比单机版与并行版（4 线程）的性能差异，使用 10_0000 大小的数据集，蓄水池容量 10，进行 100_0000 次重复抽样，对比两者的运行时间。结果如下 1234567891011121314---------单机版----------===============================Average: 100.00000000000125Variance: 100.31497999751264Standard deviation: 10.015736617818613---------并行版----------===============================Average: 100.00000000000169Variance: 100.63045999737915Standard deviation: 10.031473470900432单机版耗时：2006s并行版耗时：1265s 从输出结果可以看出，算法保证了数据选取的随机性。且并行版算法能够有效提高数据吞吐量。 五、应用场景蓄水池抽样的 O(N) 时间复杂度，O(m) 空间复杂度令其适用于对流数据、大数据集的等概率抽样。比如一个大文本数据，随机输出其中的几行。 六、总结象征性总结：优雅巧妙的算法——蓄水池抽样。 七、参考文献 数据工程师必知算法：蓄水池抽样 【算法 34】蓄水池抽样算法 (Reservoir Sampling Algorithm) 分布式 / 并行蓄水池抽样 (Distributed/Parallel Reservoir Sampling) Distributed/Parallel Reservoir Sampling]]></content>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单例模式–双重检验锁真的线程安全吗]]></title>
    <url>%2F766337335%2F</url>
    <content type="text"><![CDATA[单例模式–双重检验锁真的线程安全吗单例模式是我们最熟悉不过的一种设计模式，用来保证内存中只有一个对象的实例。虽然容易，但里面的坑也有很多，比如双重检验锁模式 (double checked locking pattern) 真的是线程安全的吗？ 起因在对项目进行 PMD 静态代码检测时，遇到了这样一个问题 Partially created objects can be returned by the Double Checked Locking pattern when used in Java. An optimizing JRE may assign a reference to the baz variable before it calls the constructor of the object the reference points to. Note: With Java 5, you can make Double checked locking work, if you declare the variable to be volatile. 大概意思是，使用双重检验锁模式，可能会返回一个部分初始化的对象。可能大家有些疑虑，什么是部分初始化的对象，我们下面继续分析 什么是双重检验锁模式12345678910public static Singleton getSingleton() &#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance;&#125; 我们看到，在同步代码块的内部和外部都判断了 instance == null，这时因为，可能会有多个线程同时进入到同步代码块外的 if 判断中，如果在同步代码块内部不进行判空的话，可能会初始化多个实例。 问题所在这种写法看似完美无缺，但它却是有问题的，或者说它并不担保一定完美无缺。主要原因在于 instance = new Singleton(); 并不是原子性的操作。创建一个对象可以分为三部： 1231.分配对象的内存空间2.初始化对象3.设置instance指向刚分配的内存地址,当instance指向分配地址时，instance不为空 但是，2、3 部之间，可能会被重排序，造成创建对象顺序变为 1-3-2. 试想一个场景：线程 A 第一次创建对象 Singleton，对象创建顺序为 1-3-2；当给 instance 分配完内存后，这时来了一个线程 B 调用了 getSingleton() 方法这时候进行 instance == null 的判断，发现 instance 并不为 null。但注意这时候 instance 并没有初始化对象，线程 B 则会将这个未初始化完成的对象返回。那 B 线程使用 instance 时就可能会出现问题，这就是双重检查锁问题所在。 使用 volatile对于上述的问题，我们可以通过把 instance 声明为 volatile 型来解决 1234567891011121314public class Singleton &#123; private volatile static Singleton instance; public static Singleton getSingleton() &#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 有些人认为使用 volatile 的原因是可见性，也就是可以保证线程在本地不会存有 instance 的副本，每次都是去主内存中读取。但其实是不对的。使用 volatile 的主要原因是其另一个特性：禁止指令重排序优化。也就是说，在 volatile 变量的赋值操作后面会有一个内存屏障，读操作不会被重排序到内存屏障之前。比如上面的例子，取操作必须在执行完 1-2-3 之后或者 1-3-2 之后，不存在执行到 1-3 然后取到值的情况。从「先行发生原则」的角度理解的话，就是对于一个 volatile 变量的写操作都先行发生于后面对这个变量的读操作（这里的“后面”是时间上的先后顺序. 但是特别注意在 Java 5 以前的版本使用了 volatile 的双检锁还是有问题的。其原因是 Java 5 以前的 JMM （Java 内存模型）是存在缺陷的，即时将变量声明成 volatile 也不能完全避免重排序，主要是 volatile 变量前后的代码仍然存在重排序问题。这个 volatile 屏蔽重排序的问题在 Java 5 中才得以修复，所以在这之后才可以放心使用 volatile。 必须在 JDK5 版本以上使用。 静态内部类123456789101112public class Singleton &#123; private static class SingletonHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; private Singleton() &#123; &#125; public static final Singleton getInstance() &#123; return SingletonHolder.INSTANCE; &#125;&#125; 这种写法是目前比较推荐的一种写法，采用静态内部类的方式，即实现了懒加载又不会出现线程安全问题。而且减少了 synchronized 的开销。 Learn more双重检查锁定与延迟初始化PMD-DoubleCheckedLockingDouble-checked locking: Clever, but broken]]></content>
      <tags>
        <tag>java</tag>
        <tag>multi-thread</tag>
      </tags>
  </entry>
</search>
